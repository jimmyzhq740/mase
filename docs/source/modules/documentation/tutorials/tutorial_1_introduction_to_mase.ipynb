{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 1: Introduction to the Mase IR, MaseGraph and Torch FX passes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we'll see how to import a model into Mase by generating a compute graph using the [MaseGraph](https://github.com/DeepWok/mase/blob/adls_2024/src/chop/ir/graph/mase_graph.py) API and how to start optimizing models using analysis and transform passes. First, we'll import a pretrained model directly from [HuggingFace Transformers](https://github.com/huggingface/transformers). For this example, we'll use Bert for sequence classification. You can read the [Bert paper](https://arxiv.org/abs/1810.04805) for information regarding the architecture.\n",
    "\n",
    "We get a warning saying that some weights were not initialized, since only the weights in the decoder are pretrained and included in the HuggingFace Hub. When we use the [AutoModelForSequenceClassification](https://huggingface.co/docs/transformers/model_doc/auto) API, a classification head is added at the end of the model, with randomly initialized weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertForSequenceClassification(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 128)\n",
      "      (token_type_embeddings): Embedding(2, 128)\n",
      "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-1): 2 x BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSdpaSelfAttention(\n",
      "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (value): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
      "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): Linear(in_features=128, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"prajjwal1/bert-tiny\")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate an FX graph for the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To import a model into Mase, we need to generate a compute graph. In the Machine Learning community, there are several ways of capturing and representing a compute graph, such as [ONNX](https://onnx.ai/), [Torchscript](https://pytorch.org/docs/stable/jit.html), [MLIR](https://mlir.llvm.org/), [TVM](https://tvm.apache.org/), etc. Mase relies on [Torch FX](https://pytorch.org/docs/stable/fx.html), which has the following features and benefits:\n",
    "\n",
    "- **High-level IR**: unlike `LLVM` or `MLIR`, `FX` offers a high-level representation of the computation which enables fast optimizations.\n",
    "\n",
    "- **Pytorch native**: every operator in the FX graph correlates to a Python object or callable, meaning we can transform and optimize the graph, then simply regenerate the Python code required to run it. Unlike ONNX, there is no requirement for a dedicated runtime: all you need is Python.\n",
    "\n",
    "When you call `MaseGraph(model)`, the [MaseTracer](https://github.com/DeepWok/mase/blob/main/src/chop/ir/graph/mase_graph.py) class runs a forward pass of the model with `Proxy` objects instead of the regular `Tensor` objects. These Proxies record every operation performed on them, which is then used to generate the compute graph. The following cell generates the graph and generates a drawing of the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`past_key_values` were not specified as input names, but model.config.use_cache = True. Setting model.config.use_cache = False.\n"
     ]
    }
   ],
   "source": [
    "from chop import MaseGraph\n",
    "\n",
    "# Generate basic FX graph, but need metadat to in next page convert into Mase graph\n",
    "mg = MaseGraph(model)\n",
    "mg.draw(\"bert-base-uncased.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 6 different types of nodes in an FX graph: `placeholder`, `get_attr`, `call_function`, `call_module`, `call_method`, `output`. Each node has several associated attributes, such as `name`, `args`/`kwargs` and `target`. These have different contents and meaning depending on the node type. We provide a summary below, but for more details, see the [FX documentation](https://pytorch.org/docs/stable/fx.html). \n",
    "\n",
    "- **placeholder**: represents a function input, which can be a `Tensor` or another Python object.\n",
    "\n",
    "- **get_attr**: retrieves a parameter from the Pytorch module hierarchy. `target` is the fully-qualified string name of the parameter’s position in the module hierarchy.\n",
    "\n",
    "- **call_function**: applies a free function to some values. `target` is a handle to the Python callable. `args` and `kwargs` represent the arguments to the function, following the Python calling convention.\n",
    "\n",
    "- **call_module**: applies a module in the module hierarchy’s `forward()` method with the given arguments. `target` is the fully-qualified string name of the module in the module hierarchy to call.\n",
    "\n",
    "- **call_method**: calls a method on a value. `target` is the string name of the method to apply to the self argument.\n",
    "\n",
    "- **output**: contains the output of the traced function in its args[0] attribute. This corresponds to the `return` statement in the Graph printout.\n",
    "\n",
    "You may be wondering the difference between `call_function`, `call_method` and `call_module` nodes: `call_function` nodes can have arbitrary Python callable as targets, while the target for `call_method` nodes must be a `Tensor` class method. `call_module` nodes refer to `torch.nn.Module` objects which must be included in the Pytorch module hierarchy. For example, the Pytorch ReLU activation function can be seen any of these node types:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "random_tensor = torch.randn(2, 2)\n",
    "\n",
    "function_relu = torch.relu(random_tensor)\n",
    "method_relu = random_tensor.relu()\n",
    "module_relu = torch.nn.ReLU()(random_tensor)\n",
    "\n",
    "assert torch.equal(function_relu, method_relu)\n",
    "assert torch.equal(function_relu, module_relu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the generated SVG file (you may find this [VSCode extension](https://marketplace.visualstudio.com/items?itemName=SimonSiefke.svg-preview) useful) and inspect each node. If you can't generate the image, we show below a segment of the graph that corresponds to the first attention layer of the Bert encoder. If you also inspect the [Bert implementation](https://github.com/huggingface/transformers/blob/main/src/transformers/models/bert/modeling_bert.py) in the HuggingFace repository, you can see how each node in the generated graph corresponds to lines in the Python code. For example, the `bert_encoder_layer_0_attention_self_<query/key/value>` nodes correspond to the calls to the Query/Key/Value linear layers defined in the `BertSelfAttention` class. You can also see how not every piece of code has an associated node in the graph - when the code is being symbolically traced, parts of the code that aren't executed (for example, if statements which never yield `True`) don't interact with the `Proxy` objects, hence they're not included in the graph.\n",
    "\n",
    "<img src=\"imgs/fx_graph_bert_base_uncased_num_hidden_layers_1_segment.png\" alt=\"drawing\" width=\"1200\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Mase IR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As previously mentioned, the Mase IR is built on top of Torch FX. However, the FX operator associated with each node in the graph refers broadly to Python semantics, such as how to execute code generation for a transformed graph. For example, when the FX code generator encounters a `call_function` node, it would know to generate code equivalent to `node.target(*node.args, **node.kwargs)`, while for `call_method` nodes, the code would correspond to `getattr(node.args[0], node.target)(*args[1:], **kwargs)`. However, beyond code generation, the FX IR has no information regarding the workload being executed by the graph - that's where the Mase IR comes in. \n",
    "\n",
    "As described in previous publications, the major benefit of the Mase IR is in offering a common abstraction layer for both hardware and software workloads (see [here](https://arxiv.org/abs/2307.15517), [here](https://openreview.net/forum?id=Z7v6mxNVdU)). You can find a list of Mase operators under the [IR definition file](https://github.com/DeepWok/mase/blob/main/src/chop/ir/common.py). You can see that most operators correspond strongly with either Pytorch or ONNX operators. Each operator is also associated with a node type, which can be one of the following. \n",
    "\n",
    "-  ``module_related_func``: includes functions under ``torch.nn.functional`` and the ``torch.nn.Module`` that wraps them. For example, ``torch.nn.functional.relu`` and ``torch.nn.ReLU`` both fall under this category.\n",
    "\n",
    "-  ``module``: a MASE module is a subclass of ``torch.nn.Module`` that does not have corresponding ``torch.nn.functional`` counterpart. For example, ``torch.nn.BatchNorm2D`` is a MASE module because ``torch.nn.functional.batch_norm_2d`` does not exist.\n",
    "\n",
    "-  ``builtin_func``: MASE builtin_func includes functions under ``torch`` that are not ``torch.nn.functional`` and ``torch.nn.Module``, such as ``torch.cat`` and ``torch.bmm``.\n",
    "\n",
    "The following types are also present, which have the same meaning as in Torch FX.\n",
    "\n",
    "-  ``placeholder``: input node of a MASEGraph.\n",
    "\n",
    "-  ``get_attr``: represents the attribute of a MASE module.\n",
    "\n",
    "-  ``output``: equivalent to the return statement in the forward function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Pass System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have worked with compilers, you might be familiar with the concept of a pass, which is a function that iterates over each node in the graph to perform some task. In Mase, there are two categories of passes: analysis and transform passes. \n",
    "\n",
    "- **Analysis passes**: extract some information about each node, annotate nodes with relevant data, and generate payloads to be used by subsequent passes.\n",
    "- **Transform passes**: change the topology of the graph by inserting, removing or replacing nodes.\n",
    "\n",
    "All passes, whether analysis or transform, have the following structure. Every pass accepts a dictionary `pass_args` containing required arguments, and outputs a tuple of the output graph (which can be annotated or transformed) and a `pass_outputs` dictionary. A pass doesn't need to use any arguments or generate any outputs (other than the output graph), however the argument and return signatures must follow this standard such that passes can be chained together.\n",
    "\n",
    "```python\n",
    "\n",
    "def dummy_pass(mg, pass_args={}):\n",
    "    \n",
    "    # ... do some setup \n",
    "    pass_outputs = {}\n",
    "\n",
    "    for node in mg.fx_graph.nodes:\n",
    "        # ... do stuff\n",
    "\n",
    "    return mg, pass_outputs\n",
    "\n",
    "```\n",
    "\n",
    "Next, we'll show how to run some analysis passes required to raise the generated FX graph to the Mase IR. Then, we'll come back to see how to write some simple analysis passes to do useful things."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raising the FX graph to the Mase IR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert the simple FX graph we generated into the Mase IR, we must run the following analysis passes, which annotate each node with relevant metadata. Note that metadata follows under three categories: `common`, `hardware` and `software`. Hardware metadata is used for generating FPGA accelerators in the [emit Verilog toolflow](https://github.com/DeepWok/mase/tree/adls_2024/src/chop/passes/graph/transforms/verilog) (see Lab 4), while software metadata is used by passes such as [autosharding](https://github.com/DeepWok/mase/tree/main/src/chop/passes/graph/analysis/autosharding), which automatically finds a model parallelism configuration in a GPU cluster. Common metadata is generally required by all workflows in Mase.\n",
    "\n",
    "- **init_metadata_analysis_pass**: initializes a `MaseMetadata` object for each node in the graph, which behaves like a dictionary and is stored under `node.meta[\"mase\"]`. Each metadata instance has the following structure, which is empty at initialization. See [here](https://deepwok.github.io/mase/modules/api/analysis/init_metadata.html) for details on the implementation.\n",
    "\n",
    "```python\n",
    "        node.meta[\"mase\"] = {\n",
    "            \"common\": {},\n",
    "            \"hardware\": {},\n",
    "            \"software\": {},\n",
    "        }\n",
    "```\n",
    "\n",
    "- **add_common_metadata_analysis_pass**: populates the `node.meta[\"mase\"][\"common\"]` dictionary by executing the following two steps. See [here](https://deepwok.github.io/mase/modules/api/analysis/add_metadata.html) for details on the implementation.\n",
    "    - **Operator inference**: determine the operator associated with each node in the graph from its fx operator and target, and annotate under `node.meta[\"mase\"][\"common\"][\"mase_op\"]`\n",
    "    - **Shape Propagation**: similarly to the [Interpreter Pattern](https://pytorch.org/docs/stable/fx.html#the-interpreter-pattern) in the FX documentation, this involves running a forward pass of the entire model with a provided dummy input, and observing the Tensor metadata (shape, data type, stride, etc) of each argument and result for every node in the graph. This is then annotated under `node.meta[\"mase\"][\"common\"][\"args\"]` and `node.meta[\"mase\"][\"common\"][\"results\"]`.\n",
    "\n",
    "The `add_common_metadata_analysis_pass` requires a dummy Tensor input to run the shape propagation step. In the following cell, we show how this can be done using the HuggingFace tokenizer, to which we pass two truthful statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Hellos in add_common_metadata\n",
      "sigoyi in add_common_metadata\n",
      "nihhhhhhhhh in graph_iterator_for_mase_ops in add_common_metadata\n",
      "nihhhhhhhhh in graph_iterator_for_mase_ops in add_common_metadata\n",
      "nihhhhhhhhh in graph_iterator_for_mase_ops in add_common_metadata\n",
      "nihhhhhhhhh in graph_iterator_for_mase_ops in add_common_metadata\n",
      "nihhhhhhhhh in graph_iterator_for_mase_ops in add_common_metadata\n",
      "nihhhhhhhhh in graph_iterator_for_mase_ops in add_common_metadata\n",
      "nihhhhhhhhh in graph_iterator_for_mase_ops in add_common_metadata\n",
      "nihhhhhhhhh in graph_iterator_for_mase_ops in add_common_metadata\n",
      "nihhhhhhhhh in graph_iterator_for_mase_ops in add_common_metadata\n",
      "nihhhhhhhhh in graph_iterator_for_mase_ops in add_common_metadata\n",
      "nihhhhhhhhh in graph_iterator_for_mase_ops in add_common_metadata\n",
      "nihhhhhhhhh in graph_iterator_for_mase_ops in add_common_metadata\n",
      "nihhhhhhhhh in graph_iterator_for_mase_ops in add_common_metadata\n",
      "nihhhhhhhhh in graph_iterator_for_mase_ops in add_common_metadata\n",
      "nihhhhhhhhh in graph_iterator_for_mase_ops in add_common_metadata\n",
      "nihhhhhhhhh in graph_iterator_for_mase_ops in add_common_metadata\n",
      "nihhhhhhhhh in graph_iterator_for_mase_ops in add_common_metadata\n",
      "nihhhhhhhhh in graph_iterator_for_mase_ops in add_common_metadata\n",
      "nihhhhhhhhh in graph_iterator_for_mase_ops in add_common_metadata\n",
      "nihhhhhhhhh in graph_iterator_for_mase_ops in add_common_metadata\n",
      "nihhhhhhhhh in graph_iterator_for_mase_ops in add_common_metadata\n",
      "nihhhhhhhhh in graph_iterator_for_mase_ops in add_common_metadata\n",
      "nihhhhhhhhh in graph_iterator_for_mase_ops in add_common_metadata\n",
      "nihhhhhhhhh in graph_iterator_for_mase_ops in add_common_metadata\n",
      "nihhhhhhhhh in graph_iterator_for_mase_ops in add_common_metadata\n",
      "nihhhhhhhhh in graph_iterator_for_mase_ops in add_common_metadata\n",
      "nihhhhhhhhh in graph_iterator_for_mase_ops in add_common_metadata\n",
      "nihhhhhhhhh in graph_iterator_for_mase_ops in add_common_metadata\n",
      "nihhhhhhhhh in graph_iterator_for_mase_ops in add_common_metadata\n",
      "nihhhhhhhhh in graph_iterator_for_mase_ops in add_common_metadata\n",
      "nihhhhhhhhh in graph_iterator_for_mase_ops in add_common_metadata\n",
      "nihhhhhhhhh in graph_iterator_for_mase_ops in add_common_metadata\n",
      "nihhhhhhhhh in graph_iterator_for_mase_ops in add_common_metadata\n",
      "nihhhhhhhhh in graph_iterator_for_mase_ops in add_common_metadata\n",
      "nihhhhhhhhh in graph_iterator_for_mase_ops in add_common_metadata\n",
      "nihhhhhhhhh in graph_iterator_for_mase_ops in add_common_metadata\n",
      "nihhhhhhhhh in graph_iterator_for_mase_ops in add_common_metadata\n",
      "nihhhhhhhhh in graph_iterator_for_mase_ops in add_common_metadata\n",
      "nihhhhhhhhh in graph_iterator_for_mase_ops in add_common_metadata\n",
      "nihhhhhhhhh in graph_iterator_for_mase_ops in add_common_metadata\n",
      "nihhhhhhhhh in graph_iterator_for_mase_ops in add_common_metadata\n",
      "nihhhhhhhhh in graph_iterator_for_mase_ops in add_common_metadata\n",
      "nihhhhhhhhh in graph_iterator_for_mase_ops in add_common_metadata\n",
      "nihhhhhhhhh in graph_iterator_for_mase_ops in add_common_metadata\n",
      "nihhhhhhhhh in graph_iterator_for_mase_ops in add_common_metadata\n",
      "nihhhhhhhhh in graph_iterator_for_mase_ops in add_common_metadata\n",
      "nihhhhhhhhh in graph_iterator_for_mase_ops in add_common_metadata\n",
      "nihhhhhhhhh in graph_iterator_for_mase_ops in add_common_metadata\n",
      "graph_model:  GraphModule(\n",
      "  (bert): Module(\n",
      "    (embeddings): Module(\n",
      "      (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
      "      (token_type_embeddings): Embedding(2, 128)\n",
      "      (position_embeddings): Embedding(512, 128)\n",
      "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): Module(\n",
      "      (layer): Module(\n",
      "        (0): Module(\n",
      "          (attention): Module(\n",
      "            (self): Module(\n",
      "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (value): Linear(in_features=128, out_features=128, bias=True)\n",
      "            )\n",
      "            (output): Module(\n",
      "              (dense): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): Module(\n",
      "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
      "          )\n",
      "          (output): Module(\n",
      "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Module(\n",
      "          (attention): Module(\n",
      "            (self): Module(\n",
      "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (value): Linear(in_features=128, out_features=128, bias=True)\n",
      "            )\n",
      "            (output): Module(\n",
      "              (dense): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): Module(\n",
      "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
      "          )\n",
      "          (output): Module(\n",
      "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): Module(\n",
      "      (dense): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): Linear(in_features=128, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "def forward(self, input_ids : torch.Tensor):\n",
      "    size = input_ids.size()\n",
      "    getitem = size[0]\n",
      "    getitem_1 = size[1];  size = None\n",
      "    bert_embeddings_token_type_ids = self.bert.embeddings.token_type_ids\n",
      "    getitem_2 = bert_embeddings_token_type_ids[(slice(None, None, None), slice(None, getitem_1, None))];  bert_embeddings_token_type_ids = None\n",
      "    expand = getitem_2.expand(getitem, getitem_1);  getitem_2 = None\n",
      "    size_1 = input_ids.size()\n",
      "    getitem_3 = size_1[1];  size_1 = None\n",
      "    bert_embeddings_position_ids = self.bert.embeddings.position_ids\n",
      "    add = getitem_3 + 0;  getitem_3 = None\n",
      "    getitem_4 = bert_embeddings_position_ids[(slice(None, None, None), slice(0, add, None))];  bert_embeddings_position_ids = add = None\n",
      "    bert_embeddings_word_embeddings = self.bert.embeddings.word_embeddings(input_ids)\n",
      "    bert_embeddings_token_type_embeddings = self.bert.embeddings.token_type_embeddings(expand);  expand = None\n",
      "    add_1 = bert_embeddings_word_embeddings + bert_embeddings_token_type_embeddings;  bert_embeddings_word_embeddings = bert_embeddings_token_type_embeddings = None\n",
      "    bert_embeddings_position_embeddings = self.bert.embeddings.position_embeddings(getitem_4);  getitem_4 = None\n",
      "    add_2 = add_1 + bert_embeddings_position_embeddings;  add_1 = bert_embeddings_position_embeddings = None\n",
      "    bert_embeddings_layer_norm = self.bert.embeddings.LayerNorm(add_2);  add_2 = None\n",
      "    bert_embeddings_dropout = self.bert.embeddings.dropout(bert_embeddings_layer_norm);  bert_embeddings_layer_norm = None\n",
      "    add_3 = getitem_1 + 0\n",
      "    getattr_1 = input_ids.device;  input_ids = None\n",
      "    ones = torch.ones((getitem, add_3), device = getattr_1);  getitem = add_3 = getattr_1 = None\n",
      "    dim = ones.dim()\n",
      "    eq = dim == 2;  dim = eq = None\n",
      "    size_2 = ones.size()\n",
      "    getitem_5 = size_2[0];  getitem_5 = None\n",
      "    getitem_6 = size_2[1];  size_2 = getitem_6 = None\n",
      "    size_3 = ones.size()\n",
      "    getitem_7 = size_3[0]\n",
      "    getitem_8 = size_3[1];  size_3 = None\n",
      "    getitem_9 = ones[(slice(None, None, None), None, None, slice(None, None, None))];  ones = None\n",
      "    expand_1 = getitem_9.expand(getitem_7, 1, getitem_1, getitem_8);  getitem_9 = getitem_7 = getitem_1 = getitem_8 = None\n",
      "    getattr_2 = bert_embeddings_dropout.dtype\n",
      "    to = expand_1.to(getattr_2);  expand_1 = None\n",
      "    sub = 1.0 - to;  to = None\n",
      "    to_1 = sub.to(torch.bool)\n",
      "    finfo = torch.finfo(getattr_2);  getattr_2 = None\n",
      "    getattr_3 = finfo.min;  finfo = None\n",
      "    masked_fill = sub.masked_fill(to_1, getattr_3);  sub = to_1 = getattr_3 = None\n",
      "    size_4 = bert_embeddings_dropout.size()\n",
      "    getitem_10 = size_4[0]\n",
      "    getitem_11 = size_4[1]\n",
      "    getitem_12 = size_4[2];  size_4 = getitem_12 = None\n",
      "    bert_encoder_layer_0_attention_self_query = getattr(self.bert.encoder.layer, \"0\").attention.self.query(bert_embeddings_dropout)\n",
      "    size_5 = bert_encoder_layer_0_attention_self_query.size()\n",
      "    getitem_13 = size_5[slice(None, -1, None)];  size_5 = None\n",
      "    add_4 = getitem_13 + (2, 64);  getitem_13 = None\n",
      "    view = bert_encoder_layer_0_attention_self_query.view(add_4);  bert_encoder_layer_0_attention_self_query = add_4 = None\n",
      "    permute = view.permute(0, 2, 1, 3);  view = None\n",
      "    bert_encoder_layer_0_attention_self_key = getattr(self.bert.encoder.layer, \"0\").attention.self.key(bert_embeddings_dropout)\n",
      "    size_6 = bert_encoder_layer_0_attention_self_key.size()\n",
      "    getitem_14 = size_6[slice(None, -1, None)];  size_6 = None\n",
      "    add_5 = getitem_14 + (2, 64);  getitem_14 = None\n",
      "    view_1 = bert_encoder_layer_0_attention_self_key.view(add_5);  bert_encoder_layer_0_attention_self_key = add_5 = None\n",
      "    permute_1 = view_1.permute(0, 2, 1, 3);  view_1 = None\n",
      "    bert_encoder_layer_0_attention_self_value = getattr(self.bert.encoder.layer, \"0\").attention.self.value(bert_embeddings_dropout)\n",
      "    size_7 = bert_encoder_layer_0_attention_self_value.size()\n",
      "    getitem_15 = size_7[slice(None, -1, None)];  size_7 = None\n",
      "    add_6 = getitem_15 + (2, 64);  getitem_15 = None\n",
      "    view_2 = bert_encoder_layer_0_attention_self_value.view(add_6);  bert_encoder_layer_0_attention_self_value = add_6 = None\n",
      "    permute_2 = view_2.permute(0, 2, 1, 3);  view_2 = None\n",
      "    scaled_dot_product_attention = torch._C._nn.scaled_dot_product_attention(permute, permute_1, permute_2, attn_mask = masked_fill, dropout_p = 0.0, is_causal = False);  permute = permute_1 = permute_2 = None\n",
      "    transpose = scaled_dot_product_attention.transpose(1, 2);  scaled_dot_product_attention = None\n",
      "    reshape = transpose.reshape(getitem_10, getitem_11, 128);  transpose = getitem_10 = getitem_11 = None\n",
      "    bert_encoder_layer_0_attention_output_dense = getattr(self.bert.encoder.layer, \"0\").attention.output.dense(reshape);  reshape = None\n",
      "    bert_encoder_layer_0_attention_output_dropout = getattr(self.bert.encoder.layer, \"0\").attention.output.dropout(bert_encoder_layer_0_attention_output_dense);  bert_encoder_layer_0_attention_output_dense = None\n",
      "    add_7 = bert_encoder_layer_0_attention_output_dropout + bert_embeddings_dropout;  bert_encoder_layer_0_attention_output_dropout = bert_embeddings_dropout = None\n",
      "    bert_encoder_layer_0_attention_output_layer_norm = getattr(self.bert.encoder.layer, \"0\").attention.output.LayerNorm(add_7);  add_7 = None\n",
      "    bert_encoder_layer_0_intermediate_dense = getattr(self.bert.encoder.layer, \"0\").intermediate.dense(bert_encoder_layer_0_attention_output_layer_norm)\n",
      "    gelu = torch._C._nn.gelu(bert_encoder_layer_0_intermediate_dense);  bert_encoder_layer_0_intermediate_dense = None\n",
      "    bert_encoder_layer_0_output_dense = getattr(self.bert.encoder.layer, \"0\").output.dense(gelu);  gelu = None\n",
      "    bert_encoder_layer_0_output_dropout = getattr(self.bert.encoder.layer, \"0\").output.dropout(bert_encoder_layer_0_output_dense);  bert_encoder_layer_0_output_dense = None\n",
      "    add_8 = bert_encoder_layer_0_output_dropout + bert_encoder_layer_0_attention_output_layer_norm;  bert_encoder_layer_0_output_dropout = bert_encoder_layer_0_attention_output_layer_norm = None\n",
      "    bert_encoder_layer_0_output_layer_norm = getattr(self.bert.encoder.layer, \"0\").output.LayerNorm(add_8);  add_8 = None\n",
      "    size_8 = bert_encoder_layer_0_output_layer_norm.size()\n",
      "    getitem_16 = size_8[0]\n",
      "    getitem_17 = size_8[1]\n",
      "    getitem_18 = size_8[2];  size_8 = getitem_18 = None\n",
      "    bert_encoder_layer_1_attention_self_query = getattr(self.bert.encoder.layer, \"1\").attention.self.query(bert_encoder_layer_0_output_layer_norm)\n",
      "    size_9 = bert_encoder_layer_1_attention_self_query.size()\n",
      "    getitem_19 = size_9[slice(None, -1, None)];  size_9 = None\n",
      "    add_9 = getitem_19 + (2, 64);  getitem_19 = None\n",
      "    view_3 = bert_encoder_layer_1_attention_self_query.view(add_9);  bert_encoder_layer_1_attention_self_query = add_9 = None\n",
      "    permute_3 = view_3.permute(0, 2, 1, 3);  view_3 = None\n",
      "    bert_encoder_layer_1_attention_self_key = getattr(self.bert.encoder.layer, \"1\").attention.self.key(bert_encoder_layer_0_output_layer_norm)\n",
      "    size_10 = bert_encoder_layer_1_attention_self_key.size()\n",
      "    getitem_20 = size_10[slice(None, -1, None)];  size_10 = None\n",
      "    add_10 = getitem_20 + (2, 64);  getitem_20 = None\n",
      "    view_4 = bert_encoder_layer_1_attention_self_key.view(add_10);  bert_encoder_layer_1_attention_self_key = add_10 = None\n",
      "    permute_4 = view_4.permute(0, 2, 1, 3);  view_4 = None\n",
      "    bert_encoder_layer_1_attention_self_value = getattr(self.bert.encoder.layer, \"1\").attention.self.value(bert_encoder_layer_0_output_layer_norm)\n",
      "    size_11 = bert_encoder_layer_1_attention_self_value.size()\n",
      "    getitem_21 = size_11[slice(None, -1, None)];  size_11 = None\n",
      "    add_11 = getitem_21 + (2, 64);  getitem_21 = None\n",
      "    view_5 = bert_encoder_layer_1_attention_self_value.view(add_11);  bert_encoder_layer_1_attention_self_value = add_11 = None\n",
      "    permute_5 = view_5.permute(0, 2, 1, 3);  view_5 = None\n",
      "    scaled_dot_product_attention_1 = torch._C._nn.scaled_dot_product_attention(permute_3, permute_4, permute_5, attn_mask = masked_fill, dropout_p = 0.0, is_causal = False);  permute_3 = permute_4 = permute_5 = masked_fill = None\n",
      "    transpose_1 = scaled_dot_product_attention_1.transpose(1, 2);  scaled_dot_product_attention_1 = None\n",
      "    reshape_1 = transpose_1.reshape(getitem_16, getitem_17, 128);  transpose_1 = getitem_16 = getitem_17 = None\n",
      "    bert_encoder_layer_1_attention_output_dense = getattr(self.bert.encoder.layer, \"1\").attention.output.dense(reshape_1);  reshape_1 = None\n",
      "    bert_encoder_layer_1_attention_output_dropout = getattr(self.bert.encoder.layer, \"1\").attention.output.dropout(bert_encoder_layer_1_attention_output_dense);  bert_encoder_layer_1_attention_output_dense = None\n",
      "    add_12 = bert_encoder_layer_1_attention_output_dropout + bert_encoder_layer_0_output_layer_norm;  bert_encoder_layer_1_attention_output_dropout = bert_encoder_layer_0_output_layer_norm = None\n",
      "    bert_encoder_layer_1_attention_output_layer_norm = getattr(self.bert.encoder.layer, \"1\").attention.output.LayerNorm(add_12);  add_12 = None\n",
      "    bert_encoder_layer_1_intermediate_dense = getattr(self.bert.encoder.layer, \"1\").intermediate.dense(bert_encoder_layer_1_attention_output_layer_norm)\n",
      "    gelu_1 = torch._C._nn.gelu(bert_encoder_layer_1_intermediate_dense);  bert_encoder_layer_1_intermediate_dense = None\n",
      "    bert_encoder_layer_1_output_dense = getattr(self.bert.encoder.layer, \"1\").output.dense(gelu_1);  gelu_1 = None\n",
      "    bert_encoder_layer_1_output_dropout = getattr(self.bert.encoder.layer, \"1\").output.dropout(bert_encoder_layer_1_output_dense);  bert_encoder_layer_1_output_dense = None\n",
      "    add_13 = bert_encoder_layer_1_output_dropout + bert_encoder_layer_1_attention_output_layer_norm;  bert_encoder_layer_1_output_dropout = bert_encoder_layer_1_attention_output_layer_norm = None\n",
      "    bert_encoder_layer_1_output_layer_norm = getattr(self.bert.encoder.layer, \"1\").output.LayerNorm(add_13);  add_13 = None\n",
      "    getitem_22 = bert_encoder_layer_1_output_layer_norm[(slice(None, None, None), 0)];  bert_encoder_layer_1_output_layer_norm = None\n",
      "    bert_pooler_dense = self.bert.pooler.dense(getitem_22);  getitem_22 = None\n",
      "    bert_pooler_activation = self.bert.pooler.activation(bert_pooler_dense);  bert_pooler_dense = None\n",
      "    dropout = self.dropout(bert_pooler_activation);  bert_pooler_activation = None\n",
      "    classifier = self.classifier(dropout);  dropout = None\n",
      "    return {'logits': classifier}\n",
      "    \n",
      "# To see more debug info, please use `graph_module.print_readable()`\n",
      "wocao in add_common_metadata\n",
      "graph_iterator_for_metadata:  GraphModule(\n",
      "  (bert): Module(\n",
      "    (embeddings): Module(\n",
      "      (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
      "      (token_type_embeddings): Embedding(2, 128)\n",
      "      (position_embeddings): Embedding(512, 128)\n",
      "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): Module(\n",
      "      (layer): Module(\n",
      "        (0): Module(\n",
      "          (attention): Module(\n",
      "            (self): Module(\n",
      "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (value): Linear(in_features=128, out_features=128, bias=True)\n",
      "            )\n",
      "            (output): Module(\n",
      "              (dense): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): Module(\n",
      "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
      "          )\n",
      "          (output): Module(\n",
      "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Module(\n",
      "          (attention): Module(\n",
      "            (self): Module(\n",
      "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (value): Linear(in_features=128, out_features=128, bias=True)\n",
      "            )\n",
      "            (output): Module(\n",
      "              (dense): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): Module(\n",
      "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
      "          )\n",
      "          (output): Module(\n",
      "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): Module(\n",
      "      (dense): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): Linear(in_features=128, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "def forward(self, input_ids : torch.Tensor):\n",
      "    size = input_ids.size()\n",
      "    getitem = size[0]\n",
      "    getitem_1 = size[1];  size = None\n",
      "    bert_embeddings_token_type_ids = self.bert.embeddings.token_type_ids\n",
      "    getitem_2 = bert_embeddings_token_type_ids[(slice(None, None, None), slice(None, getitem_1, None))];  bert_embeddings_token_type_ids = None\n",
      "    expand = getitem_2.expand(getitem, getitem_1);  getitem_2 = None\n",
      "    size_1 = input_ids.size()\n",
      "    getitem_3 = size_1[1];  size_1 = None\n",
      "    bert_embeddings_position_ids = self.bert.embeddings.position_ids\n",
      "    add = getitem_3 + 0;  getitem_3 = None\n",
      "    getitem_4 = bert_embeddings_position_ids[(slice(None, None, None), slice(0, add, None))];  bert_embeddings_position_ids = add = None\n",
      "    bert_embeddings_word_embeddings = self.bert.embeddings.word_embeddings(input_ids)\n",
      "    bert_embeddings_token_type_embeddings = self.bert.embeddings.token_type_embeddings(expand);  expand = None\n",
      "    add_1 = bert_embeddings_word_embeddings + bert_embeddings_token_type_embeddings;  bert_embeddings_word_embeddings = bert_embeddings_token_type_embeddings = None\n",
      "    bert_embeddings_position_embeddings = self.bert.embeddings.position_embeddings(getitem_4);  getitem_4 = None\n",
      "    add_2 = add_1 + bert_embeddings_position_embeddings;  add_1 = bert_embeddings_position_embeddings = None\n",
      "    bert_embeddings_layer_norm = self.bert.embeddings.LayerNorm(add_2);  add_2 = None\n",
      "    bert_embeddings_dropout = self.bert.embeddings.dropout(bert_embeddings_layer_norm);  bert_embeddings_layer_norm = None\n",
      "    add_3 = getitem_1 + 0\n",
      "    getattr_1 = input_ids.device;  input_ids = None\n",
      "    ones = torch.ones((getitem, add_3), device = getattr_1);  getitem = add_3 = getattr_1 = None\n",
      "    dim = ones.dim()\n",
      "    eq = dim == 2;  dim = eq = None\n",
      "    size_2 = ones.size()\n",
      "    getitem_5 = size_2[0];  getitem_5 = None\n",
      "    getitem_6 = size_2[1];  size_2 = getitem_6 = None\n",
      "    size_3 = ones.size()\n",
      "    getitem_7 = size_3[0]\n",
      "    getitem_8 = size_3[1];  size_3 = None\n",
      "    getitem_9 = ones[(slice(None, None, None), None, None, slice(None, None, None))];  ones = None\n",
      "    expand_1 = getitem_9.expand(getitem_7, 1, getitem_1, getitem_8);  getitem_9 = getitem_7 = getitem_1 = getitem_8 = None\n",
      "    getattr_2 = bert_embeddings_dropout.dtype\n",
      "    to = expand_1.to(getattr_2);  expand_1 = None\n",
      "    sub = 1.0 - to;  to = None\n",
      "    to_1 = sub.to(torch.bool)\n",
      "    finfo = torch.finfo(getattr_2);  getattr_2 = None\n",
      "    getattr_3 = finfo.min;  finfo = None\n",
      "    masked_fill = sub.masked_fill(to_1, getattr_3);  sub = to_1 = getattr_3 = None\n",
      "    size_4 = bert_embeddings_dropout.size()\n",
      "    getitem_10 = size_4[0]\n",
      "    getitem_11 = size_4[1]\n",
      "    getitem_12 = size_4[2];  size_4 = getitem_12 = None\n",
      "    bert_encoder_layer_0_attention_self_query = getattr(self.bert.encoder.layer, \"0\").attention.self.query(bert_embeddings_dropout)\n",
      "    size_5 = bert_encoder_layer_0_attention_self_query.size()\n",
      "    getitem_13 = size_5[slice(None, -1, None)];  size_5 = None\n",
      "    add_4 = getitem_13 + (2, 64);  getitem_13 = None\n",
      "    view = bert_encoder_layer_0_attention_self_query.view(add_4);  bert_encoder_layer_0_attention_self_query = add_4 = None\n",
      "    permute = view.permute(0, 2, 1, 3);  view = None\n",
      "    bert_encoder_layer_0_attention_self_key = getattr(self.bert.encoder.layer, \"0\").attention.self.key(bert_embeddings_dropout)\n",
      "    size_6 = bert_encoder_layer_0_attention_self_key.size()\n",
      "    getitem_14 = size_6[slice(None, -1, None)];  size_6 = None\n",
      "    add_5 = getitem_14 + (2, 64);  getitem_14 = None\n",
      "    view_1 = bert_encoder_layer_0_attention_self_key.view(add_5);  bert_encoder_layer_0_attention_self_key = add_5 = None\n",
      "    permute_1 = view_1.permute(0, 2, 1, 3);  view_1 = None\n",
      "    bert_encoder_layer_0_attention_self_value = getattr(self.bert.encoder.layer, \"0\").attention.self.value(bert_embeddings_dropout)\n",
      "    size_7 = bert_encoder_layer_0_attention_self_value.size()\n",
      "    getitem_15 = size_7[slice(None, -1, None)];  size_7 = None\n",
      "    add_6 = getitem_15 + (2, 64);  getitem_15 = None\n",
      "    view_2 = bert_encoder_layer_0_attention_self_value.view(add_6);  bert_encoder_layer_0_attention_self_value = add_6 = None\n",
      "    permute_2 = view_2.permute(0, 2, 1, 3);  view_2 = None\n",
      "    scaled_dot_product_attention = torch._C._nn.scaled_dot_product_attention(permute, permute_1, permute_2, attn_mask = masked_fill, dropout_p = 0.0, is_causal = False);  permute = permute_1 = permute_2 = None\n",
      "    transpose = scaled_dot_product_attention.transpose(1, 2);  scaled_dot_product_attention = None\n",
      "    reshape = transpose.reshape(getitem_10, getitem_11, 128);  transpose = getitem_10 = getitem_11 = None\n",
      "    bert_encoder_layer_0_attention_output_dense = getattr(self.bert.encoder.layer, \"0\").attention.output.dense(reshape);  reshape = None\n",
      "    bert_encoder_layer_0_attention_output_dropout = getattr(self.bert.encoder.layer, \"0\").attention.output.dropout(bert_encoder_layer_0_attention_output_dense);  bert_encoder_layer_0_attention_output_dense = None\n",
      "    add_7 = bert_encoder_layer_0_attention_output_dropout + bert_embeddings_dropout;  bert_encoder_layer_0_attention_output_dropout = bert_embeddings_dropout = None\n",
      "    bert_encoder_layer_0_attention_output_layer_norm = getattr(self.bert.encoder.layer, \"0\").attention.output.LayerNorm(add_7);  add_7 = None\n",
      "    bert_encoder_layer_0_intermediate_dense = getattr(self.bert.encoder.layer, \"0\").intermediate.dense(bert_encoder_layer_0_attention_output_layer_norm)\n",
      "    gelu = torch._C._nn.gelu(bert_encoder_layer_0_intermediate_dense);  bert_encoder_layer_0_intermediate_dense = None\n",
      "    bert_encoder_layer_0_output_dense = getattr(self.bert.encoder.layer, \"0\").output.dense(gelu);  gelu = None\n",
      "    bert_encoder_layer_0_output_dropout = getattr(self.bert.encoder.layer, \"0\").output.dropout(bert_encoder_layer_0_output_dense);  bert_encoder_layer_0_output_dense = None\n",
      "    add_8 = bert_encoder_layer_0_output_dropout + bert_encoder_layer_0_attention_output_layer_norm;  bert_encoder_layer_0_output_dropout = bert_encoder_layer_0_attention_output_layer_norm = None\n",
      "    bert_encoder_layer_0_output_layer_norm = getattr(self.bert.encoder.layer, \"0\").output.LayerNorm(add_8);  add_8 = None\n",
      "    size_8 = bert_encoder_layer_0_output_layer_norm.size()\n",
      "    getitem_16 = size_8[0]\n",
      "    getitem_17 = size_8[1]\n",
      "    getitem_18 = size_8[2];  size_8 = getitem_18 = None\n",
      "    bert_encoder_layer_1_attention_self_query = getattr(self.bert.encoder.layer, \"1\").attention.self.query(bert_encoder_layer_0_output_layer_norm)\n",
      "    size_9 = bert_encoder_layer_1_attention_self_query.size()\n",
      "    getitem_19 = size_9[slice(None, -1, None)];  size_9 = None\n",
      "    add_9 = getitem_19 + (2, 64);  getitem_19 = None\n",
      "    view_3 = bert_encoder_layer_1_attention_self_query.view(add_9);  bert_encoder_layer_1_attention_self_query = add_9 = None\n",
      "    permute_3 = view_3.permute(0, 2, 1, 3);  view_3 = None\n",
      "    bert_encoder_layer_1_attention_self_key = getattr(self.bert.encoder.layer, \"1\").attention.self.key(bert_encoder_layer_0_output_layer_norm)\n",
      "    size_10 = bert_encoder_layer_1_attention_self_key.size()\n",
      "    getitem_20 = size_10[slice(None, -1, None)];  size_10 = None\n",
      "    add_10 = getitem_20 + (2, 64);  getitem_20 = None\n",
      "    view_4 = bert_encoder_layer_1_attention_self_key.view(add_10);  bert_encoder_layer_1_attention_self_key = add_10 = None\n",
      "    permute_4 = view_4.permute(0, 2, 1, 3);  view_4 = None\n",
      "    bert_encoder_layer_1_attention_self_value = getattr(self.bert.encoder.layer, \"1\").attention.self.value(bert_encoder_layer_0_output_layer_norm)\n",
      "    size_11 = bert_encoder_layer_1_attention_self_value.size()\n",
      "    getitem_21 = size_11[slice(None, -1, None)];  size_11 = None\n",
      "    add_11 = getitem_21 + (2, 64);  getitem_21 = None\n",
      "    view_5 = bert_encoder_layer_1_attention_self_value.view(add_11);  bert_encoder_layer_1_attention_self_value = add_11 = None\n",
      "    permute_5 = view_5.permute(0, 2, 1, 3);  view_5 = None\n",
      "    scaled_dot_product_attention_1 = torch._C._nn.scaled_dot_product_attention(permute_3, permute_4, permute_5, attn_mask = masked_fill, dropout_p = 0.0, is_causal = False);  permute_3 = permute_4 = permute_5 = masked_fill = None\n",
      "    transpose_1 = scaled_dot_product_attention_1.transpose(1, 2);  scaled_dot_product_attention_1 = None\n",
      "    reshape_1 = transpose_1.reshape(getitem_16, getitem_17, 128);  transpose_1 = getitem_16 = getitem_17 = None\n",
      "    bert_encoder_layer_1_attention_output_dense = getattr(self.bert.encoder.layer, \"1\").attention.output.dense(reshape_1);  reshape_1 = None\n",
      "    bert_encoder_layer_1_attention_output_dropout = getattr(self.bert.encoder.layer, \"1\").attention.output.dropout(bert_encoder_layer_1_attention_output_dense);  bert_encoder_layer_1_attention_output_dense = None\n",
      "    add_12 = bert_encoder_layer_1_attention_output_dropout + bert_encoder_layer_0_output_layer_norm;  bert_encoder_layer_1_attention_output_dropout = bert_encoder_layer_0_output_layer_norm = None\n",
      "    bert_encoder_layer_1_attention_output_layer_norm = getattr(self.bert.encoder.layer, \"1\").attention.output.LayerNorm(add_12);  add_12 = None\n",
      "    bert_encoder_layer_1_intermediate_dense = getattr(self.bert.encoder.layer, \"1\").intermediate.dense(bert_encoder_layer_1_attention_output_layer_norm)\n",
      "    gelu_1 = torch._C._nn.gelu(bert_encoder_layer_1_intermediate_dense);  bert_encoder_layer_1_intermediate_dense = None\n",
      "    bert_encoder_layer_1_output_dense = getattr(self.bert.encoder.layer, \"1\").output.dense(gelu_1);  gelu_1 = None\n",
      "    bert_encoder_layer_1_output_dropout = getattr(self.bert.encoder.layer, \"1\").output.dropout(bert_encoder_layer_1_output_dense);  bert_encoder_layer_1_output_dense = None\n",
      "    add_13 = bert_encoder_layer_1_output_dropout + bert_encoder_layer_1_attention_output_layer_norm;  bert_encoder_layer_1_output_dropout = bert_encoder_layer_1_attention_output_layer_norm = None\n",
      "    bert_encoder_layer_1_output_layer_norm = getattr(self.bert.encoder.layer, \"1\").output.LayerNorm(add_13);  add_13 = None\n",
      "    getitem_22 = bert_encoder_layer_1_output_layer_norm[(slice(None, None, None), 0)];  bert_encoder_layer_1_output_layer_norm = None\n",
      "    bert_pooler_dense = self.bert.pooler.dense(getitem_22);  getitem_22 = None\n",
      "    bert_pooler_activation = self.bert.pooler.activation(bert_pooler_dense);  bert_pooler_dense = None\n",
      "    dropout = self.dropout(bert_pooler_activation);  bert_pooler_activation = None\n",
      "    classifier = self.classifier(dropout);  dropout = None\n",
      "    return {'logits': classifier}\n",
      "    \n",
      "# To see more debug info, please use `graph_module.print_readable()`\n",
      "kwargs:  {}\n",
      "kwargs:  {}\n",
      "kwargs:  {}\n",
      "kwargs:  {}\n",
      "kwargs:  {}\n",
      "kwargs:  {}\n",
      "kwargs:  {}\n",
      "kwargs:  {}\n",
      "kwargs:  {}\n",
      "args in call_module:  (tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]]),)\n",
      "kwargs in call_module:  {}\n",
      "HIIII from analyse_common_parameters_module\n",
      "args from analyse_common_parameters_module (tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]]),)\n",
      "kwargs from analyse_common_parameters_module {}\n",
      "meta before _annotate_arg_metadata: {'mase_type': 'implicit_func', 'mase_op': 'embedding'}\n",
      "kwargs:  {}\n",
      "meta after _annotate_arg_metadata: {'mase_type': 'implicit_func', 'mase_op': 'embedding', 'args': OrderedDict([('data_in_0', {'shape': [2, 10], 'torch_dtype': torch.int64, 'type': 'float', 'precision': [32]})])}\n",
      "meta after get_type_and_precision: {'mase_type': 'implicit_func', 'mase_op': 'embedding', 'args': OrderedDict([('data_in_0', {'shape': [2, 10], 'torch_dtype': torch.int64, 'type': 'float', 'precision': [32]})])}\n",
      "weight\n",
      "meta after for: {'mase_type': 'implicit_func', 'mase_op': 'embedding', 'args': OrderedDict([('data_in_0', {'shape': [2, 10], 'torch_dtype': torch.int64, 'type': 'float', 'precision': [32]}), ('weight', {'type': 'float', 'precision': [32], 'shape': [30522, 128], 'from': None})])}\n",
      "args in call_module:  (tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]),)\n",
      "kwargs in call_module:  {}\n",
      "HIIII from analyse_common_parameters_module\n",
      "args from analyse_common_parameters_module (tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]),)\n",
      "kwargs from analyse_common_parameters_module {}\n",
      "meta before _annotate_arg_metadata: {'mase_type': 'implicit_func', 'mase_op': 'embedding'}\n",
      "kwargs:  {}\n",
      "meta after _annotate_arg_metadata: {'mase_type': 'implicit_func', 'mase_op': 'embedding', 'args': OrderedDict([('data_in_0', {'shape': [2, 10], 'torch_dtype': torch.int64, 'type': 'float', 'precision': [32]})])}\n",
      "meta after get_type_and_precision: {'mase_type': 'implicit_func', 'mase_op': 'embedding', 'args': OrderedDict([('data_in_0', {'shape': [2, 10], 'torch_dtype': torch.int64, 'type': 'float', 'precision': [32]})])}\n",
      "weight\n",
      "meta after for: {'mase_type': 'implicit_func', 'mase_op': 'embedding', 'args': OrderedDict([('data_in_0', {'shape': [2, 10], 'torch_dtype': torch.int64, 'type': 'float', 'precision': [32]}), ('weight', {'type': 'float', 'precision': [32], 'shape': [2, 128], 'from': None})])}\n",
      "kwargs:  {}\n",
      "args in call_module:  (tensor([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]),)\n",
      "kwargs in call_module:  {}\n",
      "HIIII from analyse_common_parameters_module\n",
      "args from analyse_common_parameters_module (tensor([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]),)\n",
      "kwargs from analyse_common_parameters_module {}\n",
      "meta before _annotate_arg_metadata: {'mase_type': 'implicit_func', 'mase_op': 'embedding'}\n",
      "kwargs:  {}\n",
      "meta after _annotate_arg_metadata: {'mase_type': 'implicit_func', 'mase_op': 'embedding', 'args': OrderedDict([('data_in_0', {'shape': [1, 10], 'torch_dtype': torch.int64, 'type': 'float', 'precision': [32]})])}\n",
      "meta after get_type_and_precision: {'mase_type': 'implicit_func', 'mase_op': 'embedding', 'args': OrderedDict([('data_in_0', {'shape': [1, 10], 'torch_dtype': torch.int64, 'type': 'float', 'precision': [32]})])}\n",
      "weight\n",
      "meta after for: {'mase_type': 'implicit_func', 'mase_op': 'embedding', 'args': OrderedDict([('data_in_0', {'shape': [1, 10], 'torch_dtype': torch.int64, 'type': 'float', 'precision': [32]}), ('weight', {'type': 'float', 'precision': [32], 'shape': [512, 128], 'from': None})])}\n",
      "kwargs:  {}\n",
      "args in call_module:  (tensor([[[ 4.6347e-02, -1.8903e-02, -1.0256e+00,  ...,  1.0495e-01,\n",
      "          -2.4563e-02,  1.5784e-02],\n",
      "         [-5.7536e-02,  5.6336e-02, -7.4278e-02,  ...,  1.6174e-02,\n",
      "          -4.6758e-02,  6.0545e-02],\n",
      "         [-1.1717e-01,  1.5161e-02, -8.2376e-02,  ..., -3.9838e-02,\n",
      "          -5.7338e-03, -6.9560e-02],\n",
      "         ...,\n",
      "         [-1.1236e-02, -6.0448e-02,  3.4291e-02,  ..., -5.0723e-02,\n",
      "          -5.5016e-03, -2.4179e-02],\n",
      "         [-1.3988e-02, -6.5421e-02, -8.8415e-02,  ..., -1.0332e-01,\n",
      "           6.6438e-02,  1.6387e-02],\n",
      "         [-7.5427e-02,  2.6391e-02, -2.6982e-02,  ...,  8.9780e-03,\n",
      "          -4.3960e-02, -7.7567e-04]],\n",
      "\n",
      "        [[ 4.6347e-02, -1.8903e-02, -1.0256e+00,  ...,  1.0495e-01,\n",
      "          -2.4563e-02,  1.5784e-02],\n",
      "         [-1.2856e-01,  7.3375e-03, -4.7625e-02,  ..., -7.6186e-02,\n",
      "          -1.0503e-01, -1.4240e-01],\n",
      "         [-9.7862e-02,  1.5148e-02, -3.9056e-02,  ..., -4.4253e-02,\n",
      "          -9.6077e-02, -8.3552e-02],\n",
      "         ...,\n",
      "         [-1.3270e-02,  2.6168e-02,  7.7204e-02,  ..., -5.9771e-02,\n",
      "          -1.5935e-01,  2.7773e-02],\n",
      "         [ 1.0110e-01, -3.3438e-02,  4.0080e-02,  ..., -3.5608e-03,\n",
      "          -1.4410e-02,  1.4064e-01],\n",
      "         [-7.5427e-02,  2.6391e-02, -2.6982e-02,  ...,  8.9780e-03,\n",
      "          -4.3960e-02, -7.7567e-04]]], grad_fn=<AddBackward0>),)\n",
      "kwargs in call_module:  {}\n",
      "HIIII from analyse_common_parameters_module\n",
      "args from analyse_common_parameters_module (tensor([[[ 4.6347e-02, -1.8903e-02, -1.0256e+00,  ...,  1.0495e-01,\n",
      "          -2.4563e-02,  1.5784e-02],\n",
      "         [-5.7536e-02,  5.6336e-02, -7.4278e-02,  ...,  1.6174e-02,\n",
      "          -4.6758e-02,  6.0545e-02],\n",
      "         [-1.1717e-01,  1.5161e-02, -8.2376e-02,  ..., -3.9838e-02,\n",
      "          -5.7338e-03, -6.9560e-02],\n",
      "         ...,\n",
      "         [-1.1236e-02, -6.0448e-02,  3.4291e-02,  ..., -5.0723e-02,\n",
      "          -5.5016e-03, -2.4179e-02],\n",
      "         [-1.3988e-02, -6.5421e-02, -8.8415e-02,  ..., -1.0332e-01,\n",
      "           6.6438e-02,  1.6387e-02],\n",
      "         [-7.5427e-02,  2.6391e-02, -2.6982e-02,  ...,  8.9780e-03,\n",
      "          -4.3960e-02, -7.7567e-04]],\n",
      "\n",
      "        [[ 4.6347e-02, -1.8903e-02, -1.0256e+00,  ...,  1.0495e-01,\n",
      "          -2.4563e-02,  1.5784e-02],\n",
      "         [-1.2856e-01,  7.3375e-03, -4.7625e-02,  ..., -7.6186e-02,\n",
      "          -1.0503e-01, -1.4240e-01],\n",
      "         [-9.7862e-02,  1.5148e-02, -3.9056e-02,  ..., -4.4253e-02,\n",
      "          -9.6077e-02, -8.3552e-02],\n",
      "         ...,\n",
      "         [-1.3270e-02,  2.6168e-02,  7.7204e-02,  ..., -5.9771e-02,\n",
      "          -1.5935e-01,  2.7773e-02],\n",
      "         [ 1.0110e-01, -3.3438e-02,  4.0080e-02,  ..., -3.5608e-03,\n",
      "          -1.4410e-02,  1.4064e-01],\n",
      "         [-7.5427e-02,  2.6391e-02, -2.6982e-02,  ...,  8.9780e-03,\n",
      "          -4.3960e-02, -7.7567e-04]]], grad_fn=<AddBackward0>),)\n",
      "kwargs from analyse_common_parameters_module {}\n",
      "meta before _annotate_arg_metadata: {'mase_type': 'module_related_func', 'mase_op': 'layer_norm'}\n",
      "kwargs:  {}\n",
      "meta after _annotate_arg_metadata: {'mase_type': 'module_related_func', 'mase_op': 'layer_norm', 'args': OrderedDict([('data_in_0', {'shape': [2, 10, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]})])}\n",
      "meta after get_type_and_precision: {'mase_type': 'module_related_func', 'mase_op': 'layer_norm', 'args': OrderedDict([('data_in_0', {'shape': [2, 10, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]})])}\n",
      "weight\n",
      "bias\n",
      "meta after for: {'mase_type': 'module_related_func', 'mase_op': 'layer_norm', 'args': OrderedDict([('data_in_0', {'shape': [2, 10, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]}), ('weight', {'type': 'float', 'precision': [32], 'shape': [1, 128], 'from': None}), ('bias', {'type': 'float', 'precision': [32], 'shape': [1, 128], 'from': None})])}\n",
      "args in call_module:  (tensor([[[ 0.7973,  0.0109, -8.8405,  ...,  1.4170,  0.1046, -0.1551],\n",
      "         [-1.1766,  1.2879, -1.0986,  ...,  0.4749, -0.5899,  0.8746],\n",
      "         [-2.0560,  0.7748, -0.8909,  ..., -0.4034,  0.5352, -1.3657],\n",
      "         ...,\n",
      "         [ 0.2317, -0.7896,  0.9634,  ..., -0.8037,  0.4834, -0.5868],\n",
      "         [ 0.0243, -1.0235, -1.2771,  ..., -2.2378,  1.8530,  0.1558],\n",
      "         [-1.3637,  0.7055, -0.2177,  ...,  0.3557, -0.3971, -0.3107]],\n",
      "\n",
      "        [[ 0.7973,  0.0109, -8.8405,  ...,  1.4170,  0.1046, -0.1551],\n",
      "         [-2.6940,  0.6198, -0.4564,  ..., -1.4367, -1.5705, -3.1260],\n",
      "         [-1.7524,  0.8535, -0.2155,  ..., -0.5222, -1.2430, -1.7199],\n",
      "         ...,\n",
      "         [-0.0347,  0.7446,  1.4462,  ..., -1.1578, -2.6197,  0.2612],\n",
      "         [ 2.4334, -0.3068,  0.8250,  ...,  0.1475,  0.1790,  2.2907],\n",
      "         [-1.3637,  0.7055, -0.2177,  ...,  0.3557, -0.3971, -0.3107]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>),)\n",
      "kwargs in call_module:  {}\n",
      "HIIII from analyse_common_parameters_module\n",
      "args from analyse_common_parameters_module (tensor([[[ 0.7973,  0.0109, -8.8405,  ...,  1.4170,  0.1046, -0.1551],\n",
      "         [-1.1766,  1.2879, -1.0986,  ...,  0.4749, -0.5899,  0.8746],\n",
      "         [-2.0560,  0.7748, -0.8909,  ..., -0.4034,  0.5352, -1.3657],\n",
      "         ...,\n",
      "         [ 0.2317, -0.7896,  0.9634,  ..., -0.8037,  0.4834, -0.5868],\n",
      "         [ 0.0243, -1.0235, -1.2771,  ..., -2.2378,  1.8530,  0.1558],\n",
      "         [-1.3637,  0.7055, -0.2177,  ...,  0.3557, -0.3971, -0.3107]],\n",
      "\n",
      "        [[ 0.7973,  0.0109, -8.8405,  ...,  1.4170,  0.1046, -0.1551],\n",
      "         [-2.6940,  0.6198, -0.4564,  ..., -1.4367, -1.5705, -3.1260],\n",
      "         [-1.7524,  0.8535, -0.2155,  ..., -0.5222, -1.2430, -1.7199],\n",
      "         ...,\n",
      "         [-0.0347,  0.7446,  1.4462,  ..., -1.1578, -2.6197,  0.2612],\n",
      "         [ 2.4334, -0.3068,  0.8250,  ...,  0.1475,  0.1790,  2.2907],\n",
      "         [-1.3637,  0.7055, -0.2177,  ...,  0.3557, -0.3971, -0.3107]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>),)\n",
      "kwargs from analyse_common_parameters_module {}\n",
      "meta before _annotate_arg_metadata: {'mase_type': 'module_related_func', 'mase_op': 'dropout'}\n",
      "kwargs:  {}\n",
      "meta after _annotate_arg_metadata: {'mase_type': 'module_related_func', 'mase_op': 'dropout', 'args': OrderedDict([('data_in_0', {'shape': [2, 10, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]})])}\n",
      "meta after get_type_and_precision: {'mase_type': 'module_related_func', 'mase_op': 'dropout', 'args': OrderedDict([('data_in_0', {'shape': [2, 10, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]})])}\n",
      "meta after for: {'mase_type': 'module_related_func', 'mase_op': 'dropout', 'args': OrderedDict([('data_in_0', {'shape': [2, 10, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]})])}\n",
      "kwargs:  {}\n",
      "kwargs:  {}\n",
      "kwargs:  {'device': device(type='cpu')}\n",
      "kwargs:  {}\n",
      "kwargs:  {}\n",
      "kwargs:  {}\n",
      "kwargs:  {}\n",
      "kwargs:  {}\n",
      "kwargs:  {}\n",
      "kwargs:  {}\n",
      "kwargs:  {}\n",
      "kwargs:  {}\n",
      "kwargs:  {}\n",
      "kwargs:  {}\n",
      "kwargs:  {}\n",
      "kwargs:  {}\n",
      "kwargs:  {}\n",
      "kwargs:  {}\n",
      "kwargs:  {}\n",
      "kwargs:  {}\n",
      "kwargs:  {}\n",
      "kwargs:  {}\n",
      "kwargs:  {}\n",
      "kwargs:  {}\n",
      "args in call_module:  (tensor([[[ 0.7973,  0.0109, -8.8405,  ...,  1.4170,  0.1046, -0.1551],\n",
      "         [-1.1766,  1.2879, -1.0986,  ...,  0.4749, -0.5899,  0.8746],\n",
      "         [-2.0560,  0.7748, -0.8909,  ..., -0.4034,  0.5352, -1.3657],\n",
      "         ...,\n",
      "         [ 0.2317, -0.7896,  0.9634,  ..., -0.8037,  0.4834, -0.5868],\n",
      "         [ 0.0243, -1.0235, -1.2771,  ..., -2.2378,  1.8530,  0.1558],\n",
      "         [-1.3637,  0.7055, -0.2177,  ...,  0.3557, -0.3971, -0.3107]],\n",
      "\n",
      "        [[ 0.7973,  0.0109, -8.8405,  ...,  1.4170,  0.1046, -0.1551],\n",
      "         [-2.6940,  0.6198, -0.4564,  ..., -1.4367, -1.5705, -3.1260],\n",
      "         [-1.7524,  0.8535, -0.2155,  ..., -0.5222, -1.2430, -1.7199],\n",
      "         ...,\n",
      "         [-0.0347,  0.7446,  1.4462,  ..., -1.1578, -2.6197,  0.2612],\n",
      "         [ 2.4334, -0.3068,  0.8250,  ...,  0.1475,  0.1790,  2.2907],\n",
      "         [-1.3637,  0.7055, -0.2177,  ...,  0.3557, -0.3971, -0.3107]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>),)\n",
      "kwargs in call_module:  {}\n",
      "HIIII from analyse_common_parameters_module\n",
      "args from analyse_common_parameters_module (tensor([[[ 0.7973,  0.0109, -8.8405,  ...,  1.4170,  0.1046, -0.1551],\n",
      "         [-1.1766,  1.2879, -1.0986,  ...,  0.4749, -0.5899,  0.8746],\n",
      "         [-2.0560,  0.7748, -0.8909,  ..., -0.4034,  0.5352, -1.3657],\n",
      "         ...,\n",
      "         [ 0.2317, -0.7896,  0.9634,  ..., -0.8037,  0.4834, -0.5868],\n",
      "         [ 0.0243, -1.0235, -1.2771,  ..., -2.2378,  1.8530,  0.1558],\n",
      "         [-1.3637,  0.7055, -0.2177,  ...,  0.3557, -0.3971, -0.3107]],\n",
      "\n",
      "        [[ 0.7973,  0.0109, -8.8405,  ...,  1.4170,  0.1046, -0.1551],\n",
      "         [-2.6940,  0.6198, -0.4564,  ..., -1.4367, -1.5705, -3.1260],\n",
      "         [-1.7524,  0.8535, -0.2155,  ..., -0.5222, -1.2430, -1.7199],\n",
      "         ...,\n",
      "         [-0.0347,  0.7446,  1.4462,  ..., -1.1578, -2.6197,  0.2612],\n",
      "         [ 2.4334, -0.3068,  0.8250,  ...,  0.1475,  0.1790,  2.2907],\n",
      "         [-1.3637,  0.7055, -0.2177,  ...,  0.3557, -0.3971, -0.3107]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>),)\n",
      "kwargs from analyse_common_parameters_module {}\n",
      "meta before _annotate_arg_metadata: {'mase_type': 'module_related_func', 'mase_op': 'linear'}\n",
      "kwargs:  {}\n",
      "meta after _annotate_arg_metadata: {'mase_type': 'module_related_func', 'mase_op': 'linear', 'args': OrderedDict([('data_in_0', {'shape': [2, 10, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]})])}\n",
      "meta after get_type_and_precision: {'mase_type': 'module_related_func', 'mase_op': 'linear', 'args': OrderedDict([('data_in_0', {'shape': [2, 10, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]})])}\n",
      "weight\n",
      "bias\n",
      "meta after for: {'mase_type': 'module_related_func', 'mase_op': 'linear', 'args': OrderedDict([('data_in_0', {'shape': [2, 10, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]}), ('weight', {'type': 'float', 'precision': [32], 'shape': [128, 128], 'from': None}), ('bias', {'type': 'float', 'precision': [32], 'shape': [1, 128], 'from': None})])}\n",
      "kwargs:  {}\n",
      "kwargs:  {}\n",
      "kwargs:  {}\n",
      "kwargs:  {}\n",
      "kwargs:  {}\n",
      "args in call_module:  (tensor([[[ 0.7973,  0.0109, -8.8405,  ...,  1.4170,  0.1046, -0.1551],\n",
      "         [-1.1766,  1.2879, -1.0986,  ...,  0.4749, -0.5899,  0.8746],\n",
      "         [-2.0560,  0.7748, -0.8909,  ..., -0.4034,  0.5352, -1.3657],\n",
      "         ...,\n",
      "         [ 0.2317, -0.7896,  0.9634,  ..., -0.8037,  0.4834, -0.5868],\n",
      "         [ 0.0243, -1.0235, -1.2771,  ..., -2.2378,  1.8530,  0.1558],\n",
      "         [-1.3637,  0.7055, -0.2177,  ...,  0.3557, -0.3971, -0.3107]],\n",
      "\n",
      "        [[ 0.7973,  0.0109, -8.8405,  ...,  1.4170,  0.1046, -0.1551],\n",
      "         [-2.6940,  0.6198, -0.4564,  ..., -1.4367, -1.5705, -3.1260],\n",
      "         [-1.7524,  0.8535, -0.2155,  ..., -0.5222, -1.2430, -1.7199],\n",
      "         ...,\n",
      "         [-0.0347,  0.7446,  1.4462,  ..., -1.1578, -2.6197,  0.2612],\n",
      "         [ 2.4334, -0.3068,  0.8250,  ...,  0.1475,  0.1790,  2.2907],\n",
      "         [-1.3637,  0.7055, -0.2177,  ...,  0.3557, -0.3971, -0.3107]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>),)\n",
      "kwargs in call_module:  {}\n",
      "HIIII from analyse_common_parameters_module\n",
      "args from analyse_common_parameters_module (tensor([[[ 0.7973,  0.0109, -8.8405,  ...,  1.4170,  0.1046, -0.1551],\n",
      "         [-1.1766,  1.2879, -1.0986,  ...,  0.4749, -0.5899,  0.8746],\n",
      "         [-2.0560,  0.7748, -0.8909,  ..., -0.4034,  0.5352, -1.3657],\n",
      "         ...,\n",
      "         [ 0.2317, -0.7896,  0.9634,  ..., -0.8037,  0.4834, -0.5868],\n",
      "         [ 0.0243, -1.0235, -1.2771,  ..., -2.2378,  1.8530,  0.1558],\n",
      "         [-1.3637,  0.7055, -0.2177,  ...,  0.3557, -0.3971, -0.3107]],\n",
      "\n",
      "        [[ 0.7973,  0.0109, -8.8405,  ...,  1.4170,  0.1046, -0.1551],\n",
      "         [-2.6940,  0.6198, -0.4564,  ..., -1.4367, -1.5705, -3.1260],\n",
      "         [-1.7524,  0.8535, -0.2155,  ..., -0.5222, -1.2430, -1.7199],\n",
      "         ...,\n",
      "         [-0.0347,  0.7446,  1.4462,  ..., -1.1578, -2.6197,  0.2612],\n",
      "         [ 2.4334, -0.3068,  0.8250,  ...,  0.1475,  0.1790,  2.2907],\n",
      "         [-1.3637,  0.7055, -0.2177,  ...,  0.3557, -0.3971, -0.3107]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>),)\n",
      "kwargs from analyse_common_parameters_module {}\n",
      "meta before _annotate_arg_metadata: {'mase_type': 'module_related_func', 'mase_op': 'linear'}\n",
      "kwargs:  {}\n",
      "meta after _annotate_arg_metadata: {'mase_type': 'module_related_func', 'mase_op': 'linear', 'args': OrderedDict([('data_in_0', {'shape': [2, 10, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]})])}\n",
      "meta after get_type_and_precision: {'mase_type': 'module_related_func', 'mase_op': 'linear', 'args': OrderedDict([('data_in_0', {'shape': [2, 10, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]})])}\n",
      "weight\n",
      "bias\n",
      "meta after for: {'mase_type': 'module_related_func', 'mase_op': 'linear', 'args': OrderedDict([('data_in_0', {'shape': [2, 10, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]}), ('weight', {'type': 'float', 'precision': [32], 'shape': [128, 128], 'from': None}), ('bias', {'type': 'float', 'precision': [32], 'shape': [1, 128], 'from': None})])}\n",
      "kwargs:  {}\n",
      "kwargs:  {}\n",
      "kwargs:  {}\n",
      "kwargs:  {}\n",
      "kwargs:  {}\n",
      "args in call_module:  (tensor([[[ 0.7973,  0.0109, -8.8405,  ...,  1.4170,  0.1046, -0.1551],\n",
      "         [-1.1766,  1.2879, -1.0986,  ...,  0.4749, -0.5899,  0.8746],\n",
      "         [-2.0560,  0.7748, -0.8909,  ..., -0.4034,  0.5352, -1.3657],\n",
      "         ...,\n",
      "         [ 0.2317, -0.7896,  0.9634,  ..., -0.8037,  0.4834, -0.5868],\n",
      "         [ 0.0243, -1.0235, -1.2771,  ..., -2.2378,  1.8530,  0.1558],\n",
      "         [-1.3637,  0.7055, -0.2177,  ...,  0.3557, -0.3971, -0.3107]],\n",
      "\n",
      "        [[ 0.7973,  0.0109, -8.8405,  ...,  1.4170,  0.1046, -0.1551],\n",
      "         [-2.6940,  0.6198, -0.4564,  ..., -1.4367, -1.5705, -3.1260],\n",
      "         [-1.7524,  0.8535, -0.2155,  ..., -0.5222, -1.2430, -1.7199],\n",
      "         ...,\n",
      "         [-0.0347,  0.7446,  1.4462,  ..., -1.1578, -2.6197,  0.2612],\n",
      "         [ 2.4334, -0.3068,  0.8250,  ...,  0.1475,  0.1790,  2.2907],\n",
      "         [-1.3637,  0.7055, -0.2177,  ...,  0.3557, -0.3971, -0.3107]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>),)\n",
      "kwargs in call_module:  {}\n",
      "HIIII from analyse_common_parameters_module\n",
      "args from analyse_common_parameters_module (tensor([[[ 0.7973,  0.0109, -8.8405,  ...,  1.4170,  0.1046, -0.1551],\n",
      "         [-1.1766,  1.2879, -1.0986,  ...,  0.4749, -0.5899,  0.8746],\n",
      "         [-2.0560,  0.7748, -0.8909,  ..., -0.4034,  0.5352, -1.3657],\n",
      "         ...,\n",
      "         [ 0.2317, -0.7896,  0.9634,  ..., -0.8037,  0.4834, -0.5868],\n",
      "         [ 0.0243, -1.0235, -1.2771,  ..., -2.2378,  1.8530,  0.1558],\n",
      "         [-1.3637,  0.7055, -0.2177,  ...,  0.3557, -0.3971, -0.3107]],\n",
      "\n",
      "        [[ 0.7973,  0.0109, -8.8405,  ...,  1.4170,  0.1046, -0.1551],\n",
      "         [-2.6940,  0.6198, -0.4564,  ..., -1.4367, -1.5705, -3.1260],\n",
      "         [-1.7524,  0.8535, -0.2155,  ..., -0.5222, -1.2430, -1.7199],\n",
      "         ...,\n",
      "         [-0.0347,  0.7446,  1.4462,  ..., -1.1578, -2.6197,  0.2612],\n",
      "         [ 2.4334, -0.3068,  0.8250,  ...,  0.1475,  0.1790,  2.2907],\n",
      "         [-1.3637,  0.7055, -0.2177,  ...,  0.3557, -0.3971, -0.3107]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>),)\n",
      "kwargs from analyse_common_parameters_module {}\n",
      "meta before _annotate_arg_metadata: {'mase_type': 'module_related_func', 'mase_op': 'linear'}\n",
      "kwargs:  {}\n",
      "meta after _annotate_arg_metadata: {'mase_type': 'module_related_func', 'mase_op': 'linear', 'args': OrderedDict([('data_in_0', {'shape': [2, 10, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]})])}\n",
      "meta after get_type_and_precision: {'mase_type': 'module_related_func', 'mase_op': 'linear', 'args': OrderedDict([('data_in_0', {'shape': [2, 10, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]})])}\n",
      "weight\n",
      "bias\n",
      "meta after for: {'mase_type': 'module_related_func', 'mase_op': 'linear', 'args': OrderedDict([('data_in_0', {'shape': [2, 10, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]}), ('weight', {'type': 'float', 'precision': [32], 'shape': [128, 128], 'from': None}), ('bias', {'type': 'float', 'precision': [32], 'shape': [1, 128], 'from': None})])}\n",
      "kwargs:  {}\n",
      "kwargs:  {}\n",
      "kwargs:  {}\n",
      "kwargs:  {}\n",
      "kwargs:  {}\n",
      "kwargs:  {'attn_mask': tensor([[[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]]), 'dropout_p': 0.0, 'is_causal': False}\n",
      "kwargs:  {}\n",
      "kwargs:  {}\n",
      "args in call_module:  (tensor([[[-0.5911, -0.4682, -0.4314,  ...,  0.1677,  0.3883,  0.4382],\n",
      "         [-1.1141, -1.4785, -0.6477,  ...,  0.2989, -0.1569,  0.9508],\n",
      "         [-0.7059, -0.9954, -1.3923,  ...,  0.0258, -0.0364,  0.9990],\n",
      "         ...,\n",
      "         [-0.6300,  0.1252,  0.3486,  ..., -0.1261,  0.2908,  1.0980],\n",
      "         [-1.0593, -0.6395, -0.3343,  ...,  0.2486,  0.4005,  0.6046],\n",
      "         [-0.2081,  0.2785,  0.0613,  ...,  0.1182,  0.4294,  0.4781]],\n",
      "\n",
      "        [[-0.6850, -0.2168, -0.6087,  ..., -0.4610, -0.4295,  0.4391],\n",
      "         [-0.2084, -0.1325, -0.1151,  ..., -0.4943, -0.6546,  0.6617],\n",
      "         [-0.3665,  0.3408, -0.6133,  ..., -0.0885,  0.2791,  1.4721],\n",
      "         ...,\n",
      "         [-1.0985, -1.2861, -1.2531,  ..., -0.3340, -0.3050,  0.8792],\n",
      "         [-0.9787, -1.4207, -0.9908,  ..., -0.4959, -0.7944,  0.7687],\n",
      "         [-0.1970,  0.2371, -0.0115,  ..., -0.3705, -0.2893,  0.6787]]],\n",
      "       grad_fn=<ViewBackward0>),)\n",
      "kwargs in call_module:  {}\n",
      "HIIII from analyse_common_parameters_module\n",
      "args from analyse_common_parameters_module (tensor([[[-0.5911, -0.4682, -0.4314,  ...,  0.1677,  0.3883,  0.4382],\n",
      "         [-1.1141, -1.4785, -0.6477,  ...,  0.2989, -0.1569,  0.9508],\n",
      "         [-0.7059, -0.9954, -1.3923,  ...,  0.0258, -0.0364,  0.9990],\n",
      "         ...,\n",
      "         [-0.6300,  0.1252,  0.3486,  ..., -0.1261,  0.2908,  1.0980],\n",
      "         [-1.0593, -0.6395, -0.3343,  ...,  0.2486,  0.4005,  0.6046],\n",
      "         [-0.2081,  0.2785,  0.0613,  ...,  0.1182,  0.4294,  0.4781]],\n",
      "\n",
      "        [[-0.6850, -0.2168, -0.6087,  ..., -0.4610, -0.4295,  0.4391],\n",
      "         [-0.2084, -0.1325, -0.1151,  ..., -0.4943, -0.6546,  0.6617],\n",
      "         [-0.3665,  0.3408, -0.6133,  ..., -0.0885,  0.2791,  1.4721],\n",
      "         ...,\n",
      "         [-1.0985, -1.2861, -1.2531,  ..., -0.3340, -0.3050,  0.8792],\n",
      "         [-0.9787, -1.4207, -0.9908,  ..., -0.4959, -0.7944,  0.7687],\n",
      "         [-0.1970,  0.2371, -0.0115,  ..., -0.3705, -0.2893,  0.6787]]],\n",
      "       grad_fn=<ViewBackward0>),)\n",
      "kwargs from analyse_common_parameters_module {}\n",
      "meta before _annotate_arg_metadata: {'mase_type': 'module_related_func', 'mase_op': 'linear'}\n",
      "kwargs:  {}\n",
      "meta after _annotate_arg_metadata: {'mase_type': 'module_related_func', 'mase_op': 'linear', 'args': OrderedDict([('data_in_0', {'shape': [2, 10, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]})])}\n",
      "meta after get_type_and_precision: {'mase_type': 'module_related_func', 'mase_op': 'linear', 'args': OrderedDict([('data_in_0', {'shape': [2, 10, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]})])}\n",
      "weight\n",
      "bias\n",
      "meta after for: {'mase_type': 'module_related_func', 'mase_op': 'linear', 'args': OrderedDict([('data_in_0', {'shape': [2, 10, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]}), ('weight', {'type': 'float', 'precision': [32], 'shape': [128, 128], 'from': None}), ('bias', {'type': 'float', 'precision': [32], 'shape': [1, 128], 'from': None})])}\n",
      "args in call_module:  (tensor([[[-1.8657,  0.6198, -0.9432,  ...,  0.0036,  0.3981, -0.5701],\n",
      "         [-1.6518,  0.8653, -0.8332,  ...,  0.3380,  0.0425, -0.0859],\n",
      "         [-2.3834,  0.3252, -0.8502,  ..., -0.0120,  0.4924,  0.1120],\n",
      "         ...,\n",
      "         [-3.2343,  0.1446, -0.1611,  ..., -0.5140,  1.1649, -0.7596],\n",
      "         [-1.9706,  0.2732, -0.5555,  ..., -0.3419,  0.3733,  0.1055],\n",
      "         [-1.9318,  0.3609, -0.8070,  ..., -0.3425,  0.3618, -0.7749]],\n",
      "\n",
      "        [[-0.8335,  0.9213, -0.5216,  ...,  0.3686, -0.5437, -0.7170],\n",
      "         [-1.0004,  0.9042, -0.4329,  ...,  0.5498, -0.3477, -0.6620],\n",
      "         [-2.5285,  0.3980, -0.2197,  ..., -0.1209,  0.3299, -0.1648],\n",
      "         ...,\n",
      "         [-1.7525,  0.8086, -0.0273,  ...,  0.5116, -0.1827,  0.1942],\n",
      "         [-1.3959,  0.5641, -0.2265,  ...,  0.5811, -0.1137, -0.1858],\n",
      "         [-1.3464,  0.5548, -0.5958,  ...,  0.0686, -0.3579, -0.7920]]],\n",
      "       grad_fn=<ViewBackward0>),)\n",
      "kwargs in call_module:  {}\n",
      "HIIII from analyse_common_parameters_module\n",
      "args from analyse_common_parameters_module (tensor([[[-1.8657,  0.6198, -0.9432,  ...,  0.0036,  0.3981, -0.5701],\n",
      "         [-1.6518,  0.8653, -0.8332,  ...,  0.3380,  0.0425, -0.0859],\n",
      "         [-2.3834,  0.3252, -0.8502,  ..., -0.0120,  0.4924,  0.1120],\n",
      "         ...,\n",
      "         [-3.2343,  0.1446, -0.1611,  ..., -0.5140,  1.1649, -0.7596],\n",
      "         [-1.9706,  0.2732, -0.5555,  ..., -0.3419,  0.3733,  0.1055],\n",
      "         [-1.9318,  0.3609, -0.8070,  ..., -0.3425,  0.3618, -0.7749]],\n",
      "\n",
      "        [[-0.8335,  0.9213, -0.5216,  ...,  0.3686, -0.5437, -0.7170],\n",
      "         [-1.0004,  0.9042, -0.4329,  ...,  0.5498, -0.3477, -0.6620],\n",
      "         [-2.5285,  0.3980, -0.2197,  ..., -0.1209,  0.3299, -0.1648],\n",
      "         ...,\n",
      "         [-1.7525,  0.8086, -0.0273,  ...,  0.5116, -0.1827,  0.1942],\n",
      "         [-1.3959,  0.5641, -0.2265,  ...,  0.5811, -0.1137, -0.1858],\n",
      "         [-1.3464,  0.5548, -0.5958,  ...,  0.0686, -0.3579, -0.7920]]],\n",
      "       grad_fn=<ViewBackward0>),)\n",
      "kwargs from analyse_common_parameters_module {}\n",
      "meta before _annotate_arg_metadata: {'mase_type': 'module_related_func', 'mase_op': 'dropout'}\n",
      "kwargs:  {}\n",
      "meta after _annotate_arg_metadata: {'mase_type': 'module_related_func', 'mase_op': 'dropout', 'args': OrderedDict([('data_in_0', {'shape': [2, 10, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]})])}\n",
      "meta after get_type_and_precision: {'mase_type': 'module_related_func', 'mase_op': 'dropout', 'args': OrderedDict([('data_in_0', {'shape': [2, 10, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]})])}\n",
      "meta after for: {'mase_type': 'module_related_func', 'mase_op': 'dropout', 'args': OrderedDict([('data_in_0', {'shape': [2, 10, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]})])}\n",
      "kwargs:  {}\n",
      "args in call_module:  (tensor([[[-1.0683,  0.6307, -9.7836,  ...,  1.4206,  0.5027, -0.7252],\n",
      "         [-2.8284,  2.1532, -1.9318,  ...,  0.8129, -0.5474,  0.7887],\n",
      "         [-4.4394,  1.1000, -1.7411,  ..., -0.4154,  1.0276, -1.2537],\n",
      "         ...,\n",
      "         [-3.0026, -0.6450,  0.8023,  ..., -1.3177,  1.6483, -1.3464],\n",
      "         [-1.9463, -0.7503, -1.8326,  ..., -2.5797,  2.2263,  0.2613],\n",
      "         [-3.2955,  1.0665, -1.0247,  ...,  0.0132, -0.0353, -1.0856]],\n",
      "\n",
      "        [[-0.0362,  0.9322, -9.3620,  ...,  1.7856, -0.4391, -0.8721],\n",
      "         [-3.6944,  1.5240, -0.8893,  ..., -0.8869, -1.9182, -3.7880],\n",
      "         [-4.2809,  1.2516, -0.4352,  ..., -0.6431, -0.9131, -1.8847],\n",
      "         ...,\n",
      "         [-1.7872,  1.5532,  1.4188,  ..., -0.6462, -2.8024,  0.4554],\n",
      "         [ 1.0375,  0.2573,  0.5985,  ...,  0.7286,  0.0653,  2.1049],\n",
      "         [-2.7102,  1.2603, -0.8135,  ...,  0.4243, -0.7551, -1.1026]]],\n",
      "       grad_fn=<AddBackward0>),)\n",
      "kwargs in call_module:  {}\n",
      "HIIII from analyse_common_parameters_module\n",
      "args from analyse_common_parameters_module (tensor([[[-1.0683,  0.6307, -9.7836,  ...,  1.4206,  0.5027, -0.7252],\n",
      "         [-2.8284,  2.1532, -1.9318,  ...,  0.8129, -0.5474,  0.7887],\n",
      "         [-4.4394,  1.1000, -1.7411,  ..., -0.4154,  1.0276, -1.2537],\n",
      "         ...,\n",
      "         [-3.0026, -0.6450,  0.8023,  ..., -1.3177,  1.6483, -1.3464],\n",
      "         [-1.9463, -0.7503, -1.8326,  ..., -2.5797,  2.2263,  0.2613],\n",
      "         [-3.2955,  1.0665, -1.0247,  ...,  0.0132, -0.0353, -1.0856]],\n",
      "\n",
      "        [[-0.0362,  0.9322, -9.3620,  ...,  1.7856, -0.4391, -0.8721],\n",
      "         [-3.6944,  1.5240, -0.8893,  ..., -0.8869, -1.9182, -3.7880],\n",
      "         [-4.2809,  1.2516, -0.4352,  ..., -0.6431, -0.9131, -1.8847],\n",
      "         ...,\n",
      "         [-1.7872,  1.5532,  1.4188,  ..., -0.6462, -2.8024,  0.4554],\n",
      "         [ 1.0375,  0.2573,  0.5985,  ...,  0.7286,  0.0653,  2.1049],\n",
      "         [-2.7102,  1.2603, -0.8135,  ...,  0.4243, -0.7551, -1.1026]]],\n",
      "       grad_fn=<AddBackward0>),)\n",
      "kwargs from analyse_common_parameters_module {}\n",
      "meta before _annotate_arg_metadata: {'mase_type': 'module_related_func', 'mase_op': 'layer_norm'}\n",
      "kwargs:  {}\n",
      "meta after _annotate_arg_metadata: {'mase_type': 'module_related_func', 'mase_op': 'layer_norm', 'args': OrderedDict([('data_in_0', {'shape': [2, 10, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]})])}\n",
      "meta after get_type_and_precision: {'mase_type': 'module_related_func', 'mase_op': 'layer_norm', 'args': OrderedDict([('data_in_0', {'shape': [2, 10, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]})])}\n",
      "weight\n",
      "bias\n",
      "meta after for: {'mase_type': 'module_related_func', 'mase_op': 'layer_norm', 'args': OrderedDict([('data_in_0', {'shape': [2, 10, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]}), ('weight', {'type': 'float', 'precision': [32], 'shape': [1, 128], 'from': None}), ('bias', {'type': 'float', 'precision': [32], 'shape': [1, 128], 'from': None})])}\n",
      "args in call_module:  (tensor([[[ -1.7770,   0.6331, -13.4566,  ...,  -0.6506,   0.3293,  -0.0530],\n",
      "         [ -2.9586,   1.5670,  -2.1773,  ...,  -1.4067,  -0.5022,   1.1776],\n",
      "         [ -4.3545,   0.8721,  -2.0515,  ...,  -2.3917,   0.6306,  -0.3726],\n",
      "         ...,\n",
      "         [ -3.0042,  -0.3392,   0.8400,  ...,  -3.0443,   0.9988,  -0.3587],\n",
      "         [ -2.4024,  -0.4734,  -2.2378,  ...,  -4.2531,   1.5787,   0.8072],\n",
      "         [ -3.7016,   0.9536,  -1.3172,  ...,  -2.0141,  -0.1280,  -0.3129]],\n",
      "\n",
      "        [[ -0.7881,   0.8935, -12.8967,  ...,  -0.2891,  -0.4842,  -0.1856],\n",
      "         [ -3.6277,   1.1657,  -0.9883,  ...,  -2.7268,  -1.4517,  -2.2017],\n",
      "         [ -3.9557,   0.9284,  -0.4756,  ...,  -2.5239,  -0.7248,  -0.7363],\n",
      "         ...,\n",
      "         [ -2.2214,   1.2194,   1.6507,  ...,  -2.5775,  -2.1845,   0.9571],\n",
      "         [  0.0447,   0.2642,   0.6494,  ...,  -1.4648,  -0.0725,   2.1734],\n",
      "         [ -3.1096,   1.0847,  -1.0122,  ...,  -1.6455,  -0.6930,  -0.2993]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>),)\n",
      "kwargs in call_module:  {}\n",
      "HIIII from analyse_common_parameters_module\n",
      "args from analyse_common_parameters_module (tensor([[[ -1.7770,   0.6331, -13.4566,  ...,  -0.6506,   0.3293,  -0.0530],\n",
      "         [ -2.9586,   1.5670,  -2.1773,  ...,  -1.4067,  -0.5022,   1.1776],\n",
      "         [ -4.3545,   0.8721,  -2.0515,  ...,  -2.3917,   0.6306,  -0.3726],\n",
      "         ...,\n",
      "         [ -3.0042,  -0.3392,   0.8400,  ...,  -3.0443,   0.9988,  -0.3587],\n",
      "         [ -2.4024,  -0.4734,  -2.2378,  ...,  -4.2531,   1.5787,   0.8072],\n",
      "         [ -3.7016,   0.9536,  -1.3172,  ...,  -2.0141,  -0.1280,  -0.3129]],\n",
      "\n",
      "        [[ -0.7881,   0.8935, -12.8967,  ...,  -0.2891,  -0.4842,  -0.1856],\n",
      "         [ -3.6277,   1.1657,  -0.9883,  ...,  -2.7268,  -1.4517,  -2.2017],\n",
      "         [ -3.9557,   0.9284,  -0.4756,  ...,  -2.5239,  -0.7248,  -0.7363],\n",
      "         ...,\n",
      "         [ -2.2214,   1.2194,   1.6507,  ...,  -2.5775,  -2.1845,   0.9571],\n",
      "         [  0.0447,   0.2642,   0.6494,  ...,  -1.4648,  -0.0725,   2.1734],\n",
      "         [ -3.1096,   1.0847,  -1.0122,  ...,  -1.6455,  -0.6930,  -0.2993]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>),)\n",
      "kwargs from analyse_common_parameters_module {}\n",
      "meta before _annotate_arg_metadata: {'mase_type': 'module_related_func', 'mase_op': 'linear'}\n",
      "kwargs:  {}\n",
      "meta after _annotate_arg_metadata: {'mase_type': 'module_related_func', 'mase_op': 'linear', 'args': OrderedDict([('data_in_0', {'shape': [2, 10, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]})])}\n",
      "meta after get_type_and_precision: {'mase_type': 'module_related_func', 'mase_op': 'linear', 'args': OrderedDict([('data_in_0', {'shape': [2, 10, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]})])}\n",
      "weight\n",
      "bias\n",
      "meta after for: {'mase_type': 'module_related_func', 'mase_op': 'linear', 'args': OrderedDict([('data_in_0', {'shape': [2, 10, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]}), ('weight', {'type': 'float', 'precision': [32], 'shape': [512, 128], 'from': None}), ('bias', {'type': 'float', 'precision': [32], 'shape': [1, 512], 'from': None})])}\n",
      "kwargs:  {}\n",
      "args in call_module:  (tensor([[[-5.8138e-02,  5.9873e-02,  2.7161e-01,  ...,  2.6128e-01,\n",
      "          -3.5432e-02, -5.4359e-05],\n",
      "         [ 9.4135e-02, -1.2104e-01, -1.5434e-01,  ..., -1.6908e-01,\n",
      "          -1.5093e-01, -1.1183e-02],\n",
      "         [ 6.9730e-02, -1.6856e-01, -9.1753e-02,  ..., -1.2502e-01,\n",
      "           7.7347e-01, -1.8859e-04],\n",
      "         ...,\n",
      "         [-1.5503e-01, -1.6993e-01, -1.5170e-01,  ..., -3.8326e-02,\n",
      "          -1.1615e-01, -1.3614e-03],\n",
      "         [-4.5093e-02, -6.6128e-02, -1.4079e-01,  ..., -1.6994e-01,\n",
      "          -2.2979e-03, -1.6260e-04],\n",
      "         [ 5.6851e-03,  1.1040e-01,  2.5564e-01,  ..., -7.4735e-02,\n",
      "           7.4021e-01, -6.3813e-04]],\n",
      "\n",
      "        [[-1.6898e-01, -1.1194e-01,  1.8442e-01,  ...,  2.7241e-01,\n",
      "          -1.4292e-01, -1.7071e-04],\n",
      "         [-1.6316e-01, -7.1899e-02, -1.2831e-01,  ..., -1.5928e-01,\n",
      "          -1.6991e-01, -5.0123e-03],\n",
      "         [-1.6173e-01, -1.2903e-01, -9.7826e-02,  ..., -1.5090e-01,\n",
      "          -1.0767e-01, -3.9231e-02],\n",
      "         ...,\n",
      "         [-1.1920e-01, -2.4678e-02, -1.0139e-01,  ..., -3.6708e-02,\n",
      "          -1.0267e-01, -1.3509e-02],\n",
      "         [-1.3440e-01, -6.2208e-02, -1.5280e-01,  ..., -1.6579e-01,\n",
      "           4.2153e-01,  4.2215e+00],\n",
      "         [-1.6656e-01, -1.2642e-01,  1.6421e-01,  ..., -7.7377e-03,\n",
      "           3.9663e-01, -1.2408e-03]]], grad_fn=<GeluBackward0>),)\n",
      "kwargs in call_module:  {}\n",
      "HIIII from analyse_common_parameters_module\n",
      "args from analyse_common_parameters_module (tensor([[[-5.8138e-02,  5.9873e-02,  2.7161e-01,  ...,  2.6128e-01,\n",
      "          -3.5432e-02, -5.4359e-05],\n",
      "         [ 9.4135e-02, -1.2104e-01, -1.5434e-01,  ..., -1.6908e-01,\n",
      "          -1.5093e-01, -1.1183e-02],\n",
      "         [ 6.9730e-02, -1.6856e-01, -9.1753e-02,  ..., -1.2502e-01,\n",
      "           7.7347e-01, -1.8859e-04],\n",
      "         ...,\n",
      "         [-1.5503e-01, -1.6993e-01, -1.5170e-01,  ..., -3.8326e-02,\n",
      "          -1.1615e-01, -1.3614e-03],\n",
      "         [-4.5093e-02, -6.6128e-02, -1.4079e-01,  ..., -1.6994e-01,\n",
      "          -2.2979e-03, -1.6260e-04],\n",
      "         [ 5.6851e-03,  1.1040e-01,  2.5564e-01,  ..., -7.4735e-02,\n",
      "           7.4021e-01, -6.3813e-04]],\n",
      "\n",
      "        [[-1.6898e-01, -1.1194e-01,  1.8442e-01,  ...,  2.7241e-01,\n",
      "          -1.4292e-01, -1.7071e-04],\n",
      "         [-1.6316e-01, -7.1899e-02, -1.2831e-01,  ..., -1.5928e-01,\n",
      "          -1.6991e-01, -5.0123e-03],\n",
      "         [-1.6173e-01, -1.2903e-01, -9.7826e-02,  ..., -1.5090e-01,\n",
      "          -1.0767e-01, -3.9231e-02],\n",
      "         ...,\n",
      "         [-1.1920e-01, -2.4678e-02, -1.0139e-01,  ..., -3.6708e-02,\n",
      "          -1.0267e-01, -1.3509e-02],\n",
      "         [-1.3440e-01, -6.2208e-02, -1.5280e-01,  ..., -1.6579e-01,\n",
      "           4.2153e-01,  4.2215e+00],\n",
      "         [-1.6656e-01, -1.2642e-01,  1.6421e-01,  ..., -7.7377e-03,\n",
      "           3.9663e-01, -1.2408e-03]]], grad_fn=<GeluBackward0>),)\n",
      "kwargs from analyse_common_parameters_module {}\n",
      "meta before _annotate_arg_metadata: {'mase_type': 'module_related_func', 'mase_op': 'linear'}\n",
      "kwargs:  {}\n",
      "meta after _annotate_arg_metadata: {'mase_type': 'module_related_func', 'mase_op': 'linear', 'args': OrderedDict([('data_in_0', {'shape': [2, 10, 512], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]})])}\n",
      "meta after get_type_and_precision: {'mase_type': 'module_related_func', 'mase_op': 'linear', 'args': OrderedDict([('data_in_0', {'shape': [2, 10, 512], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]})])}\n",
      "weight\n",
      "bias\n",
      "meta after for: {'mase_type': 'module_related_func', 'mase_op': 'linear', 'args': OrderedDict([('data_in_0', {'shape': [2, 10, 512], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]}), ('weight', {'type': 'float', 'precision': [32], 'shape': [128, 512], 'from': None}), ('bias', {'type': 'float', 'precision': [32], 'shape': [1, 128], 'from': None})])}\n",
      "args in call_module:  (tensor([[[-0.4414,  0.5557, -7.3435,  ...,  0.0442, -0.3542,  0.2898],\n",
      "         [-0.0892, -0.0105,  0.2757,  ..., -0.4002,  0.5059, -0.1328],\n",
      "         [-0.1953, -0.0458,  0.1392,  ..., -0.0296, -0.0443,  0.1203],\n",
      "         ...,\n",
      "         [ 0.1668, -0.3900, -0.0977,  ...,  0.1333, -0.0331,  0.1747],\n",
      "         [ 0.1928, -0.1305,  0.2726,  ...,  0.1069,  0.3254, -0.2058],\n",
      "         [-0.2710,  0.0228, -0.6283,  ..., -0.4473,  0.4665,  0.8205]],\n",
      "\n",
      "        [[-0.4787,  0.5071, -6.7137,  ...,  0.0304, -0.3877,  0.0734],\n",
      "         [-0.2360,  0.1772,  0.1776,  ..., -0.4226,  0.3065, -0.0197],\n",
      "         [ 0.2050, -0.2054,  0.0156,  ...,  0.2637, -0.0888, -0.2415],\n",
      "         ...,\n",
      "         [ 0.1914,  0.4587, -0.1186,  ...,  0.0431, -0.1868,  0.1541],\n",
      "         [-0.0410, -0.2602,  0.0106,  ..., -0.3925,  0.1508,  0.7243],\n",
      "         [-0.2755, -0.0759, -0.8471,  ..., -0.3899,  0.5905,  1.1983]]],\n",
      "       grad_fn=<ViewBackward0>),)\n",
      "kwargs in call_module:  {}\n",
      "HIIII from analyse_common_parameters_module\n",
      "args from analyse_common_parameters_module (tensor([[[-0.4414,  0.5557, -7.3435,  ...,  0.0442, -0.3542,  0.2898],\n",
      "         [-0.0892, -0.0105,  0.2757,  ..., -0.4002,  0.5059, -0.1328],\n",
      "         [-0.1953, -0.0458,  0.1392,  ..., -0.0296, -0.0443,  0.1203],\n",
      "         ...,\n",
      "         [ 0.1668, -0.3900, -0.0977,  ...,  0.1333, -0.0331,  0.1747],\n",
      "         [ 0.1928, -0.1305,  0.2726,  ...,  0.1069,  0.3254, -0.2058],\n",
      "         [-0.2710,  0.0228, -0.6283,  ..., -0.4473,  0.4665,  0.8205]],\n",
      "\n",
      "        [[-0.4787,  0.5071, -6.7137,  ...,  0.0304, -0.3877,  0.0734],\n",
      "         [-0.2360,  0.1772,  0.1776,  ..., -0.4226,  0.3065, -0.0197],\n",
      "         [ 0.2050, -0.2054,  0.0156,  ...,  0.2637, -0.0888, -0.2415],\n",
      "         ...,\n",
      "         [ 0.1914,  0.4587, -0.1186,  ...,  0.0431, -0.1868,  0.1541],\n",
      "         [-0.0410, -0.2602,  0.0106,  ..., -0.3925,  0.1508,  0.7243],\n",
      "         [-0.2755, -0.0759, -0.8471,  ..., -0.3899,  0.5905,  1.1983]]],\n",
      "       grad_fn=<ViewBackward0>),)\n",
      "kwargs from analyse_common_parameters_module {}\n",
      "meta before _annotate_arg_metadata: {'mase_type': 'module_related_func', 'mase_op': 'dropout'}\n",
      "kwargs:  {}\n",
      "meta after _annotate_arg_metadata: {'mase_type': 'module_related_func', 'mase_op': 'dropout', 'args': OrderedDict([('data_in_0', {'shape': [2, 10, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]})])}\n",
      "meta after get_type_and_precision: {'mase_type': 'module_related_func', 'mase_op': 'dropout', 'args': OrderedDict([('data_in_0', {'shape': [2, 10, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]})])}\n",
      "meta after for: {'mase_type': 'module_related_func', 'mase_op': 'dropout', 'args': OrderedDict([('data_in_0', {'shape': [2, 10, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]})])}\n",
      "kwargs:  {}\n",
      "args in call_module:  (tensor([[[-2.2185e+00,  1.1889e+00, -2.0800e+01,  ..., -6.0641e-01,\n",
      "          -2.4913e-02,  2.3681e-01],\n",
      "         [-3.0477e+00,  1.5565e+00, -1.9016e+00,  ..., -1.8069e+00,\n",
      "           3.7085e-03,  1.0447e+00],\n",
      "         [-4.5498e+00,  8.2632e-01, -1.9122e+00,  ..., -2.4214e+00,\n",
      "           5.8625e-01, -2.5238e-01],\n",
      "         ...,\n",
      "         [-2.8375e+00, -7.2914e-01,  7.4228e-01,  ..., -2.9110e+00,\n",
      "           9.6568e-01, -1.8402e-01],\n",
      "         [-2.2095e+00, -6.0393e-01, -1.9652e+00,  ..., -4.1462e+00,\n",
      "           1.9041e+00,  6.0139e-01],\n",
      "         [-3.9726e+00,  9.7636e-01, -1.9455e+00,  ..., -2.4614e+00,\n",
      "           3.3849e-01,  5.0753e-01]],\n",
      "\n",
      "        [[-1.2668e+00,  1.4005e+00, -1.9610e+01,  ..., -2.5871e-01,\n",
      "          -8.7183e-01, -1.1215e-01],\n",
      "         [-3.8638e+00,  1.3430e+00, -8.1067e-01,  ..., -3.1494e+00,\n",
      "          -1.1452e+00, -2.2214e+00],\n",
      "         [-3.7507e+00,  7.2301e-01, -4.6000e-01,  ..., -2.2602e+00,\n",
      "          -8.1356e-01, -9.7782e-01],\n",
      "         ...,\n",
      "         [-2.0300e+00,  1.6781e+00,  1.5322e+00,  ..., -2.5344e+00,\n",
      "          -2.3713e+00,  1.1112e+00],\n",
      "         [ 3.7488e-03,  3.9968e-03,  6.5998e-01,  ..., -1.8574e+00,\n",
      "           7.8244e-02,  2.8977e+00],\n",
      "         [-3.3850e+00,  1.0088e+00, -1.8593e+00,  ..., -2.0353e+00,\n",
      "          -1.0244e-01,  8.9902e-01]]], grad_fn=<AddBackward0>),)\n",
      "kwargs in call_module:  {}\n",
      "HIIII from analyse_common_parameters_module\n",
      "args from analyse_common_parameters_module (tensor([[[-2.2185e+00,  1.1889e+00, -2.0800e+01,  ..., -6.0641e-01,\n",
      "          -2.4913e-02,  2.3681e-01],\n",
      "         [-3.0477e+00,  1.5565e+00, -1.9016e+00,  ..., -1.8069e+00,\n",
      "           3.7085e-03,  1.0447e+00],\n",
      "         [-4.5498e+00,  8.2632e-01, -1.9122e+00,  ..., -2.4214e+00,\n",
      "           5.8625e-01, -2.5238e-01],\n",
      "         ...,\n",
      "         [-2.8375e+00, -7.2914e-01,  7.4228e-01,  ..., -2.9110e+00,\n",
      "           9.6568e-01, -1.8402e-01],\n",
      "         [-2.2095e+00, -6.0393e-01, -1.9652e+00,  ..., -4.1462e+00,\n",
      "           1.9041e+00,  6.0139e-01],\n",
      "         [-3.9726e+00,  9.7636e-01, -1.9455e+00,  ..., -2.4614e+00,\n",
      "           3.3849e-01,  5.0753e-01]],\n",
      "\n",
      "        [[-1.2668e+00,  1.4005e+00, -1.9610e+01,  ..., -2.5871e-01,\n",
      "          -8.7183e-01, -1.1215e-01],\n",
      "         [-3.8638e+00,  1.3430e+00, -8.1067e-01,  ..., -3.1494e+00,\n",
      "          -1.1452e+00, -2.2214e+00],\n",
      "         [-3.7507e+00,  7.2301e-01, -4.6000e-01,  ..., -2.2602e+00,\n",
      "          -8.1356e-01, -9.7782e-01],\n",
      "         ...,\n",
      "         [-2.0300e+00,  1.6781e+00,  1.5322e+00,  ..., -2.5344e+00,\n",
      "          -2.3713e+00,  1.1112e+00],\n",
      "         [ 3.7488e-03,  3.9968e-03,  6.5998e-01,  ..., -1.8574e+00,\n",
      "           7.8244e-02,  2.8977e+00],\n",
      "         [-3.3850e+00,  1.0088e+00, -1.8593e+00,  ..., -2.0353e+00,\n",
      "          -1.0244e-01,  8.9902e-01]]], grad_fn=<AddBackward0>),)\n",
      "kwargs from analyse_common_parameters_module {}\n",
      "meta before _annotate_arg_metadata: {'mase_type': 'module_related_func', 'mase_op': 'layer_norm'}\n",
      "kwargs:  {}\n",
      "meta after _annotate_arg_metadata: {'mase_type': 'module_related_func', 'mase_op': 'layer_norm', 'args': OrderedDict([('data_in_0', {'shape': [2, 10, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]})])}\n",
      "meta after get_type_and_precision: {'mase_type': 'module_related_func', 'mase_op': 'layer_norm', 'args': OrderedDict([('data_in_0', {'shape': [2, 10, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]})])}\n",
      "weight\n",
      "bias\n",
      "meta after for: {'mase_type': 'module_related_func', 'mase_op': 'layer_norm', 'args': OrderedDict([('data_in_0', {'shape': [2, 10, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]}), ('weight', {'type': 'float', 'precision': [32], 'shape': [1, 128], 'from': None}), ('bias', {'type': 'float', 'precision': [32], 'shape': [1, 128], 'from': None})])}\n",
      "kwargs:  {}\n",
      "kwargs:  {}\n",
      "kwargs:  {}\n",
      "kwargs:  {}\n",
      "args in call_module:  (tensor([[[-0.9552,  0.6594, -6.5403,  ..., -0.7144,  0.0906,  0.3369],\n",
      "         [-2.5251,  1.3955, -0.8914,  ..., -2.1363,  0.0271,  1.1132],\n",
      "         [-3.7148,  0.6796, -0.8710,  ..., -2.6492,  0.5694, -0.1085],\n",
      "         ...,\n",
      "         [-2.2403, -0.7594,  0.5414,  ..., -3.0426,  0.8895, -0.0546],\n",
      "         [-1.6945, -0.6326, -0.8632,  ..., -4.0678,  1.7219,  0.6481],\n",
      "         [-2.9625,  0.7451, -0.8037,  ..., -2.5048,  0.3125,  0.5537]],\n",
      "\n",
      "        [[-0.5150,  0.8150, -6.5015,  ..., -0.5377, -0.4171,  0.1350],\n",
      "         [-2.9979,  1.0930, -0.2619,  ..., -3.1811, -1.0048, -1.8349],\n",
      "         [-2.8788,  0.5405, -0.0789,  ..., -2.3969, -0.7016, -0.7332],\n",
      "         ...,\n",
      "         [-1.7194,  1.5158,  1.0070,  ..., -2.8931, -2.3309,  1.1685],\n",
      "         [ 0.0717, -0.1039,  0.5084,  ..., -2.1932,  0.0751,  2.8236],\n",
      "         [-2.4774,  0.7563, -0.7502,  ..., -2.1312, -0.0685,  0.8700]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>),)\n",
      "kwargs in call_module:  {}\n",
      "HIIII from analyse_common_parameters_module\n",
      "args from analyse_common_parameters_module (tensor([[[-0.9552,  0.6594, -6.5403,  ..., -0.7144,  0.0906,  0.3369],\n",
      "         [-2.5251,  1.3955, -0.8914,  ..., -2.1363,  0.0271,  1.1132],\n",
      "         [-3.7148,  0.6796, -0.8710,  ..., -2.6492,  0.5694, -0.1085],\n",
      "         ...,\n",
      "         [-2.2403, -0.7594,  0.5414,  ..., -3.0426,  0.8895, -0.0546],\n",
      "         [-1.6945, -0.6326, -0.8632,  ..., -4.0678,  1.7219,  0.6481],\n",
      "         [-2.9625,  0.7451, -0.8037,  ..., -2.5048,  0.3125,  0.5537]],\n",
      "\n",
      "        [[-0.5150,  0.8150, -6.5015,  ..., -0.5377, -0.4171,  0.1350],\n",
      "         [-2.9979,  1.0930, -0.2619,  ..., -3.1811, -1.0048, -1.8349],\n",
      "         [-2.8788,  0.5405, -0.0789,  ..., -2.3969, -0.7016, -0.7332],\n",
      "         ...,\n",
      "         [-1.7194,  1.5158,  1.0070,  ..., -2.8931, -2.3309,  1.1685],\n",
      "         [ 0.0717, -0.1039,  0.5084,  ..., -2.1932,  0.0751,  2.8236],\n",
      "         [-2.4774,  0.7563, -0.7502,  ..., -2.1312, -0.0685,  0.8700]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>),)\n",
      "kwargs from analyse_common_parameters_module {}\n",
      "meta before _annotate_arg_metadata: {'mase_type': 'module_related_func', 'mase_op': 'linear'}\n",
      "kwargs:  {}\n",
      "meta after _annotate_arg_metadata: {'mase_type': 'module_related_func', 'mase_op': 'linear', 'args': OrderedDict([('data_in_0', {'shape': [2, 10, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]})])}\n",
      "meta after get_type_and_precision: {'mase_type': 'module_related_func', 'mase_op': 'linear', 'args': OrderedDict([('data_in_0', {'shape': [2, 10, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]})])}\n",
      "weight\n",
      "bias\n",
      "meta after for: {'mase_type': 'module_related_func', 'mase_op': 'linear', 'args': OrderedDict([('data_in_0', {'shape': [2, 10, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]}), ('weight', {'type': 'float', 'precision': [32], 'shape': [128, 128], 'from': None}), ('bias', {'type': 'float', 'precision': [32], 'shape': [1, 128], 'from': None})])}\n",
      "kwargs:  {}\n",
      "kwargs:  {}\n",
      "kwargs:  {}\n",
      "kwargs:  {}\n",
      "kwargs:  {}\n",
      "args in call_module:  (tensor([[[-0.9552,  0.6594, -6.5403,  ..., -0.7144,  0.0906,  0.3369],\n",
      "         [-2.5251,  1.3955, -0.8914,  ..., -2.1363,  0.0271,  1.1132],\n",
      "         [-3.7148,  0.6796, -0.8710,  ..., -2.6492,  0.5694, -0.1085],\n",
      "         ...,\n",
      "         [-2.2403, -0.7594,  0.5414,  ..., -3.0426,  0.8895, -0.0546],\n",
      "         [-1.6945, -0.6326, -0.8632,  ..., -4.0678,  1.7219,  0.6481],\n",
      "         [-2.9625,  0.7451, -0.8037,  ..., -2.5048,  0.3125,  0.5537]],\n",
      "\n",
      "        [[-0.5150,  0.8150, -6.5015,  ..., -0.5377, -0.4171,  0.1350],\n",
      "         [-2.9979,  1.0930, -0.2619,  ..., -3.1811, -1.0048, -1.8349],\n",
      "         [-2.8788,  0.5405, -0.0789,  ..., -2.3969, -0.7016, -0.7332],\n",
      "         ...,\n",
      "         [-1.7194,  1.5158,  1.0070,  ..., -2.8931, -2.3309,  1.1685],\n",
      "         [ 0.0717, -0.1039,  0.5084,  ..., -2.1932,  0.0751,  2.8236],\n",
      "         [-2.4774,  0.7563, -0.7502,  ..., -2.1312, -0.0685,  0.8700]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>),)\n",
      "kwargs in call_module:  {}\n",
      "HIIII from analyse_common_parameters_module\n",
      "args from analyse_common_parameters_module (tensor([[[-0.9552,  0.6594, -6.5403,  ..., -0.7144,  0.0906,  0.3369],\n",
      "         [-2.5251,  1.3955, -0.8914,  ..., -2.1363,  0.0271,  1.1132],\n",
      "         [-3.7148,  0.6796, -0.8710,  ..., -2.6492,  0.5694, -0.1085],\n",
      "         ...,\n",
      "         [-2.2403, -0.7594,  0.5414,  ..., -3.0426,  0.8895, -0.0546],\n",
      "         [-1.6945, -0.6326, -0.8632,  ..., -4.0678,  1.7219,  0.6481],\n",
      "         [-2.9625,  0.7451, -0.8037,  ..., -2.5048,  0.3125,  0.5537]],\n",
      "\n",
      "        [[-0.5150,  0.8150, -6.5015,  ..., -0.5377, -0.4171,  0.1350],\n",
      "         [-2.9979,  1.0930, -0.2619,  ..., -3.1811, -1.0048, -1.8349],\n",
      "         [-2.8788,  0.5405, -0.0789,  ..., -2.3969, -0.7016, -0.7332],\n",
      "         ...,\n",
      "         [-1.7194,  1.5158,  1.0070,  ..., -2.8931, -2.3309,  1.1685],\n",
      "         [ 0.0717, -0.1039,  0.5084,  ..., -2.1932,  0.0751,  2.8236],\n",
      "         [-2.4774,  0.7563, -0.7502,  ..., -2.1312, -0.0685,  0.8700]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>),)\n",
      "kwargs from analyse_common_parameters_module {}\n",
      "meta before _annotate_arg_metadata: {'mase_type': 'module_related_func', 'mase_op': 'linear'}\n",
      "kwargs:  {}\n",
      "meta after _annotate_arg_metadata: {'mase_type': 'module_related_func', 'mase_op': 'linear', 'args': OrderedDict([('data_in_0', {'shape': [2, 10, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]})])}\n",
      "meta after get_type_and_precision: {'mase_type': 'module_related_func', 'mase_op': 'linear', 'args': OrderedDict([('data_in_0', {'shape': [2, 10, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]})])}\n",
      "weight\n",
      "bias\n",
      "meta after for: {'mase_type': 'module_related_func', 'mase_op': 'linear', 'args': OrderedDict([('data_in_0', {'shape': [2, 10, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]}), ('weight', {'type': 'float', 'precision': [32], 'shape': [128, 128], 'from': None}), ('bias', {'type': 'float', 'precision': [32], 'shape': [1, 128], 'from': None})])}\n",
      "kwargs:  {}\n",
      "kwargs:  {}\n",
      "kwargs:  {}\n",
      "kwargs:  {}\n",
      "kwargs:  {}\n",
      "args in call_module:  (tensor([[[-0.9552,  0.6594, -6.5403,  ..., -0.7144,  0.0906,  0.3369],\n",
      "         [-2.5251,  1.3955, -0.8914,  ..., -2.1363,  0.0271,  1.1132],\n",
      "         [-3.7148,  0.6796, -0.8710,  ..., -2.6492,  0.5694, -0.1085],\n",
      "         ...,\n",
      "         [-2.2403, -0.7594,  0.5414,  ..., -3.0426,  0.8895, -0.0546],\n",
      "         [-1.6945, -0.6326, -0.8632,  ..., -4.0678,  1.7219,  0.6481],\n",
      "         [-2.9625,  0.7451, -0.8037,  ..., -2.5048,  0.3125,  0.5537]],\n",
      "\n",
      "        [[-0.5150,  0.8150, -6.5015,  ..., -0.5377, -0.4171,  0.1350],\n",
      "         [-2.9979,  1.0930, -0.2619,  ..., -3.1811, -1.0048, -1.8349],\n",
      "         [-2.8788,  0.5405, -0.0789,  ..., -2.3969, -0.7016, -0.7332],\n",
      "         ...,\n",
      "         [-1.7194,  1.5158,  1.0070,  ..., -2.8931, -2.3309,  1.1685],\n",
      "         [ 0.0717, -0.1039,  0.5084,  ..., -2.1932,  0.0751,  2.8236],\n",
      "         [-2.4774,  0.7563, -0.7502,  ..., -2.1312, -0.0685,  0.8700]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>),)\n",
      "kwargs in call_module:  {}\n",
      "HIIII from analyse_common_parameters_module\n",
      "args from analyse_common_parameters_module (tensor([[[-0.9552,  0.6594, -6.5403,  ..., -0.7144,  0.0906,  0.3369],\n",
      "         [-2.5251,  1.3955, -0.8914,  ..., -2.1363,  0.0271,  1.1132],\n",
      "         [-3.7148,  0.6796, -0.8710,  ..., -2.6492,  0.5694, -0.1085],\n",
      "         ...,\n",
      "         [-2.2403, -0.7594,  0.5414,  ..., -3.0426,  0.8895, -0.0546],\n",
      "         [-1.6945, -0.6326, -0.8632,  ..., -4.0678,  1.7219,  0.6481],\n",
      "         [-2.9625,  0.7451, -0.8037,  ..., -2.5048,  0.3125,  0.5537]],\n",
      "\n",
      "        [[-0.5150,  0.8150, -6.5015,  ..., -0.5377, -0.4171,  0.1350],\n",
      "         [-2.9979,  1.0930, -0.2619,  ..., -3.1811, -1.0048, -1.8349],\n",
      "         [-2.8788,  0.5405, -0.0789,  ..., -2.3969, -0.7016, -0.7332],\n",
      "         ...,\n",
      "         [-1.7194,  1.5158,  1.0070,  ..., -2.8931, -2.3309,  1.1685],\n",
      "         [ 0.0717, -0.1039,  0.5084,  ..., -2.1932,  0.0751,  2.8236],\n",
      "         [-2.4774,  0.7563, -0.7502,  ..., -2.1312, -0.0685,  0.8700]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>),)\n",
      "kwargs from analyse_common_parameters_module {}\n",
      "meta before _annotate_arg_metadata: {'mase_type': 'module_related_func', 'mase_op': 'linear'}\n",
      "kwargs:  {}\n",
      "meta after _annotate_arg_metadata: {'mase_type': 'module_related_func', 'mase_op': 'linear', 'args': OrderedDict([('data_in_0', {'shape': [2, 10, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]})])}\n",
      "meta after get_type_and_precision: {'mase_type': 'module_related_func', 'mase_op': 'linear', 'args': OrderedDict([('data_in_0', {'shape': [2, 10, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]})])}\n",
      "weight\n",
      "bias\n",
      "meta after for: {'mase_type': 'module_related_func', 'mase_op': 'linear', 'args': OrderedDict([('data_in_0', {'shape': [2, 10, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]}), ('weight', {'type': 'float', 'precision': [32], 'shape': [128, 128], 'from': None}), ('bias', {'type': 'float', 'precision': [32], 'shape': [1, 128], 'from': None})])}\n",
      "kwargs:  {}\n",
      "kwargs:  {}\n",
      "kwargs:  {}\n",
      "kwargs:  {}\n",
      "kwargs:  {}\n",
      "kwargs:  {'attn_mask': tensor([[[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]]), 'dropout_p': 0.0, 'is_causal': False}\n",
      "kwargs:  {}\n",
      "kwargs:  {}\n",
      "args in call_module:  (tensor([[[ 3.7393e-01,  3.7078e-01, -7.5553e-01,  ..., -1.3792e-03,\n",
      "          -5.2249e-01, -4.2095e-01],\n",
      "         [ 3.9396e-01,  4.7657e-02, -1.0277e+00,  ...,  1.3235e-01,\n",
      "          -4.1385e-01, -1.3744e+00],\n",
      "         [ 9.9586e-01,  2.4414e-01, -8.3459e-01,  ...,  2.4736e-01,\n",
      "          -1.6626e-01, -7.0940e-01],\n",
      "         ...,\n",
      "         [ 1.4504e+00, -1.2077e-01, -4.8160e-01,  ...,  8.6187e-02,\n",
      "          -6.9561e-01, -8.5675e-01],\n",
      "         [ 3.8821e-01,  1.4150e-01, -1.5051e-01,  ...,  1.8643e-01,\n",
      "          -1.0965e+00, -4.8097e-01],\n",
      "         [ 1.0467e-01,  5.5196e-01,  1.0818e-01,  ...,  1.5424e-01,\n",
      "          -1.1762e+00, -2.9385e-01]],\n",
      "\n",
      "        [[ 4.9445e-01,  9.6664e-03, -5.7117e-01,  ...,  2.2845e-01,\n",
      "          -8.2075e-01, -1.1496e+00],\n",
      "         [ 4.7672e-01, -2.3672e-01, -8.9246e-01,  ...,  3.3008e-01,\n",
      "          -5.5070e-01, -1.8440e+00],\n",
      "         [ 4.5120e-01, -5.8035e-02, -6.8736e-01,  ...,  4.7493e-01,\n",
      "          -4.6589e-01, -2.0454e+00],\n",
      "         ...,\n",
      "         [ 3.3361e-01,  1.5915e-03, -1.0108e+00,  ...,  9.0025e-01,\n",
      "           3.1643e-01, -2.0784e+00],\n",
      "         [ 1.0123e+00, -1.1147e+00, -1.3032e+00,  ...,  6.6286e-01,\n",
      "          -1.0588e+00, -7.6781e-01],\n",
      "         [ 1.4273e+00, -1.2951e+00,  5.7719e-01,  ...,  6.6493e-01,\n",
      "          -9.1110e-01, -1.0382e+00]]], grad_fn=<ViewBackward0>),)\n",
      "kwargs in call_module:  {}\n",
      "HIIII from analyse_common_parameters_module\n",
      "args from analyse_common_parameters_module (tensor([[[ 3.7393e-01,  3.7078e-01, -7.5553e-01,  ..., -1.3792e-03,\n",
      "          -5.2249e-01, -4.2095e-01],\n",
      "         [ 3.9396e-01,  4.7657e-02, -1.0277e+00,  ...,  1.3235e-01,\n",
      "          -4.1385e-01, -1.3744e+00],\n",
      "         [ 9.9586e-01,  2.4414e-01, -8.3459e-01,  ...,  2.4736e-01,\n",
      "          -1.6626e-01, -7.0940e-01],\n",
      "         ...,\n",
      "         [ 1.4504e+00, -1.2077e-01, -4.8160e-01,  ...,  8.6187e-02,\n",
      "          -6.9561e-01, -8.5675e-01],\n",
      "         [ 3.8821e-01,  1.4150e-01, -1.5051e-01,  ...,  1.8643e-01,\n",
      "          -1.0965e+00, -4.8097e-01],\n",
      "         [ 1.0467e-01,  5.5196e-01,  1.0818e-01,  ...,  1.5424e-01,\n",
      "          -1.1762e+00, -2.9385e-01]],\n",
      "\n",
      "        [[ 4.9445e-01,  9.6664e-03, -5.7117e-01,  ...,  2.2845e-01,\n",
      "          -8.2075e-01, -1.1496e+00],\n",
      "         [ 4.7672e-01, -2.3672e-01, -8.9246e-01,  ...,  3.3008e-01,\n",
      "          -5.5070e-01, -1.8440e+00],\n",
      "         [ 4.5120e-01, -5.8035e-02, -6.8736e-01,  ...,  4.7493e-01,\n",
      "          -4.6589e-01, -2.0454e+00],\n",
      "         ...,\n",
      "         [ 3.3361e-01,  1.5915e-03, -1.0108e+00,  ...,  9.0025e-01,\n",
      "           3.1643e-01, -2.0784e+00],\n",
      "         [ 1.0123e+00, -1.1147e+00, -1.3032e+00,  ...,  6.6286e-01,\n",
      "          -1.0588e+00, -7.6781e-01],\n",
      "         [ 1.4273e+00, -1.2951e+00,  5.7719e-01,  ...,  6.6493e-01,\n",
      "          -9.1110e-01, -1.0382e+00]]], grad_fn=<ViewBackward0>),)\n",
      "kwargs from analyse_common_parameters_module {}\n",
      "meta before _annotate_arg_metadata: {'mase_type': 'module_related_func', 'mase_op': 'linear'}\n",
      "kwargs:  {}\n",
      "meta after _annotate_arg_metadata: {'mase_type': 'module_related_func', 'mase_op': 'linear', 'args': OrderedDict([('data_in_0', {'shape': [2, 10, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]})])}\n",
      "meta after get_type_and_precision: {'mase_type': 'module_related_func', 'mase_op': 'linear', 'args': OrderedDict([('data_in_0', {'shape': [2, 10, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]})])}\n",
      "weight\n",
      "bias\n",
      "meta after for: {'mase_type': 'module_related_func', 'mase_op': 'linear', 'args': OrderedDict([('data_in_0', {'shape': [2, 10, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]}), ('weight', {'type': 'float', 'precision': [32], 'shape': [128, 128], 'from': None}), ('bias', {'type': 'float', 'precision': [32], 'shape': [1, 128], 'from': None})])}\n",
      "args in call_module:  (tensor([[[-3.4022, -0.0542, -0.9780,  ...,  0.0189,  0.7857, -0.4697],\n",
      "         [-2.8888,  0.1039, -0.5324,  ..., -0.7707,  1.0280,  0.1771],\n",
      "         [-2.5894,  0.0629, -1.3014,  ...,  0.0568,  1.4114,  2.2357],\n",
      "         ...,\n",
      "         [-3.0773, -1.0595,  0.8602,  ..., -1.0677, -0.1214, -0.5790],\n",
      "         [-3.4534,  0.0389, -1.0642,  ..., -0.4892,  0.6781, -1.6342],\n",
      "         [-3.5153,  0.0572, -0.7674,  ..., -0.4800,  0.7568, -1.4605]],\n",
      "\n",
      "        [[-2.2187,  0.6555, -0.0531,  ...,  0.9291,  0.6603, -1.0552],\n",
      "         [-1.6315,  1.0393,  0.2731,  ...,  0.7853,  0.2952, -0.7504],\n",
      "         [-1.2231,  0.5662,  0.3105,  ...,  0.6093,  0.1747, -0.7406],\n",
      "         ...,\n",
      "         [-1.1975, -0.7578,  2.4795,  ..., -0.5203,  1.0671, -0.5883],\n",
      "         [ 0.7609, -2.6236, -0.8976,  ...,  1.0184,  0.6602, -3.5583],\n",
      "         [-1.3988, -1.4592,  0.3097,  ..., -1.1127,  1.1862, -0.7199]]],\n",
      "       grad_fn=<ViewBackward0>),)\n",
      "kwargs in call_module:  {}\n",
      "HIIII from analyse_common_parameters_module\n",
      "args from analyse_common_parameters_module (tensor([[[-3.4022, -0.0542, -0.9780,  ...,  0.0189,  0.7857, -0.4697],\n",
      "         [-2.8888,  0.1039, -0.5324,  ..., -0.7707,  1.0280,  0.1771],\n",
      "         [-2.5894,  0.0629, -1.3014,  ...,  0.0568,  1.4114,  2.2357],\n",
      "         ...,\n",
      "         [-3.0773, -1.0595,  0.8602,  ..., -1.0677, -0.1214, -0.5790],\n",
      "         [-3.4534,  0.0389, -1.0642,  ..., -0.4892,  0.6781, -1.6342],\n",
      "         [-3.5153,  0.0572, -0.7674,  ..., -0.4800,  0.7568, -1.4605]],\n",
      "\n",
      "        [[-2.2187,  0.6555, -0.0531,  ...,  0.9291,  0.6603, -1.0552],\n",
      "         [-1.6315,  1.0393,  0.2731,  ...,  0.7853,  0.2952, -0.7504],\n",
      "         [-1.2231,  0.5662,  0.3105,  ...,  0.6093,  0.1747, -0.7406],\n",
      "         ...,\n",
      "         [-1.1975, -0.7578,  2.4795,  ..., -0.5203,  1.0671, -0.5883],\n",
      "         [ 0.7609, -2.6236, -0.8976,  ...,  1.0184,  0.6602, -3.5583],\n",
      "         [-1.3988, -1.4592,  0.3097,  ..., -1.1127,  1.1862, -0.7199]]],\n",
      "       grad_fn=<ViewBackward0>),)\n",
      "kwargs from analyse_common_parameters_module {}\n",
      "meta before _annotate_arg_metadata: {'mase_type': 'module_related_func', 'mase_op': 'dropout'}\n",
      "kwargs:  {}\n",
      "meta after _annotate_arg_metadata: {'mase_type': 'module_related_func', 'mase_op': 'dropout', 'args': OrderedDict([('data_in_0', {'shape': [2, 10, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]})])}\n",
      "meta after get_type_and_precision: {'mase_type': 'module_related_func', 'mase_op': 'dropout', 'args': OrderedDict([('data_in_0', {'shape': [2, 10, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]})])}\n",
      "meta after for: {'mase_type': 'module_related_func', 'mase_op': 'dropout', 'args': OrderedDict([('data_in_0', {'shape': [2, 10, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]})])}\n",
      "kwargs:  {}\n",
      "args in call_module:  (tensor([[[-4.3575,  0.6052, -7.5183,  ..., -0.6954,  0.8764, -0.1328],\n",
      "         [-5.4138,  1.4995, -1.4237,  ..., -2.9070,  1.0550,  1.2903],\n",
      "         [-6.3042,  0.7425, -2.1725,  ..., -2.5925,  1.9809,  2.1272],\n",
      "         ...,\n",
      "         [-5.3176, -1.8189,  1.4017,  ..., -4.1103,  0.7681, -0.6336],\n",
      "         [-5.1479, -0.5937, -1.9274,  ..., -4.5569,  2.4000, -0.9862],\n",
      "         [-6.4778,  0.8024, -1.5711,  ..., -2.9848,  1.0693, -0.9069]],\n",
      "\n",
      "        [[-2.7337,  1.4705, -6.5547,  ...,  0.3913,  0.2433, -0.9202],\n",
      "         [-4.6295,  2.1323,  0.0112,  ..., -2.3959, -0.7097, -2.5854],\n",
      "         [-4.1019,  1.1067,  0.2315,  ..., -1.7875, -0.5268, -1.4738],\n",
      "         ...,\n",
      "         [-2.9169,  0.7580,  3.4865,  ..., -3.4133, -1.2639,  0.5803],\n",
      "         [ 0.8326, -2.7275, -0.3892,  ..., -1.1748,  0.7352, -0.7347],\n",
      "         [-3.8762, -0.7029, -0.4404,  ..., -3.2439,  1.1178,  0.1501]]],\n",
      "       grad_fn=<AddBackward0>),)\n",
      "kwargs in call_module:  {}\n",
      "HIIII from analyse_common_parameters_module\n",
      "args from analyse_common_parameters_module (tensor([[[-4.3575,  0.6052, -7.5183,  ..., -0.6954,  0.8764, -0.1328],\n",
      "         [-5.4138,  1.4995, -1.4237,  ..., -2.9070,  1.0550,  1.2903],\n",
      "         [-6.3042,  0.7425, -2.1725,  ..., -2.5925,  1.9809,  2.1272],\n",
      "         ...,\n",
      "         [-5.3176, -1.8189,  1.4017,  ..., -4.1103,  0.7681, -0.6336],\n",
      "         [-5.1479, -0.5937, -1.9274,  ..., -4.5569,  2.4000, -0.9862],\n",
      "         [-6.4778,  0.8024, -1.5711,  ..., -2.9848,  1.0693, -0.9069]],\n",
      "\n",
      "        [[-2.7337,  1.4705, -6.5547,  ...,  0.3913,  0.2433, -0.9202],\n",
      "         [-4.6295,  2.1323,  0.0112,  ..., -2.3959, -0.7097, -2.5854],\n",
      "         [-4.1019,  1.1067,  0.2315,  ..., -1.7875, -0.5268, -1.4738],\n",
      "         ...,\n",
      "         [-2.9169,  0.7580,  3.4865,  ..., -3.4133, -1.2639,  0.5803],\n",
      "         [ 0.8326, -2.7275, -0.3892,  ..., -1.1748,  0.7352, -0.7347],\n",
      "         [-3.8762, -0.7029, -0.4404,  ..., -3.2439,  1.1178,  0.1501]]],\n",
      "       grad_fn=<AddBackward0>),)\n",
      "kwargs from analyse_common_parameters_module {}\n",
      "meta before _annotate_arg_metadata: {'mase_type': 'module_related_func', 'mase_op': 'layer_norm'}\n",
      "kwargs:  {}\n",
      "meta after _annotate_arg_metadata: {'mase_type': 'module_related_func', 'mase_op': 'layer_norm', 'args': OrderedDict([('data_in_0', {'shape': [2, 10, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]})])}\n",
      "meta after get_type_and_precision: {'mase_type': 'module_related_func', 'mase_op': 'layer_norm', 'args': OrderedDict([('data_in_0', {'shape': [2, 10, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]})])}\n",
      "weight\n",
      "bias\n",
      "meta after for: {'mase_type': 'module_related_func', 'mase_op': 'layer_norm', 'args': OrderedDict([('data_in_0', {'shape': [2, 10, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]}), ('weight', {'type': 'float', 'precision': [32], 'shape': [1, 128], 'from': None}), ('bias', {'type': 'float', 'precision': [32], 'shape': [1, 128], 'from': None})])}\n",
      "args in call_module:  (tensor([[[-3.2104,  0.3759, -4.2239,  ..., -0.8159,  0.0654,  0.6324],\n",
      "         [-3.2195,  0.8408, -0.7066,  ..., -2.0694,  0.0845,  1.5757],\n",
      "         [-3.3174,  0.3642, -0.9267,  ..., -1.6822,  0.5468,  1.9592],\n",
      "         ...,\n",
      "         [-2.8950, -0.9748,  0.5110,  ..., -2.5955, -0.1346,  0.4105],\n",
      "         [-2.7342, -0.3217, -0.8329,  ..., -2.7833,  0.7899,  0.2220],\n",
      "         [-3.2842,  0.3908, -0.6589,  ..., -1.8333,  0.0151,  0.2972]],\n",
      "\n",
      "        [[-1.9852,  0.9714, -3.5744,  ...,  0.0258, -0.4250,  0.0636],\n",
      "         [-2.6705,  1.1774, -0.0556,  ..., -1.6904, -1.0272, -0.7927],\n",
      "         [-2.5440,  0.6477,  0.0454,  ..., -1.4028, -0.9394, -0.1847],\n",
      "         ...,\n",
      "         [-1.2755,  0.3401,  1.1050,  ..., -1.7603, -1.1409,  1.0804],\n",
      "         [ 0.2947, -1.1849, -0.1830,  ..., -0.7801, -0.2139,  0.4431],\n",
      "         [-1.8876, -0.3210, -0.2044,  ..., -1.8729,  0.0302,  0.8792]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>),)\n",
      "kwargs in call_module:  {}\n",
      "HIIII from analyse_common_parameters_module\n",
      "args from analyse_common_parameters_module (tensor([[[-3.2104,  0.3759, -4.2239,  ..., -0.8159,  0.0654,  0.6324],\n",
      "         [-3.2195,  0.8408, -0.7066,  ..., -2.0694,  0.0845,  1.5757],\n",
      "         [-3.3174,  0.3642, -0.9267,  ..., -1.6822,  0.5468,  1.9592],\n",
      "         ...,\n",
      "         [-2.8950, -0.9748,  0.5110,  ..., -2.5955, -0.1346,  0.4105],\n",
      "         [-2.7342, -0.3217, -0.8329,  ..., -2.7833,  0.7899,  0.2220],\n",
      "         [-3.2842,  0.3908, -0.6589,  ..., -1.8333,  0.0151,  0.2972]],\n",
      "\n",
      "        [[-1.9852,  0.9714, -3.5744,  ...,  0.0258, -0.4250,  0.0636],\n",
      "         [-2.6705,  1.1774, -0.0556,  ..., -1.6904, -1.0272, -0.7927],\n",
      "         [-2.5440,  0.6477,  0.0454,  ..., -1.4028, -0.9394, -0.1847],\n",
      "         ...,\n",
      "         [-1.2755,  0.3401,  1.1050,  ..., -1.7603, -1.1409,  1.0804],\n",
      "         [ 0.2947, -1.1849, -0.1830,  ..., -0.7801, -0.2139,  0.4431],\n",
      "         [-1.8876, -0.3210, -0.2044,  ..., -1.8729,  0.0302,  0.8792]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>),)\n",
      "kwargs from analyse_common_parameters_module {}\n",
      "meta before _annotate_arg_metadata: {'mase_type': 'module_related_func', 'mase_op': 'linear'}\n",
      "kwargs:  {}\n",
      "meta after _annotate_arg_metadata: {'mase_type': 'module_related_func', 'mase_op': 'linear', 'args': OrderedDict([('data_in_0', {'shape': [2, 10, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]})])}\n",
      "meta after get_type_and_precision: {'mase_type': 'module_related_func', 'mase_op': 'linear', 'args': OrderedDict([('data_in_0', {'shape': [2, 10, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]})])}\n",
      "weight\n",
      "bias\n",
      "meta after for: {'mase_type': 'module_related_func', 'mase_op': 'linear', 'args': OrderedDict([('data_in_0', {'shape': [2, 10, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]}), ('weight', {'type': 'float', 'precision': [32], 'shape': [512, 128], 'from': None}), ('bias', {'type': 'float', 'precision': [32], 'shape': [1, 512], 'from': None})])}\n",
      "kwargs:  {}\n",
      "args in call_module:  (tensor([[[ 1.9286e-01,  2.3495e-01,  1.5497e+00,  ...,  1.8711e-01,\n",
      "          -1.6482e-01,  2.0480e-01],\n",
      "         [ 1.7658e-01,  1.8470e-02,  2.9655e+00,  ..., -6.2954e-03,\n",
      "          -7.7786e-02, -9.7973e-02],\n",
      "         [ 7.9390e-01,  5.2888e-01,  9.4895e-01,  ...,  3.9509e-02,\n",
      "          -1.2585e-01, -1.2164e-01],\n",
      "         ...,\n",
      "         [ 1.2641e+00,  2.6559e-01,  6.7288e-01,  ...,  1.1463e-01,\n",
      "          -1.6953e-01,  2.5607e-02],\n",
      "         [ 9.5857e-01,  5.6920e-02,  1.0216e+00,  ...,  6.0606e-01,\n",
      "          -1.6946e-01, -1.6171e-01],\n",
      "         [ 4.6259e-01,  4.1431e-03,  1.9219e+00,  ...,  7.6788e-01,\n",
      "          -1.6738e-01,  3.1475e-01]],\n",
      "\n",
      "        [[ 4.8749e-02,  7.7597e-01,  1.5119e+00,  ...,  2.7402e-01,\n",
      "          -1.6989e-01, -9.8509e-03],\n",
      "         [ 3.9689e-01,  9.1671e-01,  2.6039e+00,  ...,  7.2379e-02,\n",
      "          -1.2073e-01, -1.5587e-01],\n",
      "         [ 6.7670e-01,  1.2827e+00,  1.8828e+00,  ..., -1.4670e-03,\n",
      "          -1.1382e-01, -1.6307e-01],\n",
      "         ...,\n",
      "         [ 8.2698e-01, -1.5797e-01, -1.2902e-03,  ...,  2.6055e-02,\n",
      "          -1.3130e-01, -1.4333e-01],\n",
      "         [ 1.4966e-01,  2.5652e-01, -1.4161e-01,  ...,  4.2516e-01,\n",
      "          -1.5273e-01,  1.3092e-01],\n",
      "         [ 6.9028e-02, -9.3149e-03,  1.1797e+00,  ...,  4.5577e-01,\n",
      "          -1.1593e-01, -3.8963e-02]]], grad_fn=<GeluBackward0>),)\n",
      "kwargs in call_module:  {}\n",
      "HIIII from analyse_common_parameters_module\n",
      "args from analyse_common_parameters_module (tensor([[[ 1.9286e-01,  2.3495e-01,  1.5497e+00,  ...,  1.8711e-01,\n",
      "          -1.6482e-01,  2.0480e-01],\n",
      "         [ 1.7658e-01,  1.8470e-02,  2.9655e+00,  ..., -6.2954e-03,\n",
      "          -7.7786e-02, -9.7973e-02],\n",
      "         [ 7.9390e-01,  5.2888e-01,  9.4895e-01,  ...,  3.9509e-02,\n",
      "          -1.2585e-01, -1.2164e-01],\n",
      "         ...,\n",
      "         [ 1.2641e+00,  2.6559e-01,  6.7288e-01,  ...,  1.1463e-01,\n",
      "          -1.6953e-01,  2.5607e-02],\n",
      "         [ 9.5857e-01,  5.6920e-02,  1.0216e+00,  ...,  6.0606e-01,\n",
      "          -1.6946e-01, -1.6171e-01],\n",
      "         [ 4.6259e-01,  4.1431e-03,  1.9219e+00,  ...,  7.6788e-01,\n",
      "          -1.6738e-01,  3.1475e-01]],\n",
      "\n",
      "        [[ 4.8749e-02,  7.7597e-01,  1.5119e+00,  ...,  2.7402e-01,\n",
      "          -1.6989e-01, -9.8509e-03],\n",
      "         [ 3.9689e-01,  9.1671e-01,  2.6039e+00,  ...,  7.2379e-02,\n",
      "          -1.2073e-01, -1.5587e-01],\n",
      "         [ 6.7670e-01,  1.2827e+00,  1.8828e+00,  ..., -1.4670e-03,\n",
      "          -1.1382e-01, -1.6307e-01],\n",
      "         ...,\n",
      "         [ 8.2698e-01, -1.5797e-01, -1.2902e-03,  ...,  2.6055e-02,\n",
      "          -1.3130e-01, -1.4333e-01],\n",
      "         [ 1.4966e-01,  2.5652e-01, -1.4161e-01,  ...,  4.2516e-01,\n",
      "          -1.5273e-01,  1.3092e-01],\n",
      "         [ 6.9028e-02, -9.3149e-03,  1.1797e+00,  ...,  4.5577e-01,\n",
      "          -1.1593e-01, -3.8963e-02]]], grad_fn=<GeluBackward0>),)\n",
      "kwargs from analyse_common_parameters_module {}\n",
      "meta before _annotate_arg_metadata: {'mase_type': 'module_related_func', 'mase_op': 'linear'}\n",
      "kwargs:  {}\n",
      "meta after _annotate_arg_metadata: {'mase_type': 'module_related_func', 'mase_op': 'linear', 'args': OrderedDict([('data_in_0', {'shape': [2, 10, 512], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]})])}\n",
      "meta after get_type_and_precision: {'mase_type': 'module_related_func', 'mase_op': 'linear', 'args': OrderedDict([('data_in_0', {'shape': [2, 10, 512], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]})])}\n",
      "weight\n",
      "bias\n",
      "meta after for: {'mase_type': 'module_related_func', 'mase_op': 'linear', 'args': OrderedDict([('data_in_0', {'shape': [2, 10, 512], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]}), ('weight', {'type': 'float', 'precision': [32], 'shape': [128, 512], 'from': None}), ('bias', {'type': 'float', 'precision': [32], 'shape': [1, 128], 'from': None})])}\n",
      "args in call_module:  (tensor([[[ 0.5728, -0.4535,  0.6656,  ..., -0.4396,  0.5755,  0.0420],\n",
      "         [ 0.7189, -0.0957,  0.0671,  ...,  0.4572,  0.0378,  0.3877],\n",
      "         [ 0.1518, -0.4558,  0.0576,  ..., -0.2358,  0.2616,  0.5815],\n",
      "         ...,\n",
      "         [ 0.7816, -0.4846,  0.0888,  ..., -0.0799,  0.2969,  0.0830],\n",
      "         [ 0.7256, -0.3127,  0.1065,  ...,  0.0811, -0.2507,  0.1728],\n",
      "         [ 0.3125, -0.4127,  0.5740,  ..., -0.4628,  0.3488,  0.2541]],\n",
      "\n",
      "        [[ 0.2591, -0.6040,  0.9030,  ..., -0.4296,  0.5977,  0.7894],\n",
      "         [ 0.0689, -0.2821,  0.4373,  ..., -0.6361,  0.6068,  0.7132],\n",
      "         [ 0.2372,  0.2490,  0.2086,  ...,  0.0206,  0.1601,  0.4527],\n",
      "         ...,\n",
      "         [-0.5717,  0.1253,  0.2439,  ...,  0.2647, -0.3383,  0.1386],\n",
      "         [ 0.0559, -0.1194,  0.2379,  ...,  0.3643, -0.2901, -0.0055],\n",
      "         [ 0.2307, -0.4741,  0.6187,  ..., -0.4628,  0.2942,  0.3540]]],\n",
      "       grad_fn=<ViewBackward0>),)\n",
      "kwargs in call_module:  {}\n",
      "HIIII from analyse_common_parameters_module\n",
      "args from analyse_common_parameters_module (tensor([[[ 0.5728, -0.4535,  0.6656,  ..., -0.4396,  0.5755,  0.0420],\n",
      "         [ 0.7189, -0.0957,  0.0671,  ...,  0.4572,  0.0378,  0.3877],\n",
      "         [ 0.1518, -0.4558,  0.0576,  ..., -0.2358,  0.2616,  0.5815],\n",
      "         ...,\n",
      "         [ 0.7816, -0.4846,  0.0888,  ..., -0.0799,  0.2969,  0.0830],\n",
      "         [ 0.7256, -0.3127,  0.1065,  ...,  0.0811, -0.2507,  0.1728],\n",
      "         [ 0.3125, -0.4127,  0.5740,  ..., -0.4628,  0.3488,  0.2541]],\n",
      "\n",
      "        [[ 0.2591, -0.6040,  0.9030,  ..., -0.4296,  0.5977,  0.7894],\n",
      "         [ 0.0689, -0.2821,  0.4373,  ..., -0.6361,  0.6068,  0.7132],\n",
      "         [ 0.2372,  0.2490,  0.2086,  ...,  0.0206,  0.1601,  0.4527],\n",
      "         ...,\n",
      "         [-0.5717,  0.1253,  0.2439,  ...,  0.2647, -0.3383,  0.1386],\n",
      "         [ 0.0559, -0.1194,  0.2379,  ...,  0.3643, -0.2901, -0.0055],\n",
      "         [ 0.2307, -0.4741,  0.6187,  ..., -0.4628,  0.2942,  0.3540]]],\n",
      "       grad_fn=<ViewBackward0>),)\n",
      "kwargs from analyse_common_parameters_module {}\n",
      "meta before _annotate_arg_metadata: {'mase_type': 'module_related_func', 'mase_op': 'dropout'}\n",
      "kwargs:  {}\n",
      "meta after _annotate_arg_metadata: {'mase_type': 'module_related_func', 'mase_op': 'dropout', 'args': OrderedDict([('data_in_0', {'shape': [2, 10, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]})])}\n",
      "meta after get_type_and_precision: {'mase_type': 'module_related_func', 'mase_op': 'dropout', 'args': OrderedDict([('data_in_0', {'shape': [2, 10, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]})])}\n",
      "meta after for: {'mase_type': 'module_related_func', 'mase_op': 'dropout', 'args': OrderedDict([('data_in_0', {'shape': [2, 10, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]})])}\n",
      "kwargs:  {}\n",
      "args in call_module:  (tensor([[[-2.6377, -0.0776, -3.5583,  ..., -1.2555,  0.6409,  0.6745],\n",
      "         [-2.5006,  0.7451, -0.6395,  ..., -1.6121,  0.1223,  1.9634],\n",
      "         [-3.1656, -0.0916, -0.8691,  ..., -1.9180,  0.8084,  2.5407],\n",
      "         ...,\n",
      "         [-2.1133, -1.4594,  0.5999,  ..., -2.6754,  0.1624,  0.4934],\n",
      "         [-2.0086, -0.6343, -0.7264,  ..., -2.7022,  0.5393,  0.3947],\n",
      "         [-2.9717, -0.0219, -0.0849,  ..., -2.2962,  0.3640,  0.5514]],\n",
      "\n",
      "        [[-1.7261,  0.3673, -2.6714,  ..., -0.4038,  0.1728,  0.8530],\n",
      "         [-2.6016,  0.8953,  0.3817,  ..., -2.3265, -0.4204, -0.0794],\n",
      "         [-2.3068,  0.8966,  0.2540,  ..., -1.3821, -0.7792,  0.2679],\n",
      "         ...,\n",
      "         [-1.8472,  0.4654,  1.3490,  ..., -1.4956, -1.4792,  1.2190],\n",
      "         [ 0.3506, -1.3043,  0.0549,  ..., -0.4158, -0.5040,  0.4376],\n",
      "         [-1.6568, -0.7951,  0.4143,  ..., -2.3358,  0.3244,  1.2331]]],\n",
      "       grad_fn=<AddBackward0>),)\n",
      "kwargs in call_module:  {}\n",
      "HIIII from analyse_common_parameters_module\n",
      "args from analyse_common_parameters_module (tensor([[[-2.6377, -0.0776, -3.5583,  ..., -1.2555,  0.6409,  0.6745],\n",
      "         [-2.5006,  0.7451, -0.6395,  ..., -1.6121,  0.1223,  1.9634],\n",
      "         [-3.1656, -0.0916, -0.8691,  ..., -1.9180,  0.8084,  2.5407],\n",
      "         ...,\n",
      "         [-2.1133, -1.4594,  0.5999,  ..., -2.6754,  0.1624,  0.4934],\n",
      "         [-2.0086, -0.6343, -0.7264,  ..., -2.7022,  0.5393,  0.3947],\n",
      "         [-2.9717, -0.0219, -0.0849,  ..., -2.2962,  0.3640,  0.5514]],\n",
      "\n",
      "        [[-1.7261,  0.3673, -2.6714,  ..., -0.4038,  0.1728,  0.8530],\n",
      "         [-2.6016,  0.8953,  0.3817,  ..., -2.3265, -0.4204, -0.0794],\n",
      "         [-2.3068,  0.8966,  0.2540,  ..., -1.3821, -0.7792,  0.2679],\n",
      "         ...,\n",
      "         [-1.8472,  0.4654,  1.3490,  ..., -1.4956, -1.4792,  1.2190],\n",
      "         [ 0.3506, -1.3043,  0.0549,  ..., -0.4158, -0.5040,  0.4376],\n",
      "         [-1.6568, -0.7951,  0.4143,  ..., -2.3358,  0.3244,  1.2331]]],\n",
      "       grad_fn=<AddBackward0>),)\n",
      "kwargs from analyse_common_parameters_module {}\n",
      "meta before _annotate_arg_metadata: {'mase_type': 'module_related_func', 'mase_op': 'layer_norm'}\n",
      "kwargs:  {}\n",
      "meta after _annotate_arg_metadata: {'mase_type': 'module_related_func', 'mase_op': 'layer_norm', 'args': OrderedDict([('data_in_0', {'shape': [2, 10, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]})])}\n",
      "meta after get_type_and_precision: {'mase_type': 'module_related_func', 'mase_op': 'layer_norm', 'args': OrderedDict([('data_in_0', {'shape': [2, 10, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]})])}\n",
      "weight\n",
      "bias\n",
      "meta after for: {'mase_type': 'module_related_func', 'mase_op': 'layer_norm', 'args': OrderedDict([('data_in_0', {'shape': [2, 10, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]}), ('weight', {'type': 'float', 'precision': [32], 'shape': [1, 128], 'from': None}), ('bias', {'type': 'float', 'precision': [32], 'shape': [1, 128], 'from': None})])}\n",
      "kwargs:  {}\n",
      "args in call_module:  (tensor([[-2.6047e+00, -5.6908e-02, -4.0176e+00, -2.4736e+00,  1.3022e-01,\n",
      "          5.8118e-01, -5.7153e-01,  1.9127e+00, -1.1805e+00,  6.9020e-01,\n",
      "          4.5442e-01,  3.2954e-01, -1.3788e+00,  6.6789e-01,  1.5465e+00,\n",
      "         -1.1459e+00, -8.4317e-01, -9.6472e-01, -1.8232e+00,  4.2713e-01,\n",
      "         -1.9306e-01, -9.6682e-02,  1.5611e+00,  6.5784e-01,  1.0610e+00,\n",
      "         -1.4607e+00,  1.0741e+00,  1.5929e+00, -4.6406e-01,  5.0152e-01,\n",
      "         -5.0161e-01, -1.0759e+00, -2.7925e+00,  9.2734e-01,  9.3553e-01,\n",
      "         -1.5886e+00, -6.2240e-01,  6.1838e-02, -3.0539e+00, -1.2681e+00,\n",
      "          2.0045e-01, -1.8220e+00,  1.4676e+00, -9.3578e-01, -2.9759e-01,\n",
      "         -1.8378e+00, -7.1860e-01, -8.7553e-01,  6.2708e-01, -6.4997e-01,\n",
      "         -4.7458e-01,  1.6183e+00,  1.2467e+00,  3.2701e-03,  5.1466e-02,\n",
      "         -4.2258e-01,  1.0262e+00,  1.0007e+00, -6.8735e-01,  1.4073e+00,\n",
      "          1.1230e+00, -9.3882e-01, -1.4537e+00, -1.6854e+00, -3.8300e-01,\n",
      "          9.2867e-01,  3.2779e-01,  9.0853e-01,  4.3367e-02,  4.9259e-01,\n",
      "          9.6623e-02, -6.6455e-01, -1.3066e-01,  5.8354e-01, -5.4339e-01,\n",
      "          4.6123e-01,  2.1266e-01,  7.9008e-01,  1.4543e+00,  5.6157e-01,\n",
      "         -2.4691e-01,  1.4524e-01,  7.5035e-01,  1.0509e+00,  5.8655e-01,\n",
      "          1.5855e-01, -2.8421e-01, -6.3863e-01,  1.7643e+00, -1.9278e+00,\n",
      "          1.5233e+00,  3.3054e-01, -7.0186e-01,  8.9800e-01,  8.6959e-01,\n",
      "          1.2072e+00,  5.4017e-01,  2.1079e-01,  7.9370e-02, -5.8165e-02,\n",
      "         -8.9967e-01, -3.7194e-01,  4.4542e-01, -4.2422e-01,  1.5958e+00,\n",
      "         -1.8875e+00,  5.8101e-01,  1.7893e-01,  3.2174e-01, -1.1472e+00,\n",
      "         -4.8322e-01,  7.3665e-01, -4.2679e-01,  1.3967e+00,  4.6592e-01,\n",
      "          1.5134e+00, -1.9747e-01, -1.3177e+00,  1.0626e+00, -3.6244e-01,\n",
      "          1.3543e-01,  6.9455e-01,  1.1900e-01, -1.1985e-01, -2.8220e+00,\n",
      "         -1.2309e+00,  4.6699e-01,  7.6280e-01],\n",
      "        [-1.6621e+00,  3.3484e-01, -2.9486e+00, -2.4466e+00, -4.0572e-01,\n",
      "          1.4066e+00,  7.9469e-02,  2.0086e+00, -5.5306e-01, -2.7301e-01,\n",
      "         -1.1028e-01,  4.6192e-01,  1.3430e-01,  9.7812e-01,  2.8846e+00,\n",
      "         -6.4101e-01, -2.3083e+00, -2.4953e-01, -8.5544e-01,  6.0582e-01,\n",
      "         -8.6941e-01, -7.0131e-01,  2.4672e+00, -3.1508e-01,  1.3333e+00,\n",
      "         -6.9306e-01,  1.0707e+00,  1.5821e+00,  2.1426e-02, -9.7394e-01,\n",
      "         -1.2321e+00, -1.1484e+00, -2.0828e+00, -1.2286e-01,  5.7212e-01,\n",
      "         -7.5937e-01, -7.9089e-02,  1.9369e-01, -1.8630e+00, -1.2244e+00,\n",
      "          1.2822e+00, -1.8093e+00,  1.5238e+00, -1.2274e+00, -8.5008e-01,\n",
      "         -1.1392e+00, -7.1737e-01, -7.6570e-01,  8.5854e-01, -4.2691e-01,\n",
      "         -7.4893e-01,  1.6350e+00,  4.0738e-01,  7.3521e-02,  3.3105e-01,\n",
      "         -4.8294e-01,  1.1361e+00, -6.6051e-01, -1.1152e+00,  2.3099e+00,\n",
      "          1.0814e+00, -1.8272e+00, -2.1543e-01, -4.8265e-01, -1.0520e+00,\n",
      "          5.3280e-01, -4.1287e-01,  9.6404e-01,  3.1925e-01, -9.1659e-01,\n",
      "         -9.1037e-02, -1.2053e-01,  2.5276e-01,  7.4086e-01, -8.3982e-01,\n",
      "         -3.2924e-02, -5.1667e-01,  2.6869e-01,  1.2154e+00,  2.6070e-01,\n",
      "          3.5424e-02,  5.7172e-01,  6.2765e-01,  1.8055e+00, -1.7161e-01,\n",
      "         -6.8295e-01, -7.3400e-01, -5.7412e-01,  1.3621e+00, -1.9317e+00,\n",
      "          9.3508e-01, -7.7188e-02, -8.1092e-01,  1.5163e+00,  3.7706e-01,\n",
      "          1.7803e+00, -3.1782e-01, -8.3723e-01,  8.8905e-01,  1.8200e-01,\n",
      "          2.4901e-01,  6.6693e-01,  7.5333e-01, -1.0091e+00,  1.1987e+00,\n",
      "         -1.4132e+00,  7.4146e-01, -5.9930e-01, -2.3466e-01, -1.3463e+00,\n",
      "         -1.1671e+00,  2.0674e+00,  4.3368e-01,  2.9438e-01, -7.8581e-01,\n",
      "          1.2876e+00, -6.2541e-01, -1.4583e+00,  1.5398e+00, -1.2887e+00,\n",
      "          3.4793e-01,  1.3454e+00,  6.8748e-01, -1.1698e+00, -2.7514e+00,\n",
      "         -3.2879e-01, -3.5950e-02,  9.0546e-01]], grad_fn=<SelectBackward0>),)\n",
      "kwargs in call_module:  {}\n",
      "HIIII from analyse_common_parameters_module\n",
      "args from analyse_common_parameters_module (tensor([[-2.6047e+00, -5.6908e-02, -4.0176e+00, -2.4736e+00,  1.3022e-01,\n",
      "          5.8118e-01, -5.7153e-01,  1.9127e+00, -1.1805e+00,  6.9020e-01,\n",
      "          4.5442e-01,  3.2954e-01, -1.3788e+00,  6.6789e-01,  1.5465e+00,\n",
      "         -1.1459e+00, -8.4317e-01, -9.6472e-01, -1.8232e+00,  4.2713e-01,\n",
      "         -1.9306e-01, -9.6682e-02,  1.5611e+00,  6.5784e-01,  1.0610e+00,\n",
      "         -1.4607e+00,  1.0741e+00,  1.5929e+00, -4.6406e-01,  5.0152e-01,\n",
      "         -5.0161e-01, -1.0759e+00, -2.7925e+00,  9.2734e-01,  9.3553e-01,\n",
      "         -1.5886e+00, -6.2240e-01,  6.1838e-02, -3.0539e+00, -1.2681e+00,\n",
      "          2.0045e-01, -1.8220e+00,  1.4676e+00, -9.3578e-01, -2.9759e-01,\n",
      "         -1.8378e+00, -7.1860e-01, -8.7553e-01,  6.2708e-01, -6.4997e-01,\n",
      "         -4.7458e-01,  1.6183e+00,  1.2467e+00,  3.2701e-03,  5.1466e-02,\n",
      "         -4.2258e-01,  1.0262e+00,  1.0007e+00, -6.8735e-01,  1.4073e+00,\n",
      "          1.1230e+00, -9.3882e-01, -1.4537e+00, -1.6854e+00, -3.8300e-01,\n",
      "          9.2867e-01,  3.2779e-01,  9.0853e-01,  4.3367e-02,  4.9259e-01,\n",
      "          9.6623e-02, -6.6455e-01, -1.3066e-01,  5.8354e-01, -5.4339e-01,\n",
      "          4.6123e-01,  2.1266e-01,  7.9008e-01,  1.4543e+00,  5.6157e-01,\n",
      "         -2.4691e-01,  1.4524e-01,  7.5035e-01,  1.0509e+00,  5.8655e-01,\n",
      "          1.5855e-01, -2.8421e-01, -6.3863e-01,  1.7643e+00, -1.9278e+00,\n",
      "          1.5233e+00,  3.3054e-01, -7.0186e-01,  8.9800e-01,  8.6959e-01,\n",
      "          1.2072e+00,  5.4017e-01,  2.1079e-01,  7.9370e-02, -5.8165e-02,\n",
      "         -8.9967e-01, -3.7194e-01,  4.4542e-01, -4.2422e-01,  1.5958e+00,\n",
      "         -1.8875e+00,  5.8101e-01,  1.7893e-01,  3.2174e-01, -1.1472e+00,\n",
      "         -4.8322e-01,  7.3665e-01, -4.2679e-01,  1.3967e+00,  4.6592e-01,\n",
      "          1.5134e+00, -1.9747e-01, -1.3177e+00,  1.0626e+00, -3.6244e-01,\n",
      "          1.3543e-01,  6.9455e-01,  1.1900e-01, -1.1985e-01, -2.8220e+00,\n",
      "         -1.2309e+00,  4.6699e-01,  7.6280e-01],\n",
      "        [-1.6621e+00,  3.3484e-01, -2.9486e+00, -2.4466e+00, -4.0572e-01,\n",
      "          1.4066e+00,  7.9469e-02,  2.0086e+00, -5.5306e-01, -2.7301e-01,\n",
      "         -1.1028e-01,  4.6192e-01,  1.3430e-01,  9.7812e-01,  2.8846e+00,\n",
      "         -6.4101e-01, -2.3083e+00, -2.4953e-01, -8.5544e-01,  6.0582e-01,\n",
      "         -8.6941e-01, -7.0131e-01,  2.4672e+00, -3.1508e-01,  1.3333e+00,\n",
      "         -6.9306e-01,  1.0707e+00,  1.5821e+00,  2.1426e-02, -9.7394e-01,\n",
      "         -1.2321e+00, -1.1484e+00, -2.0828e+00, -1.2286e-01,  5.7212e-01,\n",
      "         -7.5937e-01, -7.9089e-02,  1.9369e-01, -1.8630e+00, -1.2244e+00,\n",
      "          1.2822e+00, -1.8093e+00,  1.5238e+00, -1.2274e+00, -8.5008e-01,\n",
      "         -1.1392e+00, -7.1737e-01, -7.6570e-01,  8.5854e-01, -4.2691e-01,\n",
      "         -7.4893e-01,  1.6350e+00,  4.0738e-01,  7.3521e-02,  3.3105e-01,\n",
      "         -4.8294e-01,  1.1361e+00, -6.6051e-01, -1.1152e+00,  2.3099e+00,\n",
      "          1.0814e+00, -1.8272e+00, -2.1543e-01, -4.8265e-01, -1.0520e+00,\n",
      "          5.3280e-01, -4.1287e-01,  9.6404e-01,  3.1925e-01, -9.1659e-01,\n",
      "         -9.1037e-02, -1.2053e-01,  2.5276e-01,  7.4086e-01, -8.3982e-01,\n",
      "         -3.2924e-02, -5.1667e-01,  2.6869e-01,  1.2154e+00,  2.6070e-01,\n",
      "          3.5424e-02,  5.7172e-01,  6.2765e-01,  1.8055e+00, -1.7161e-01,\n",
      "         -6.8295e-01, -7.3400e-01, -5.7412e-01,  1.3621e+00, -1.9317e+00,\n",
      "          9.3508e-01, -7.7188e-02, -8.1092e-01,  1.5163e+00,  3.7706e-01,\n",
      "          1.7803e+00, -3.1782e-01, -8.3723e-01,  8.8905e-01,  1.8200e-01,\n",
      "          2.4901e-01,  6.6693e-01,  7.5333e-01, -1.0091e+00,  1.1987e+00,\n",
      "         -1.4132e+00,  7.4146e-01, -5.9930e-01, -2.3466e-01, -1.3463e+00,\n",
      "         -1.1671e+00,  2.0674e+00,  4.3368e-01,  2.9438e-01, -7.8581e-01,\n",
      "          1.2876e+00, -6.2541e-01, -1.4583e+00,  1.5398e+00, -1.2887e+00,\n",
      "          3.4793e-01,  1.3454e+00,  6.8748e-01, -1.1698e+00, -2.7514e+00,\n",
      "         -3.2879e-01, -3.5950e-02,  9.0546e-01]], grad_fn=<SelectBackward0>),)\n",
      "kwargs from analyse_common_parameters_module {}\n",
      "meta before _annotate_arg_metadata: {'mase_type': 'module_related_func', 'mase_op': 'linear'}\n",
      "kwargs:  {}\n",
      "meta after _annotate_arg_metadata: {'mase_type': 'module_related_func', 'mase_op': 'linear', 'args': OrderedDict([('data_in_0', {'shape': [2, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]})])}\n",
      "meta after get_type_and_precision: {'mase_type': 'module_related_func', 'mase_op': 'linear', 'args': OrderedDict([('data_in_0', {'shape': [2, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]})])}\n",
      "weight\n",
      "bias\n",
      "meta after for: {'mase_type': 'module_related_func', 'mase_op': 'linear', 'args': OrderedDict([('data_in_0', {'shape': [2, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]}), ('weight', {'type': 'float', 'precision': [32], 'shape': [128, 128], 'from': None}), ('bias', {'type': 'float', 'precision': [32], 'shape': [1, 128], 'from': None})])}\n",
      "args in call_module:  (tensor([[-6.3169e+00,  6.8587e-02, -3.5956e+00,  7.5035e-01, -4.4038e+00,\n",
      "          2.5316e-01, -2.7388e+00, -1.4280e+00, -3.2537e-02, -4.1343e-02,\n",
      "         -8.6057e-01,  5.5854e-03, -1.8743e-01,  7.0835e+00, -2.8756e-01,\n",
      "         -7.8162e-01,  1.7658e+00,  6.3705e-02, -9.1811e-01,  1.4215e+00,\n",
      "          1.9118e+00,  4.9301e-03,  1.0167e+00, -3.3660e-01, -5.7913e+00,\n",
      "         -2.6496e-02, -4.4297e+00,  1.8680e+00,  2.4082e+00,  7.2149e-02,\n",
      "         -2.3556e-02, -7.9104e-02, -1.5415e+00, -6.6201e-01,  1.0727e+00,\n",
      "          4.2857e+00, -2.9725e+00, -1.0755e-01,  2.2589e+00, -3.9959e+00,\n",
      "          1.9954e+00,  2.4782e+00, -3.9064e+00,  2.4546e+00, -4.4824e+00,\n",
      "         -1.4244e-01, -3.0363e+00,  3.2992e+00,  2.0262e+00,  3.9577e+00,\n",
      "          1.4763e+00, -1.4702e+00,  1.8804e-02,  2.1262e+00,  2.7725e+00,\n",
      "          3.0907e+00, -1.8061e+00, -1.9575e+00,  1.5545e+00, -1.9900e+00,\n",
      "          1.9142e-02,  2.0416e+00, -9.1435e-01,  2.1183e+00, -1.0158e+00,\n",
      "         -6.9402e+00, -4.4416e-01,  8.0959e-01,  4.2980e-01,  2.1684e+00,\n",
      "          3.1553e+00,  1.4630e-01, -2.7478e+00, -6.7283e-02,  1.6631e+00,\n",
      "         -3.6743e+00, -5.4500e-01,  1.2188e-01, -2.3500e+00,  8.3936e-02,\n",
      "         -3.6642e-01, -1.1457e-01, -1.6481e+00, -4.8409e+00,  4.9756e+00,\n",
      "         -2.3266e+00,  6.5881e-01, -1.5325e+00, -1.2876e+00,  1.1168e+00,\n",
      "         -9.2144e-01,  2.4904e+00, -7.8281e-01,  2.1228e+00,  2.3620e-01,\n",
      "          7.3308e-01, -1.4566e+00, -3.2401e-01, -4.8932e+00, -1.7278e+00,\n",
      "         -2.7459e+00,  1.1697e-01, -4.3401e+00, -9.4332e-01, -3.2567e+00,\n",
      "         -6.2875e-01, -4.7289e+00, -2.6546e+00,  4.9459e-01,  3.2344e+00,\n",
      "          3.9321e+00,  8.5236e-01, -7.7493e-01,  4.1355e+00, -6.0454e+00,\n",
      "          2.7775e-03,  1.2982e-01, -5.2790e-02,  7.7913e-02, -4.0465e+00,\n",
      "          2.8614e-01, -5.5792e+00, -1.6153e+00,  1.4196e+00, -4.9043e+00,\n",
      "          2.0277e+00,  2.1705e+00,  3.8147e+00],\n",
      "        [-6.2230e+00,  1.8147e-01, -3.6653e+00, -1.2918e-01, -3.9383e+00,\n",
      "         -9.2159e-01, -3.0009e+00, -9.5436e-01,  1.2498e-01, -7.5171e-02,\n",
      "         -1.0008e+00, -1.2851e-01, -1.4964e-01,  7.4145e+00, -4.2737e-01,\n",
      "         -1.5978e+00,  7.5891e-01, -2.1671e-02, -8.3248e-01,  2.7739e+00,\n",
      "          1.3808e+00,  9.7651e-02,  1.9069e+00,  1.1621e+00, -6.5571e+00,\n",
      "         -2.4593e-02, -5.0903e+00,  1.1729e+00,  3.3483e+00,  3.2112e-02,\n",
      "         -2.6890e-02,  9.8493e-02, -2.4912e+00, -1.2492e+00,  1.9495e+00,\n",
      "          4.7659e+00, -1.8730e+00, -1.2771e-01,  2.9482e+00, -4.3887e+00,\n",
      "          1.4858e+00,  3.0374e+00, -4.0719e+00,  2.5256e+00, -4.4680e+00,\n",
      "         -1.6629e-01, -4.1889e+00,  2.8581e+00,  1.8314e+00,  2.9157e+00,\n",
      "          1.1694e+00, -1.6207e+00, -1.1496e-01,  1.2987e+00,  3.0364e+00,\n",
      "          2.7847e+00, -1.3545e+00, -1.6749e+00,  1.8932e+00, -1.8437e+00,\n",
      "         -1.7798e-02,  1.1590e+00, -1.6390e+00,  1.8231e+00, -7.6496e-01,\n",
      "         -6.8741e+00,  5.2686e-01,  1.7201e+00,  1.9141e+00,  2.3480e+00,\n",
      "          3.2714e+00,  1.1483e-01, -4.2301e+00,  5.3677e-03,  1.2084e+00,\n",
      "         -3.2830e+00,  3.3847e-01,  1.5871e-01, -1.8401e+00,  1.8905e-01,\n",
      "          8.6120e-01, -1.7577e-01, -1.2868e+00, -5.0869e+00,  3.8773e+00,\n",
      "         -2.5895e+00,  9.9408e-01,  5.2219e-01, -6.0541e-01,  1.3182e+00,\n",
      "         -4.7722e-01,  2.6262e+00, -5.8186e-01,  2.8801e+00, -4.4734e-01,\n",
      "          1.9695e-01, -1.6684e+00,  1.7179e-01, -4.7965e+00, -1.9523e+00,\n",
      "         -2.9879e+00,  1.4562e+00, -4.2093e+00, -8.0548e-01, -2.9373e+00,\n",
      "         -8.6955e-01, -3.1470e+00, -3.0202e+00,  4.4926e-01,  2.4559e+00,\n",
      "          4.2252e+00,  6.4123e-01, -4.4959e-01,  4.4353e+00, -6.2342e+00,\n",
      "          4.2334e-02,  1.3383e+00,  4.4795e-01,  2.6126e-01, -2.4844e+00,\n",
      "          2.8311e-01, -5.4062e+00, -9.9606e-01,  2.3326e+00, -4.3697e+00,\n",
      "          1.5399e+00,  3.0220e+00,  3.5732e+00]], grad_fn=<AddmmBackward0>),)\n",
      "kwargs in call_module:  {}\n",
      "HIIII from analyse_common_parameters_module\n",
      "args from analyse_common_parameters_module (tensor([[-6.3169e+00,  6.8587e-02, -3.5956e+00,  7.5035e-01, -4.4038e+00,\n",
      "          2.5316e-01, -2.7388e+00, -1.4280e+00, -3.2537e-02, -4.1343e-02,\n",
      "         -8.6057e-01,  5.5854e-03, -1.8743e-01,  7.0835e+00, -2.8756e-01,\n",
      "         -7.8162e-01,  1.7658e+00,  6.3705e-02, -9.1811e-01,  1.4215e+00,\n",
      "          1.9118e+00,  4.9301e-03,  1.0167e+00, -3.3660e-01, -5.7913e+00,\n",
      "         -2.6496e-02, -4.4297e+00,  1.8680e+00,  2.4082e+00,  7.2149e-02,\n",
      "         -2.3556e-02, -7.9104e-02, -1.5415e+00, -6.6201e-01,  1.0727e+00,\n",
      "          4.2857e+00, -2.9725e+00, -1.0755e-01,  2.2589e+00, -3.9959e+00,\n",
      "          1.9954e+00,  2.4782e+00, -3.9064e+00,  2.4546e+00, -4.4824e+00,\n",
      "         -1.4244e-01, -3.0363e+00,  3.2992e+00,  2.0262e+00,  3.9577e+00,\n",
      "          1.4763e+00, -1.4702e+00,  1.8804e-02,  2.1262e+00,  2.7725e+00,\n",
      "          3.0907e+00, -1.8061e+00, -1.9575e+00,  1.5545e+00, -1.9900e+00,\n",
      "          1.9142e-02,  2.0416e+00, -9.1435e-01,  2.1183e+00, -1.0158e+00,\n",
      "         -6.9402e+00, -4.4416e-01,  8.0959e-01,  4.2980e-01,  2.1684e+00,\n",
      "          3.1553e+00,  1.4630e-01, -2.7478e+00, -6.7283e-02,  1.6631e+00,\n",
      "         -3.6743e+00, -5.4500e-01,  1.2188e-01, -2.3500e+00,  8.3936e-02,\n",
      "         -3.6642e-01, -1.1457e-01, -1.6481e+00, -4.8409e+00,  4.9756e+00,\n",
      "         -2.3266e+00,  6.5881e-01, -1.5325e+00, -1.2876e+00,  1.1168e+00,\n",
      "         -9.2144e-01,  2.4904e+00, -7.8281e-01,  2.1228e+00,  2.3620e-01,\n",
      "          7.3308e-01, -1.4566e+00, -3.2401e-01, -4.8932e+00, -1.7278e+00,\n",
      "         -2.7459e+00,  1.1697e-01, -4.3401e+00, -9.4332e-01, -3.2567e+00,\n",
      "         -6.2875e-01, -4.7289e+00, -2.6546e+00,  4.9459e-01,  3.2344e+00,\n",
      "          3.9321e+00,  8.5236e-01, -7.7493e-01,  4.1355e+00, -6.0454e+00,\n",
      "          2.7775e-03,  1.2982e-01, -5.2790e-02,  7.7913e-02, -4.0465e+00,\n",
      "          2.8614e-01, -5.5792e+00, -1.6153e+00,  1.4196e+00, -4.9043e+00,\n",
      "          2.0277e+00,  2.1705e+00,  3.8147e+00],\n",
      "        [-6.2230e+00,  1.8147e-01, -3.6653e+00, -1.2918e-01, -3.9383e+00,\n",
      "         -9.2159e-01, -3.0009e+00, -9.5436e-01,  1.2498e-01, -7.5171e-02,\n",
      "         -1.0008e+00, -1.2851e-01, -1.4964e-01,  7.4145e+00, -4.2737e-01,\n",
      "         -1.5978e+00,  7.5891e-01, -2.1671e-02, -8.3248e-01,  2.7739e+00,\n",
      "          1.3808e+00,  9.7651e-02,  1.9069e+00,  1.1621e+00, -6.5571e+00,\n",
      "         -2.4593e-02, -5.0903e+00,  1.1729e+00,  3.3483e+00,  3.2112e-02,\n",
      "         -2.6890e-02,  9.8493e-02, -2.4912e+00, -1.2492e+00,  1.9495e+00,\n",
      "          4.7659e+00, -1.8730e+00, -1.2771e-01,  2.9482e+00, -4.3887e+00,\n",
      "          1.4858e+00,  3.0374e+00, -4.0719e+00,  2.5256e+00, -4.4680e+00,\n",
      "         -1.6629e-01, -4.1889e+00,  2.8581e+00,  1.8314e+00,  2.9157e+00,\n",
      "          1.1694e+00, -1.6207e+00, -1.1496e-01,  1.2987e+00,  3.0364e+00,\n",
      "          2.7847e+00, -1.3545e+00, -1.6749e+00,  1.8932e+00, -1.8437e+00,\n",
      "         -1.7798e-02,  1.1590e+00, -1.6390e+00,  1.8231e+00, -7.6496e-01,\n",
      "         -6.8741e+00,  5.2686e-01,  1.7201e+00,  1.9141e+00,  2.3480e+00,\n",
      "          3.2714e+00,  1.1483e-01, -4.2301e+00,  5.3677e-03,  1.2084e+00,\n",
      "         -3.2830e+00,  3.3847e-01,  1.5871e-01, -1.8401e+00,  1.8905e-01,\n",
      "          8.6120e-01, -1.7577e-01, -1.2868e+00, -5.0869e+00,  3.8773e+00,\n",
      "         -2.5895e+00,  9.9408e-01,  5.2219e-01, -6.0541e-01,  1.3182e+00,\n",
      "         -4.7722e-01,  2.6262e+00, -5.8186e-01,  2.8801e+00, -4.4734e-01,\n",
      "          1.9695e-01, -1.6684e+00,  1.7179e-01, -4.7965e+00, -1.9523e+00,\n",
      "         -2.9879e+00,  1.4562e+00, -4.2093e+00, -8.0548e-01, -2.9373e+00,\n",
      "         -8.6955e-01, -3.1470e+00, -3.0202e+00,  4.4926e-01,  2.4559e+00,\n",
      "          4.2252e+00,  6.4123e-01, -4.4959e-01,  4.4353e+00, -6.2342e+00,\n",
      "          4.2334e-02,  1.3383e+00,  4.4795e-01,  2.6126e-01, -2.4844e+00,\n",
      "          2.8311e-01, -5.4062e+00, -9.9606e-01,  2.3326e+00, -4.3697e+00,\n",
      "          1.5399e+00,  3.0220e+00,  3.5732e+00]], grad_fn=<AddmmBackward0>),)\n",
      "kwargs from analyse_common_parameters_module {}\n",
      "meta before _annotate_arg_metadata: {'mase_type': 'module_related_func', 'mase_op': 'tanh'}\n",
      "kwargs:  {}\n",
      "meta after _annotate_arg_metadata: {'mase_type': 'module_related_func', 'mase_op': 'tanh', 'args': OrderedDict([('data_in_0', {'shape': [2, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]})])}\n",
      "meta after get_type_and_precision: {'mase_type': 'module_related_func', 'mase_op': 'tanh', 'args': OrderedDict([('data_in_0', {'shape': [2, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]})])}\n",
      "meta after for: {'mase_type': 'module_related_func', 'mase_op': 'tanh', 'args': OrderedDict([('data_in_0', {'shape': [2, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]})])}\n",
      "args in call_module:  (tensor([[-1.0000,  0.0685, -0.9985,  0.6354, -0.9997,  0.2479, -0.9917, -0.8913,\n",
      "         -0.0325, -0.0413, -0.6966,  0.0056, -0.1853,  1.0000, -0.2799, -0.6536,\n",
      "          0.9431,  0.0636, -0.7250,  0.8899,  0.9572,  0.0049,  0.7685, -0.3244,\n",
      "         -1.0000, -0.0265, -0.9997,  0.9534,  0.9839,  0.0720, -0.0236, -0.0789,\n",
      "         -0.9124, -0.5797,  0.7905,  0.9996, -0.9948, -0.1071,  0.9784, -0.9993,\n",
      "          0.9637,  0.9860, -0.9992,  0.9854, -0.9997, -0.1415, -0.9954,  0.9973,\n",
      "          0.9658,  0.9993,  0.9008, -0.8996,  0.0188,  0.9719,  0.9922,  0.9959,\n",
      "         -0.9474, -0.9609,  0.9145, -0.9633,  0.0191,  0.9669, -0.7232,  0.9715,\n",
      "         -0.7681, -1.0000, -0.4171,  0.6694,  0.4052,  0.9742,  0.9964,  0.1453,\n",
      "         -0.9918, -0.0672,  0.9306, -0.9987, -0.4968,  0.1213, -0.9820,  0.0837,\n",
      "         -0.3509, -0.1141, -0.9286, -0.9999,  0.9999, -0.9811,  0.5776, -0.9108,\n",
      "         -0.8585,  0.8064, -0.7266,  0.9864, -0.6543,  0.9718,  0.2319,  0.6249,\n",
      "         -0.8970, -0.3131, -0.9999, -0.9388, -0.9918,  0.1164, -0.9997, -0.7367,\n",
      "         -0.9970, -0.5572, -0.9998, -0.9902,  0.4579,  0.9969,  0.9992,  0.6923,\n",
      "         -0.6498,  0.9995, -1.0000,  0.0028,  0.1291, -0.0527,  0.0778, -0.9994,\n",
      "          0.2786, -1.0000, -0.9239,  0.8895, -0.9999,  0.9659,  0.9743,  0.9990],\n",
      "        [-1.0000,  0.1795, -0.9987, -0.1285, -0.9992, -0.7266, -0.9951, -0.7418,\n",
      "          0.1243, -0.0750, -0.7619, -0.1278, -0.1485,  1.0000, -0.4031, -0.9213,\n",
      "          0.6404, -0.0217, -0.6818,  0.9922,  0.8811,  0.0973,  0.9568,  0.8217,\n",
      "         -1.0000, -0.0246, -0.9999,  0.8252,  0.9975,  0.0321, -0.0269,  0.0982,\n",
      "         -0.9864, -0.8481,  0.9603,  0.9999, -0.9539, -0.1270,  0.9945, -0.9997,\n",
      "          0.9026,  0.9954, -0.9994,  0.9873, -0.9997, -0.1648, -0.9995,  0.9934,\n",
      "          0.9500,  0.9941,  0.8241, -0.9247, -0.1145,  0.8614,  0.9954,  0.9924,\n",
      "         -0.8751, -0.9322,  0.9557, -0.9511, -0.0178,  0.8207, -0.9273,  0.9491,\n",
      "         -0.6440, -1.0000,  0.4830,  0.9379,  0.9574,  0.9819,  0.9971,  0.1143,\n",
      "         -0.9996,  0.0054,  0.8362, -0.9972,  0.3261,  0.1574, -0.9508,  0.1868,\n",
      "          0.6969, -0.1740, -0.8583, -0.9999,  0.9991, -0.9888,  0.7591,  0.4794,\n",
      "         -0.5409,  0.8663, -0.4440,  0.9896, -0.5240,  0.9937, -0.4197,  0.1944,\n",
      "         -0.9313,  0.1701, -0.9999, -0.9605, -0.9949,  0.8969, -0.9996, -0.6671,\n",
      "         -0.9944, -0.7011, -0.9963, -0.9953,  0.4213,  0.9854,  0.9996,  0.5657,\n",
      "         -0.4216,  0.9997, -1.0000,  0.0423,  0.8713,  0.4202,  0.2555, -0.9862,\n",
      "          0.2758, -1.0000, -0.7599,  0.9813, -0.9997,  0.9121,  0.9953,  0.9984]],\n",
      "       grad_fn=<TanhBackward0>),)\n",
      "kwargs in call_module:  {}\n",
      "HIIII from analyse_common_parameters_module\n",
      "args from analyse_common_parameters_module (tensor([[-1.0000,  0.0685, -0.9985,  0.6354, -0.9997,  0.2479, -0.9917, -0.8913,\n",
      "         -0.0325, -0.0413, -0.6966,  0.0056, -0.1853,  1.0000, -0.2799, -0.6536,\n",
      "          0.9431,  0.0636, -0.7250,  0.8899,  0.9572,  0.0049,  0.7685, -0.3244,\n",
      "         -1.0000, -0.0265, -0.9997,  0.9534,  0.9839,  0.0720, -0.0236, -0.0789,\n",
      "         -0.9124, -0.5797,  0.7905,  0.9996, -0.9948, -0.1071,  0.9784, -0.9993,\n",
      "          0.9637,  0.9860, -0.9992,  0.9854, -0.9997, -0.1415, -0.9954,  0.9973,\n",
      "          0.9658,  0.9993,  0.9008, -0.8996,  0.0188,  0.9719,  0.9922,  0.9959,\n",
      "         -0.9474, -0.9609,  0.9145, -0.9633,  0.0191,  0.9669, -0.7232,  0.9715,\n",
      "         -0.7681, -1.0000, -0.4171,  0.6694,  0.4052,  0.9742,  0.9964,  0.1453,\n",
      "         -0.9918, -0.0672,  0.9306, -0.9987, -0.4968,  0.1213, -0.9820,  0.0837,\n",
      "         -0.3509, -0.1141, -0.9286, -0.9999,  0.9999, -0.9811,  0.5776, -0.9108,\n",
      "         -0.8585,  0.8064, -0.7266,  0.9864, -0.6543,  0.9718,  0.2319,  0.6249,\n",
      "         -0.8970, -0.3131, -0.9999, -0.9388, -0.9918,  0.1164, -0.9997, -0.7367,\n",
      "         -0.9970, -0.5572, -0.9998, -0.9902,  0.4579,  0.9969,  0.9992,  0.6923,\n",
      "         -0.6498,  0.9995, -1.0000,  0.0028,  0.1291, -0.0527,  0.0778, -0.9994,\n",
      "          0.2786, -1.0000, -0.9239,  0.8895, -0.9999,  0.9659,  0.9743,  0.9990],\n",
      "        [-1.0000,  0.1795, -0.9987, -0.1285, -0.9992, -0.7266, -0.9951, -0.7418,\n",
      "          0.1243, -0.0750, -0.7619, -0.1278, -0.1485,  1.0000, -0.4031, -0.9213,\n",
      "          0.6404, -0.0217, -0.6818,  0.9922,  0.8811,  0.0973,  0.9568,  0.8217,\n",
      "         -1.0000, -0.0246, -0.9999,  0.8252,  0.9975,  0.0321, -0.0269,  0.0982,\n",
      "         -0.9864, -0.8481,  0.9603,  0.9999, -0.9539, -0.1270,  0.9945, -0.9997,\n",
      "          0.9026,  0.9954, -0.9994,  0.9873, -0.9997, -0.1648, -0.9995,  0.9934,\n",
      "          0.9500,  0.9941,  0.8241, -0.9247, -0.1145,  0.8614,  0.9954,  0.9924,\n",
      "         -0.8751, -0.9322,  0.9557, -0.9511, -0.0178,  0.8207, -0.9273,  0.9491,\n",
      "         -0.6440, -1.0000,  0.4830,  0.9379,  0.9574,  0.9819,  0.9971,  0.1143,\n",
      "         -0.9996,  0.0054,  0.8362, -0.9972,  0.3261,  0.1574, -0.9508,  0.1868,\n",
      "          0.6969, -0.1740, -0.8583, -0.9999,  0.9991, -0.9888,  0.7591,  0.4794,\n",
      "         -0.5409,  0.8663, -0.4440,  0.9896, -0.5240,  0.9937, -0.4197,  0.1944,\n",
      "         -0.9313,  0.1701, -0.9999, -0.9605, -0.9949,  0.8969, -0.9996, -0.6671,\n",
      "         -0.9944, -0.7011, -0.9963, -0.9953,  0.4213,  0.9854,  0.9996,  0.5657,\n",
      "         -0.4216,  0.9997, -1.0000,  0.0423,  0.8713,  0.4202,  0.2555, -0.9862,\n",
      "          0.2758, -1.0000, -0.7599,  0.9813, -0.9997,  0.9121,  0.9953,  0.9984]],\n",
      "       grad_fn=<TanhBackward0>),)\n",
      "kwargs from analyse_common_parameters_module {}\n",
      "meta before _annotate_arg_metadata: {'mase_type': 'module_related_func', 'mase_op': 'dropout'}\n",
      "kwargs:  {}\n",
      "meta after _annotate_arg_metadata: {'mase_type': 'module_related_func', 'mase_op': 'dropout', 'args': OrderedDict([('data_in_0', {'shape': [2, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]})])}\n",
      "meta after get_type_and_precision: {'mase_type': 'module_related_func', 'mase_op': 'dropout', 'args': OrderedDict([('data_in_0', {'shape': [2, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]})])}\n",
      "meta after for: {'mase_type': 'module_related_func', 'mase_op': 'dropout', 'args': OrderedDict([('data_in_0', {'shape': [2, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]})])}\n",
      "args in call_module:  (tensor([[-1.0000,  0.0685, -0.9985,  0.6354, -0.9997,  0.2479, -0.9917, -0.8913,\n",
      "         -0.0325, -0.0413, -0.6966,  0.0056, -0.1853,  1.0000, -0.2799, -0.6536,\n",
      "          0.9431,  0.0636, -0.7250,  0.8899,  0.9572,  0.0049,  0.7685, -0.3244,\n",
      "         -1.0000, -0.0265, -0.9997,  0.9534,  0.9839,  0.0720, -0.0236, -0.0789,\n",
      "         -0.9124, -0.5797,  0.7905,  0.9996, -0.9948, -0.1071,  0.9784, -0.9993,\n",
      "          0.9637,  0.9860, -0.9992,  0.9854, -0.9997, -0.1415, -0.9954,  0.9973,\n",
      "          0.9658,  0.9993,  0.9008, -0.8996,  0.0188,  0.9719,  0.9922,  0.9959,\n",
      "         -0.9474, -0.9609,  0.9145, -0.9633,  0.0191,  0.9669, -0.7232,  0.9715,\n",
      "         -0.7681, -1.0000, -0.4171,  0.6694,  0.4052,  0.9742,  0.9964,  0.1453,\n",
      "         -0.9918, -0.0672,  0.9306, -0.9987, -0.4968,  0.1213, -0.9820,  0.0837,\n",
      "         -0.3509, -0.1141, -0.9286, -0.9999,  0.9999, -0.9811,  0.5776, -0.9108,\n",
      "         -0.8585,  0.8064, -0.7266,  0.9864, -0.6543,  0.9718,  0.2319,  0.6249,\n",
      "         -0.8970, -0.3131, -0.9999, -0.9388, -0.9918,  0.1164, -0.9997, -0.7367,\n",
      "         -0.9970, -0.5572, -0.9998, -0.9902,  0.4579,  0.9969,  0.9992,  0.6923,\n",
      "         -0.6498,  0.9995, -1.0000,  0.0028,  0.1291, -0.0527,  0.0778, -0.9994,\n",
      "          0.2786, -1.0000, -0.9239,  0.8895, -0.9999,  0.9659,  0.9743,  0.9990],\n",
      "        [-1.0000,  0.1795, -0.9987, -0.1285, -0.9992, -0.7266, -0.9951, -0.7418,\n",
      "          0.1243, -0.0750, -0.7619, -0.1278, -0.1485,  1.0000, -0.4031, -0.9213,\n",
      "          0.6404, -0.0217, -0.6818,  0.9922,  0.8811,  0.0973,  0.9568,  0.8217,\n",
      "         -1.0000, -0.0246, -0.9999,  0.8252,  0.9975,  0.0321, -0.0269,  0.0982,\n",
      "         -0.9864, -0.8481,  0.9603,  0.9999, -0.9539, -0.1270,  0.9945, -0.9997,\n",
      "          0.9026,  0.9954, -0.9994,  0.9873, -0.9997, -0.1648, -0.9995,  0.9934,\n",
      "          0.9500,  0.9941,  0.8241, -0.9247, -0.1145,  0.8614,  0.9954,  0.9924,\n",
      "         -0.8751, -0.9322,  0.9557, -0.9511, -0.0178,  0.8207, -0.9273,  0.9491,\n",
      "         -0.6440, -1.0000,  0.4830,  0.9379,  0.9574,  0.9819,  0.9971,  0.1143,\n",
      "         -0.9996,  0.0054,  0.8362, -0.9972,  0.3261,  0.1574, -0.9508,  0.1868,\n",
      "          0.6969, -0.1740, -0.8583, -0.9999,  0.9991, -0.9888,  0.7591,  0.4794,\n",
      "         -0.5409,  0.8663, -0.4440,  0.9896, -0.5240,  0.9937, -0.4197,  0.1944,\n",
      "         -0.9313,  0.1701, -0.9999, -0.9605, -0.9949,  0.8969, -0.9996, -0.6671,\n",
      "         -0.9944, -0.7011, -0.9963, -0.9953,  0.4213,  0.9854,  0.9996,  0.5657,\n",
      "         -0.4216,  0.9997, -1.0000,  0.0423,  0.8713,  0.4202,  0.2555, -0.9862,\n",
      "          0.2758, -1.0000, -0.7599,  0.9813, -0.9997,  0.9121,  0.9953,  0.9984]],\n",
      "       grad_fn=<TanhBackward0>),)\n",
      "kwargs in call_module:  {}\n",
      "HIIII from analyse_common_parameters_module\n",
      "args from analyse_common_parameters_module (tensor([[-1.0000,  0.0685, -0.9985,  0.6354, -0.9997,  0.2479, -0.9917, -0.8913,\n",
      "         -0.0325, -0.0413, -0.6966,  0.0056, -0.1853,  1.0000, -0.2799, -0.6536,\n",
      "          0.9431,  0.0636, -0.7250,  0.8899,  0.9572,  0.0049,  0.7685, -0.3244,\n",
      "         -1.0000, -0.0265, -0.9997,  0.9534,  0.9839,  0.0720, -0.0236, -0.0789,\n",
      "         -0.9124, -0.5797,  0.7905,  0.9996, -0.9948, -0.1071,  0.9784, -0.9993,\n",
      "          0.9637,  0.9860, -0.9992,  0.9854, -0.9997, -0.1415, -0.9954,  0.9973,\n",
      "          0.9658,  0.9993,  0.9008, -0.8996,  0.0188,  0.9719,  0.9922,  0.9959,\n",
      "         -0.9474, -0.9609,  0.9145, -0.9633,  0.0191,  0.9669, -0.7232,  0.9715,\n",
      "         -0.7681, -1.0000, -0.4171,  0.6694,  0.4052,  0.9742,  0.9964,  0.1453,\n",
      "         -0.9918, -0.0672,  0.9306, -0.9987, -0.4968,  0.1213, -0.9820,  0.0837,\n",
      "         -0.3509, -0.1141, -0.9286, -0.9999,  0.9999, -0.9811,  0.5776, -0.9108,\n",
      "         -0.8585,  0.8064, -0.7266,  0.9864, -0.6543,  0.9718,  0.2319,  0.6249,\n",
      "         -0.8970, -0.3131, -0.9999, -0.9388, -0.9918,  0.1164, -0.9997, -0.7367,\n",
      "         -0.9970, -0.5572, -0.9998, -0.9902,  0.4579,  0.9969,  0.9992,  0.6923,\n",
      "         -0.6498,  0.9995, -1.0000,  0.0028,  0.1291, -0.0527,  0.0778, -0.9994,\n",
      "          0.2786, -1.0000, -0.9239,  0.8895, -0.9999,  0.9659,  0.9743,  0.9990],\n",
      "        [-1.0000,  0.1795, -0.9987, -0.1285, -0.9992, -0.7266, -0.9951, -0.7418,\n",
      "          0.1243, -0.0750, -0.7619, -0.1278, -0.1485,  1.0000, -0.4031, -0.9213,\n",
      "          0.6404, -0.0217, -0.6818,  0.9922,  0.8811,  0.0973,  0.9568,  0.8217,\n",
      "         -1.0000, -0.0246, -0.9999,  0.8252,  0.9975,  0.0321, -0.0269,  0.0982,\n",
      "         -0.9864, -0.8481,  0.9603,  0.9999, -0.9539, -0.1270,  0.9945, -0.9997,\n",
      "          0.9026,  0.9954, -0.9994,  0.9873, -0.9997, -0.1648, -0.9995,  0.9934,\n",
      "          0.9500,  0.9941,  0.8241, -0.9247, -0.1145,  0.8614,  0.9954,  0.9924,\n",
      "         -0.8751, -0.9322,  0.9557, -0.9511, -0.0178,  0.8207, -0.9273,  0.9491,\n",
      "         -0.6440, -1.0000,  0.4830,  0.9379,  0.9574,  0.9819,  0.9971,  0.1143,\n",
      "         -0.9996,  0.0054,  0.8362, -0.9972,  0.3261,  0.1574, -0.9508,  0.1868,\n",
      "          0.6969, -0.1740, -0.8583, -0.9999,  0.9991, -0.9888,  0.7591,  0.4794,\n",
      "         -0.5409,  0.8663, -0.4440,  0.9896, -0.5240,  0.9937, -0.4197,  0.1944,\n",
      "         -0.9313,  0.1701, -0.9999, -0.9605, -0.9949,  0.8969, -0.9996, -0.6671,\n",
      "         -0.9944, -0.7011, -0.9963, -0.9953,  0.4213,  0.9854,  0.9996,  0.5657,\n",
      "         -0.4216,  0.9997, -1.0000,  0.0423,  0.8713,  0.4202,  0.2555, -0.9862,\n",
      "          0.2758, -1.0000, -0.7599,  0.9813, -0.9997,  0.9121,  0.9953,  0.9984]],\n",
      "       grad_fn=<TanhBackward0>),)\n",
      "kwargs from analyse_common_parameters_module {}\n",
      "meta before _annotate_arg_metadata: {'mase_type': 'module_related_func', 'mase_op': 'linear'}\n",
      "kwargs:  {}\n",
      "meta after _annotate_arg_metadata: {'mase_type': 'module_related_func', 'mase_op': 'linear', 'args': OrderedDict([('data_in_0', {'shape': [2, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]})])}\n",
      "meta after get_type_and_precision: {'mase_type': 'module_related_func', 'mase_op': 'linear', 'args': OrderedDict([('data_in_0', {'shape': [2, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]})])}\n",
      "weight\n",
      "bias\n",
      "meta after for: {'mase_type': 'module_related_func', 'mase_op': 'linear', 'args': OrderedDict([('data_in_0', {'shape': [2, 128], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]}), ('weight', {'type': 'float', 'precision': [32], 'shape': [2, 128], 'from': None}), ('bias', {'type': 'float', 'precision': [32], 'shape': [1, 2], 'from': None})])}\n",
      "wobucao in add_common_metadata\n",
      "nihappp in add_common_metadata\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import chop.passes as passes\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "dummy_input = tokenizer(\n",
    "    [\n",
    "        \"AI may take over the world one day\",\n",
    "        \"This is why you should learn ADLS\",\n",
    "    ],\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "print (dummy_input)\n",
    "# after generating FX IR, init is used to initializes a MaseMetdata object for each node in the FX graph\n",
    "mg, _ = passes.init_metadata_analysis_pass(mg)\n",
    "#  add_common:\n",
    "# 1. Determine the type of operation (e.g., add, matmul, relu) performed by each node. This info is added in node.meta[\"mase\"][\"common\"][\"mase_op\"]\n",
    "    # the mase_op is stored inside the \"common\" key, which is itself part of the \"mase\" metadata dictionary attached to each node\n",
    "# 2. forward pass of the entire mode with a dummy input to observe the tensor metadata\n",
    "# the add_common_metadata_analysis_pass takes mg and pass_arg (a dict) as inputs\n",
    "# The tensor metadata is then stored in node.meta[\"mase\"][\"common\"][\"args\"] and node.meta[\"mase\"][\"common\"][\"results\"]\n",
    "# e.g. How a node meta looks like:\n",
    "\"\"\"\n",
    "node.meta = {\n",
    "    \"mase\": {\n",
    "        \"common\": {\n",
    "            \"mase_op\": \"matmul\",           # The type of operation (e.g., matrix multiplication).\n",
    "            \"args\": [                      # Input tensor metadata.\n",
    "                {\"shape\": [1, 512], \"dtype\": \"float32\", \"stride\": [512, 1]},\n",
    "                {\"shape\": [512, 512], \"dtype\": \"float32\", \"stride\": [512, 1]},\n",
    "            ],\n",
    "            \"results\": [                   # Output tensor metadata.\n",
    "                {\"shape\": [1, 512], \"dtype\": \"float32\", \"stride\": [512, 1]},\n",
    "            ],\n",
    "        },\n",
    "        \"hardware\": {},                    # Placeholder for hardware metadata.\n",
    "        \"software\": {},                    # Placeholder for software metadata.\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "mg, _ = passes.add_common_metadata_analysis_pass(\n",
    "    mg,\n",
    "    pass_args={\n",
    "        \"dummy_in\": dummy_input,\n",
    "        \"add_value\": False,\n",
    "    },\n",
    ")\n",
    "mg.draw(\"nihap.svg\")\n",
    "\n",
    "#  The output shown below represents the results of each node after the input token passing each node,\n",
    "# could be the node for intermediate layer of the model, could be input node, or could be the node for ouput of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: writing an analysis pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing an analysis pass is often simple - in the following example, we implement a pass which counts the number of dropout layers in the graph. We also show how to use the `get_logger` API from `chop.tools` to provide information about the graph to the user at runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mFound dropout module: bert.embeddings.dropout\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mFound dropout module: bert.encoder.layer.0.attention.output.dropout\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mFound dropout module: bert.encoder.layer.0.output.dropout\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mFound dropout module: bert.encoder.layer.1.attention.output.dropout\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mFound dropout module: bert.encoder.layer.1.output.dropout\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mFound dropout module: dropout\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDropout count is: 6\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from chop.tools import get_logger\n",
    "\n",
    "logger = get_logger(\"mase_logger\")\n",
    "logger.setLevel(\"INFO\")\n",
    "\n",
    "\n",
    "def count_dropout_analysis_pass(mg, pass_args={}):\n",
    "\n",
    "    dropout_modules = 0\n",
    "    dropout_functions = 0\n",
    "\n",
    "    for node in mg.fx_graph.nodes:\n",
    "        if node.op == \"call_module\" and \"dropout\" in node.target:\n",
    "            logger.info(f\"Found dropout module: {node.target}\")\n",
    "            dropout_modules += 1\n",
    "        else:\n",
    "            logger.debug(f\"Skipping node: {node.target}\")\n",
    "\n",
    "    return mg, {\"dropout_count\": dropout_modules + dropout_functions}\n",
    "\n",
    "\n",
    "mg, pass_out = count_dropout_analysis_pass(mg)\n",
    "\n",
    "logger.info(f\"Dropout count is: {pass_out['dropout_count']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: writing a transform pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we delete all dropout nodes from the graph. Dropout is a useful training technique, but it doesn't have any effect on the activations at inference time, hence these nodes can be removed to simplify the graph. Transform passes may involve deleting, inserting, or replacing nodes in the graph. When doing this, we must carefully handle the arguments to ensure the graph topology is valid after transformation. Before erasing the dropout nodes, we must first find all other nodes that take the output of the dropout node as arguments, by running `node.replace_all_uses_with`. Without doing this, there would still be nodes that require arguments that no longer exist. \n",
    "\n",
    "> **Task**: Delete the call to `replace_all_uses_with` to verify that FX will report a RuntimeError.\n",
    "\n",
    "Finally, we rerun the analysis pass previously implemented to recount the number of dropout modules, and verify this is now zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.fx as fx\n",
    "\n",
    "\n",
    "def remove_dropout_transform_pass(mg, pass_args={}):\n",
    "\n",
    "    for node in mg.fx_graph.nodes:\n",
    "        if node.op == \"call_module\" and \"dropout\" in node.target:\n",
    "            logger.info(f\"Removing dropout module: {node.target}\")\n",
    "\n",
    "            # Replace all users of the dropout node with its parent node\n",
    "            parent_node = node.args[0]\n",
    "            logger.debug(f\"This dropout module has parent node: {parent_node}\")\n",
    "            node.replace_all_uses_with(parent_node)\n",
    "\n",
    "            # Erase the dropout node\n",
    "            mg.fx_graph.erase_node(node)\n",
    "        else:\n",
    "            logger.debug(f\"Skipping node: {node.target}\")\n",
    "\n",
    "    return mg, {}\n",
    "\n",
    "\n",
    "mg, _ = remove_dropout_transform_pass(mg)\n",
    "mg, pass_out = count_dropout_analysis_pass(mg)\n",
    "\n",
    "assert pass_out[\"dropout_count\"] == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting the MaseGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can export the transformed MaseGraph to be shared and used in future tutorials, by running the `mg.export()` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mExporting MaseGraph to /root/tutorial_1.pt, /root/tutorial_1.mz\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mExporting GraphModule to /root/tutorial_1.pt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mExporting MaseMetadata to /root/tutorial_1.mz\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "mg.export(f\"{Path.home()}/tutorial_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After exporting, you can pick up where you left off by running the `MaseGraph.from_checkpoint` constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_mg = MaseGraph.from_checkpoint(f\"{Path.home()}/tutorial_1\",safe_load=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
