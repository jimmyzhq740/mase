{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hardware Emit Pass\n",
    "The `emit_verilog` transform pass generates a top-level RTL file and testbench file according to the `MaseGraph`, which includes a hardware implementation of each layer in the network. This top-level file instantiates modules from the `components` library in MASE and/or modules generated using [HLS](https://en.wikipedia.org/wiki/High-level_synthesis), when internal components are not available. The hardware can then be simulated using [Verilator](https://www.veripool.org/verilator/), or deployed on an FPGA.\n",
    "\n",
    "First, add Machop to your system PATH (if you haven't already done so) and import the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mSet logging level to debug\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage:\n",
      "        verilator --help\n",
      "        verilator --version\n",
      "        verilator --binary -j 0 [options] [source_files.v]... [opt_c_files.cpp/c/cc/a/o/so]\n",
      "        verilator --cc [options] [source_files.v]... [opt_c_files.cpp/c/cc/a/o/so]\n",
      "        verilator --sc [options] [source_files.v]... [opt_c_files.cpp/c/cc/a/o/so]\n",
      "        verilator --lint-only -Wall [source_files.v]...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "\n",
    "from chop.ir.graph.mase_graph import MaseGraph\n",
    "\n",
    "from chop.passes.graph.analysis import (\n",
    "    init_metadata_analysis_pass,\n",
    "    add_common_metadata_analysis_pass,\n",
    "    add_hardware_metadata_analysis_pass,\n",
    "    add_software_metadata_analysis_pass,\n",
    "    report_node_type_analysis_pass,\n",
    ")\n",
    "\n",
    "from chop.passes.graph.transforms import (\n",
    "    emit_verilog_top_transform_pass,\n",
    "    emit_internal_rtl_transform_pass,\n",
    "    emit_bram_transform_pass,\n",
    "    emit_cocotb_transform_pass,\n",
    "    quantize_transform_pass,\n",
    ")\n",
    "\n",
    "from chop.tools.logger import set_logging_verbosity\n",
    "\n",
    "set_logging_verbosity(\"debug\")\n",
    "\n",
    "import toml\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# TO DO: remove\n",
    "import os\n",
    "os.environ[\"PATH\"] = \"/opt/homebrew/bin:\" + os.environ[\"PATH\"]\n",
    "!verilator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "  def __init__(self, num_classes=10):\n",
    "    # initialize the parent class—in this case, the nn.Module class from PyTorch.\n",
    "    super().__init__()\n",
    "\n",
    "    # Define layers in the model\n",
    "    # When you instantiate a layer like nn.Conv2d inside the forward method,\n",
    "    # it is created anew each time forward is called. Because that layer is constructed at runtime during every forward pass,\n",
    "    # its weights are randomly re-initialized every time.\n",
    "    # Hence the weights will not be tracked by PyTorch’s parameter-registration mechanism (they won’t show up in model.parameters()), and\n",
    "    # Won’t get updated during backpropagation (since they’re re-created each time),\n",
    "    # Are randomly re-initialized on every forward pass, which makes learning impossible.\n",
    "\n",
    "    # Convolutional layers\n",
    "    # kernel_size: the size of the CNN filter of small matrix that has weights\n",
    "    # kernel_size=3: the kernel/filter will have both height and width of 3 (i.e., 3×3).\n",
    "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "\n",
    "    # Pooling layer\n",
    "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    # Fully-connected layers\n",
    "    # # After two 2x2 poolings on a 28x28 input, the spatial dimension is reduced to 7x7.\n",
    "    # Hence, the input to the first linear layer is 64 * 7 * 7.\n",
    "    self.fc1 = nn.Linear(in_features=64 * 7 * 7, out_features=128)\n",
    "    self.fc2 = nn.Linear(in_features=128, out_features=num_classes)\n",
    "\n",
    "  def forward(self, x):\n",
    "    # Convolution -> ReLU -> Pool\n",
    "    x = self.pool(F.relu(self.conv1(x)))\n",
    "    x = self.pool(F.relu(self.conv2(x)))\n",
    "\n",
    "    # Flatten\n",
    "    x = x.view(x.size(0), -1)  # same as x.view(-1, 64*7*7)\n",
    "\n",
    "    # Fully-connected -> ReLU\n",
    "    x = F.relu(self.fc1(x))\n",
    "\n",
    "    # Final layer (logits)\n",
    "    x = self.fc2(x)\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SingleConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # A single 2D convolution layer\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=1,\n",
    "            # input channel size of one example is 1, i.e. grey scale\n",
    "            # output channel size becomes 2.\n",
    "            # out_channels=2, that convolution layer learns two distinct filters\n",
    "            out_channels=2,\n",
    "            kernel_size=3,\n",
    "            padding=1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply convolution (and optionally an activation)\n",
    "        # Here we show it with a ReLU, but you can remove F.relu(...) if you want pure convolution\n",
    "        x=self.conv1(x)\n",
    "        # x = F.relu(self.conv1(x))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 1, 4, 4])\n",
      "Input tensor:\n",
      " tensor([[[[-1.1258, -1.1524, -0.2506, -0.4339],\n",
      "          [ 0.8487,  0.6920, -0.3160, -2.1152],\n",
      "          [ 0.3223, -1.2633,  0.3500,  0.3081],\n",
      "          [ 0.1198,  1.2377,  1.1168, -0.2473]]]])\n",
      "\n",
      "Output shape: torch.Size([1, 2, 4, 4])\n",
      "Output tensor:\n",
      " tensor([[[[-0.5136, -0.1470, -0.2287, -0.7550],\n",
      "          [ 0.2449, -1.0380, -0.9036, -0.5101],\n",
      "          [-0.5668,  0.2264,  0.7911, -0.8494],\n",
      "          [ 0.4742, -0.0806, -0.5119, -0.3172]],\n",
      "\n",
      "         [[-0.3570,  0.1973,  0.5993,  0.1430],\n",
      "          [-0.3330, -0.5056, -0.6247, -0.1729],\n",
      "          [-0.3489, -0.3864,  0.6195, -0.6861],\n",
      "          [ 0.0048, -1.0650, -0.6682, -0.4203]]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n",
      "Weights:\n",
      " Parameter containing:\n",
      "tensor([[[[ 0.1318,  0.2000, -0.2260],\n",
      "          [-0.1452,  0.1211,  0.2768],\n",
      "          [-0.0686,  0.2494, -0.0537]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0353,  0.3018, -0.3092],\n",
      "          [-0.2098, -0.0844, -0.1299],\n",
      "          [ 0.2880, -0.2161, -0.1534]]]], requires_grad=True)\n",
      "\n",
      "Bias:\n",
      " Parameter containing:\n",
      "tensor([-0.2329, -0.3122], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W301 22:49:30.350090492 NNPACK.cpp:62] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Create a random batch of 1 image, 4×4 (grayscale)\n",
    "    x = torch.randn((1, 1, 4, 4))\n",
    "\n",
    "    model = SingleConvNet()\n",
    "    output = model(x)\n",
    "\n",
    "    print(\"Input shape:\", x.shape)\n",
    "    print(\"Input tensor:\\n\", x)        # Show the actual input values\n",
    "\n",
    "    print(\"\\nOutput shape:\", output.shape)\n",
    "    print(\"Output tensor:\\n\", output)  # Show the actual output values\n",
    "\n",
    "    print(\"Weights:\\n\", model.conv1.weight)\n",
    "    print(\"\\nBias:\\n\", model.conv1.bias)\n",
    "\n",
    "# Weights, bias are random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36mDEBUG   \u001b[0m \u001b[34mgraph():\n",
      "    %x : [num_users=1] = placeholder[target=x]\n",
      "    %conv1 : [num_users=1] = call_module[target=conv1](args = (%x,), kwargs = {})\n",
      "    return conv1\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.0209, -0.7185,  0.5186],\n",
      "          [-1.3125,  0.1920,  0.5428],\n",
      "          [-2.2188,  0.2590, -1.0297]]]])\n",
      "Hellos in add_common_metadata\n",
      "sigoyi in add_common_metadata\n",
      "wocao in add_common_metadata\n",
      "wobucao in add_common_metadata\n",
      "nihappp in add_common_metadata\n"
     ]
    }
   ],
   "source": [
    "cnn = SingleConvNet()\n",
    "mg = MaseGraph(model=cnn)\n",
    "\n",
    "# Provide a dummy input for the graph so it can use for tracing\n",
    "batch_size = 1\n",
    "# x = torch.randn((batch_size, 2, 2))\n",
    "# batch_size: number of examples\n",
    "# 1, 4,4,: each example has 1 channel, each channel has a size of 4x4\n",
    "x = torch.randn((batch_size, 1, 3, 3))\n",
    "print(x)\n",
    "dummy_in = {\"x\": x}\n",
    "\n",
    "mg, _ = init_metadata_analysis_pass(mg, None)\n",
    "mg, _ = add_common_metadata_analysis_pass(\n",
    "    mg, {\"dummy_in\": dummy_in, \"add_value\": False}\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mInspecting graph [add_common_node_type_analysis_pass]\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Node name    Fx Node op    Mase type            Mase op      Value type\n",
      "-----------  ------------  -------------------  -----------  ------------\n",
      "x            placeholder   placeholder          placeholder  NA\n",
      "conv1        call_module   module_related_func  conv2d       fixed\n",
      "output       output        output               output       NA\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "placeholder\n",
      "node_config:  {'name': 'fixed', 'data_in_width': 8, 'data_in_frac_width': 5, 'weight_width': 8, 'weight_frac_width': 5, 'bias_width': 8, 'bias_frac_width': 5, 'data_out_width': 8, 'data_out_frac_width': 5, 'floor': True}\n",
      "output\n"
     ]
    }
   ],
   "source": [
    "config_file = os.path.join(\n",
    "    os.path.abspath(\"\"),\n",
    "    \"..\",\n",
    "    \"..\",\n",
    "    \"configs\",\n",
    "    \"tests\",\n",
    "    \"quantize\",\n",
    "    \"fixed.toml\",\n",
    ")\n",
    "# Fixed.toml used to quantize the model\n",
    "with open(config_file, \"r\") as f:\n",
    "    quan_args = toml.load(f)[\"passes\"][\"quantize\"]\n",
    "mg, _ = quantize_transform_pass(mg, quan_args)\n",
    "\n",
    "_ = report_node_type_analysis_pass(mg)\n",
    "\n",
    "# Update the metadata\n",
    "for node in mg.fx_graph.nodes:\n",
    "    for arg, arg_info in node.meta[\"mase\"][\"common\"][\"args\"].items():\n",
    "        if isinstance(arg_info, dict):\n",
    "            arg_info[\"type\"] = \"fixed\"\n",
    "            arg_info[\"precision\"] = [8, 5]\n",
    "    for result, result_info in node.meta[\"mase\"][\"common\"][\"results\"].items():\n",
    "        if isinstance(result_info, dict):\n",
    "            result_info[\"type\"] = \"fixed\"\n",
    "            result_info[\"precision\"] = [8, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hardware Metapass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mase_op: conv2d\n",
      "2222\n",
      "vp:  {}\n",
      "arg_info in add_verilog_param:  {'shape': [1, 1, 3, 3], 'torch_dtype': torch.float32, 'type': 'fixed', 'precision': [8, 5]}\n",
      "arg_info shape: [1, 1, 3, 3]\n",
      "length of arg_info: 4\n",
      "arg_info in add_verilog_param:  {'type': 'fixed', 'precision': [8, 5], 'shape': [2, 1, 3, 3], 'from': None}\n",
      "arg_info shape: [2, 1, 3, 3]\n",
      "length of arg_info: 4\n",
      "arg_info in add_verilog_param:  {'type': 'fixed', 'precision': [8, 5], 'shape': [1, 2], 'from': None}\n",
      "arg_info shape: [1, 2]\n",
      "length of arg_info: 2\n",
      "mase_op: placeholder\n",
      "common: {'mase_type': 'placeholder', 'mase_op': 'placeholder', 'args': {}, 'results': OrderedDict([('data_out_0', {'type': 'fixed', 'precision': [8, 5], 'shape': [1, 1, 3, 3], 'torch_dtype': torch.float32})])}\n",
      "hardware: {'is_implicit': True, 'device_id': 0, 'max_parallelism': [4, 4, 4, 4]}\n",
      "mase_op: conv2d\n",
      "common: {'mase_type': 'module_related_func', 'mase_op': 'conv2d', 'args': OrderedDict([('data_in_0', {'shape': [1, 1, 3, 3], 'torch_dtype': torch.float32, 'type': 'fixed', 'precision': [8, 5]}), ('weight', {'type': 'fixed', 'precision': [8, 5], 'shape': [2, 1, 3, 3], 'from': None}), ('bias', {'type': 'fixed', 'precision': [8, 5], 'shape': [1, 2], 'from': None})]), 'results': OrderedDict([('data_out_0', {'type': 'fixed', 'precision': [8, 5], 'shape': [1, 2, 3, 3], 'torch_dtype': torch.float32})])}\n",
      "hardware: {'is_implicit': False, 'device_id': -1, 'interface': {'weight': {'storage': 'BRAM', 'transpose': False}, 'bias': {'storage': 'BRAM', 'transpose': False}}, 'toolchain': 'INTERNAL_RTL', 'module': 'convolution', 'dependence_files': ['linear_layers/fixed_operators/rtl/fixed_dot_product.sv', 'linear_layers/fixed_operators/rtl/fixed_vector_mult.sv', 'linear_layers/fixed_operators/rtl/fixed_adder_tree.sv', 'linear_layers/fixed_operators/rtl/fixed_adder_tree_layer.sv', 'linear_layers/fixed_operators/rtl/fixed_accumulator.sv', 'linear_layers/fixed_operators/rtl/fixed_mult.sv', 'memory/rtl/input_buffer.sv', 'memory/rtl/unpacked_skid_buffer.sv', 'memory/rtl/skid_buffer.sv', 'memory/rtl/blk_mem_gen_0.sv', 'memory/rtl/unpacked_skid_buffer.sv', 'common/rtl/join2.sv', 'cast/rtl/floor_round.sv', 'cast/rtl/signed_clamp.sv', 'cast/rtl/fixed_signed_cast.sv', 'cast/rtl/fixed_cast.sv', 'cast/rtl/fixed_rounding.sv', 'convolution_layers/rtl/convolution_arith.sv', 'convolution_layers/rtl/convolution.sv', 'convolution_layers/rtl/padding.sv', 'convolution_layers/rtl/roller.sv', 'convolution_layers/rtl/sliding_window.sv'], 'max_parallelism': [4, 4, 4, 4], 'verilog_param': {'DATA_IN_0_PRECISION_0': 8, 'DATA_IN_0_PRECISION_1': 5, 'DATA_IN_0_TENSOR_SIZE_DIM_0': 3, 'DATA_IN_0_PARALLELISM_DIM_0': 3, 'DATA_IN_0_TENSOR_SIZE_DIM_1': 3, 'DATA_IN_0_PARALLELISM_DIM_1': 3, 'DATA_IN_0_TENSOR_SIZE_DIM_2': 1, 'DATA_IN_0_PARALLELISM_DIM_2': 1, 'DATA_IN_0_TENSOR_SIZE_DIM_3': 1, 'DATA_IN_0_PARALLELISM_DIM_3': 1, 'WEIGHT_PRECISION_0': 8, 'WEIGHT_PRECISION_1': 5, 'WEIGHT_TENSOR_SIZE_DIM_0': 3, 'WEIGHT_PARALLELISM_DIM_0': 3, 'WEIGHT_TENSOR_SIZE_DIM_1': 3, 'WEIGHT_PARALLELISM_DIM_1': 3, 'WEIGHT_TENSOR_SIZE_DIM_2': 1, 'WEIGHT_PARALLELISM_DIM_2': 1, 'WEIGHT_TENSOR_SIZE_DIM_3': 2, 'WEIGHT_PARALLELISM_DIM_3': 2, 'BIAS_PRECISION_0': 8, 'BIAS_PRECISION_1': 5, 'BIAS_TENSOR_SIZE_DIM_0': 2, 'BIAS_PARALLELISM_DIM_0': 2, 'BIAS_TENSOR_SIZE_DIM_1': 1, 'BIAS_PARALLELISM_DIM_1': 1, 'DATA_OUT_0_PRECISION_0': 8, 'DATA_OUT_0_PRECISION_1': 5, 'DATA_OUT_0_TENSOR_SIZE_DIM_0': 3, 'DATA_OUT_0_PARALLELISM_DIM_0': 3, 'DATA_OUT_0_TENSOR_SIZE_DIM_1': 3, 'DATA_OUT_0_PARALLELISM_DIM_1': 3, 'DATA_OUT_0_TENSOR_SIZE_DIM_2': 2, 'DATA_OUT_0_PARALLELISM_DIM_2': 2, 'DATA_OUT_0_TENSOR_SIZE_DIM_3': 1, 'DATA_OUT_0_PARALLELISM_DIM_3': 1}}\n",
      "mase_op: output\n",
      "common: {'mase_type': 'output', 'mase_op': 'output', 'args': {}, 'results': OrderedDict([('data_out_0', {'type': 'fixed', 'precision': [8, 5], 'shape': [1, 2, 3, 3], 'torch_dtype': torch.float32})])}\n",
      "hardware: {'is_implicit': True, 'device_id': 0, 'max_parallelism': [4, 4, 4, 4]}\n",
      "param_name in CNN.jynb: weight\n",
      "parameter in CNN.jynb: Parameter containing:\n",
      "tensor([[[[-0.1946,  0.2865,  0.1487],\n",
      "          [ 0.1616,  0.0175, -0.1709],\n",
      "          [ 0.0564, -0.3112, -0.2409]]],\n",
      "\n",
      "\n",
      "        [[[-0.1718,  0.2103,  0.1954],\n",
      "          [-0.1478, -0.0120,  0.2132],\n",
      "          [ 0.3314,  0.1323,  0.0450]]]], requires_grad=True)\n",
      "param_name in CNN.jynb: bias\n",
      "parameter in CNN.jynb: Parameter containing:\n",
      "tensor([-0.3299, -0.2162], requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nweights and bias in the Conv/linear in Maze\\nparam_data = node.meta[\"mase\"].module.get_parameter(param_name).data\\nprint (\"param_data: \", param_data)\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mg, _ = add_hardware_metadata_analysis_pass(mg)\n",
    "for node in mg.nodes:\n",
    "        mase_op = node.meta[\"mase\"][\"common\"][\"mase_op\"]\n",
    "        print ('mase_op:', mase_op)\n",
    "        print (\"common:\",node.meta[\"mase\"][\"common\"])\n",
    "        print (\"hardware:\",node.meta[\"mase\"][\"hardware\"])\n",
    "\n",
    "for node in mg.fx_graph.nodes:\n",
    "        if node.meta[\"mase\"].parameters[\"hardware\"][\"is_implicit\"]:\n",
    "            continue\n",
    "        # Only modules have internal parameters\n",
    "        if node.meta[\"mase\"].module is None:\n",
    "            continue\n",
    "        # print (node.meta[\"mase\"].parameters[\"hardware\"])\n",
    "        # Only checks the hardware data that contains the key toolchain\n",
    "        if \"INTERNAL\" in node.meta[\"mase\"].parameters[\"hardware\"][\"toolchain\"]:\n",
    "                for param_name, parameter in node.meta[\"mase\"].module.named_parameters():\n",
    "                        print (\"param_name in CNN.jynb:\",param_name)\n",
    "                        print (\"parameter in CNN.jynb:\", parameter)\n",
    "\n",
    "\"\"\"\n",
    "weights and bias in the Conv/linear in Maze\n",
    "param_data = node.meta[\"mase\"].module.get_parameter(param_name).data\n",
    "print (\"param_data: \", param_data)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emit for SV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mEmitting Verilog...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEmitting internal components...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key in get_verilog_parameter: DATA_IN_0_PRECISION_0\n",
      "key in get_verilog_parameter: DATA_IN_0_PRECISION_1\n",
      "key in get_verilog_parameter: DATA_IN_0_TENSOR_SIZE_DIM_0\n",
      "key in get_verilog_parameter: DATA_IN_0_PARALLELISM_DIM_0\n",
      "key in get_verilog_parameter: DATA_IN_0_TENSOR_SIZE_DIM_1\n",
      "key in get_verilog_parameter: DATA_IN_0_PARALLELISM_DIM_1\n",
      "key in get_verilog_parameter: DATA_IN_0_TENSOR_SIZE_DIM_2\n",
      "key in get_verilog_parameter: DATA_IN_0_PARALLELISM_DIM_2\n",
      "key in get_verilog_parameter: DATA_IN_0_TENSOR_SIZE_DIM_3\n",
      "key in get_verilog_parameter: DATA_IN_0_PARALLELISM_DIM_3\n",
      "key in get_verilog_parameter: WEIGHT_PRECISION_0\n",
      "key in get_verilog_parameter: WEIGHT_PRECISION_1\n",
      "key in get_verilog_parameter: WEIGHT_TENSOR_SIZE_DIM_0\n",
      "key in get_verilog_parameter: WEIGHT_PARALLELISM_DIM_0\n",
      "key in get_verilog_parameter: WEIGHT_TENSOR_SIZE_DIM_1\n",
      "key in get_verilog_parameter: WEIGHT_PARALLELISM_DIM_1\n",
      "key in get_verilog_parameter: WEIGHT_TENSOR_SIZE_DIM_2\n",
      "key in get_verilog_parameter: WEIGHT_PARALLELISM_DIM_2\n",
      "key in get_verilog_parameter: WEIGHT_TENSOR_SIZE_DIM_3\n",
      "key in get_verilog_parameter: WEIGHT_PARALLELISM_DIM_3\n",
      "key in get_verilog_parameter: BIAS_PRECISION_0\n",
      "key in get_verilog_parameter: BIAS_PRECISION_1\n",
      "key in get_verilog_parameter: BIAS_TENSOR_SIZE_DIM_0\n",
      "key in get_verilog_parameter: BIAS_PARALLELISM_DIM_0\n",
      "key in get_verilog_parameter: BIAS_TENSOR_SIZE_DIM_1\n",
      "key in get_verilog_parameter: BIAS_PARALLELISM_DIM_1\n",
      "key in get_verilog_parameter: DATA_OUT_0_PRECISION_0\n",
      "key in get_verilog_parameter: DATA_OUT_0_PRECISION_1\n",
      "key in get_verilog_parameter: DATA_OUT_0_TENSOR_SIZE_DIM_0\n",
      "key in get_verilog_parameter: DATA_OUT_0_PARALLELISM_DIM_0\n",
      "key in get_verilog_parameter: DATA_OUT_0_TENSOR_SIZE_DIM_1\n",
      "key in get_verilog_parameter: DATA_OUT_0_PARALLELISM_DIM_1\n",
      "key in get_verilog_parameter: DATA_OUT_0_TENSOR_SIZE_DIM_2\n",
      "key in get_verilog_parameter: DATA_OUT_0_PARALLELISM_DIM_2\n",
      "key in get_verilog_parameter: DATA_OUT_0_TENSOR_SIZE_DIM_3\n",
      "key in get_verilog_parameter: DATA_OUT_0_PARALLELISM_DIM_3\n",
      "key in get_verilog_parameter: DATA_IN_0_PRECISION_0\n",
      "key in get_verilog_parameter: DATA_IN_0_PRECISION_1\n",
      "key in get_verilog_parameter: DATA_IN_0_TENSOR_SIZE_DIM_0\n",
      "key in get_verilog_parameter: DATA_IN_0_PARALLELISM_DIM_0\n",
      "key in get_verilog_parameter: DATA_IN_0_TENSOR_SIZE_DIM_1\n",
      "key in get_verilog_parameter: DATA_IN_0_PARALLELISM_DIM_1\n",
      "key in get_verilog_parameter: DATA_IN_0_TENSOR_SIZE_DIM_2\n",
      "key in get_verilog_parameter: DATA_IN_0_PARALLELISM_DIM_2\n",
      "key in get_verilog_parameter: DATA_IN_0_TENSOR_SIZE_DIM_3\n",
      "key in get_verilog_parameter: DATA_IN_0_PARALLELISM_DIM_3\n",
      "key in get_verilog_parameter: WEIGHT_PRECISION_0\n",
      "key in get_verilog_parameter: WEIGHT_PRECISION_1\n",
      "key in get_verilog_parameter: WEIGHT_TENSOR_SIZE_DIM_0\n",
      "key in get_verilog_parameter: WEIGHT_PARALLELISM_DIM_0\n",
      "key in get_verilog_parameter: WEIGHT_TENSOR_SIZE_DIM_1\n",
      "key in get_verilog_parameter: WEIGHT_PARALLELISM_DIM_1\n",
      "key in get_verilog_parameter: WEIGHT_TENSOR_SIZE_DIM_2\n",
      "key in get_verilog_parameter: WEIGHT_PARALLELISM_DIM_2\n",
      "key in get_verilog_parameter: WEIGHT_TENSOR_SIZE_DIM_3\n",
      "key in get_verilog_parameter: WEIGHT_PARALLELISM_DIM_3\n",
      "key in get_verilog_parameter: BIAS_PRECISION_0\n",
      "key in get_verilog_parameter: BIAS_PRECISION_1\n",
      "key in get_verilog_parameter: BIAS_TENSOR_SIZE_DIM_0\n",
      "key in get_verilog_parameter: BIAS_PARALLELISM_DIM_0\n",
      "key in get_verilog_parameter: BIAS_TENSOR_SIZE_DIM_1\n",
      "key in get_verilog_parameter: BIAS_PARALLELISM_DIM_1\n",
      "key in get_verilog_parameter: DATA_OUT_0_PRECISION_0\n",
      "key in get_verilog_parameter: DATA_OUT_0_PRECISION_1\n",
      "key in get_verilog_parameter: DATA_OUT_0_TENSOR_SIZE_DIM_0\n",
      "key in get_verilog_parameter: DATA_OUT_0_PARALLELISM_DIM_0\n",
      "key in get_verilog_parameter: DATA_OUT_0_TENSOR_SIZE_DIM_1\n",
      "key in get_verilog_parameter: DATA_OUT_0_PARALLELISM_DIM_1\n",
      "key in get_verilog_parameter: DATA_OUT_0_TENSOR_SIZE_DIM_2\n",
      "key in get_verilog_parameter: DATA_OUT_0_PARALLELISM_DIM_2\n",
      "key in get_verilog_parameter: DATA_OUT_0_TENSOR_SIZE_DIM_3\n",
      "key in get_verilog_parameter: DATA_OUT_0_PARALLELISM_DIM_3\n",
      "Parameter_map in VerilogEmitter: {'conv1_DATA_IN_0_PRECISION_0': 8, 'conv1_DATA_IN_0_PRECISION_1': 5, 'conv1_DATA_IN_0_TENSOR_SIZE_DIM_0': 3, 'conv1_DATA_IN_0_PARALLELISM_DIM_0': 3, 'conv1_DATA_IN_0_TENSOR_SIZE_DIM_1': 3, 'conv1_DATA_IN_0_PARALLELISM_DIM_1': 3, 'conv1_DATA_IN_0_TENSOR_SIZE_DIM_2': 1, 'conv1_DATA_IN_0_PARALLELISM_DIM_2': 1, 'conv1_DATA_IN_0_TENSOR_SIZE_DIM_3': 1, 'conv1_DATA_IN_0_PARALLELISM_DIM_3': 1, 'conv1_WEIGHT_PRECISION_0': 8, 'conv1_WEIGHT_PRECISION_1': 5, 'conv1_WEIGHT_TENSOR_SIZE_DIM_0': 3, 'conv1_WEIGHT_PARALLELISM_DIM_0': 3, 'conv1_WEIGHT_TENSOR_SIZE_DIM_1': 3, 'conv1_WEIGHT_PARALLELISM_DIM_1': 3, 'conv1_WEIGHT_TENSOR_SIZE_DIM_2': 1, 'conv1_WEIGHT_PARALLELISM_DIM_2': 1, 'conv1_WEIGHT_TENSOR_SIZE_DIM_3': 2, 'conv1_WEIGHT_PARALLELISM_DIM_3': 2, 'conv1_BIAS_PRECISION_0': 8, 'conv1_BIAS_PRECISION_1': 5, 'conv1_BIAS_TENSOR_SIZE_DIM_0': 2, 'conv1_BIAS_PARALLELISM_DIM_0': 2, 'conv1_BIAS_TENSOR_SIZE_DIM_1': 1, 'conv1_BIAS_PARALLELISM_DIM_1': 1, 'conv1_DATA_OUT_0_PRECISION_0': 8, 'conv1_DATA_OUT_0_PRECISION_1': 5, 'conv1_DATA_OUT_0_TENSOR_SIZE_DIM_0': 3, 'conv1_DATA_OUT_0_PARALLELISM_DIM_0': 3, 'conv1_DATA_OUT_0_TENSOR_SIZE_DIM_1': 3, 'conv1_DATA_OUT_0_PARALLELISM_DIM_1': 3, 'conv1_DATA_OUT_0_TENSOR_SIZE_DIM_2': 2, 'conv1_DATA_OUT_0_PARALLELISM_DIM_2': 2, 'conv1_DATA_OUT_0_TENSOR_SIZE_DIM_3': 1, 'conv1_DATA_OUT_0_PARALLELISM_DIM_3': 1, 'DATA_IN_0_PRECISION_0': 8, 'DATA_IN_0_PRECISION_1': 5, 'DATA_IN_0_TENSOR_SIZE_DIM_0': 3, 'DATA_IN_0_PARALLELISM_DIM_0': 3, 'DATA_IN_0_TENSOR_SIZE_DIM_1': 3, 'DATA_IN_0_PARALLELISM_DIM_1': 3, 'DATA_IN_0_TENSOR_SIZE_DIM_2': 1, 'DATA_IN_0_PARALLELISM_DIM_2': 1, 'DATA_IN_0_TENSOR_SIZE_DIM_3': 1, 'DATA_IN_0_PARALLELISM_DIM_3': 1, 'DATA_OUT_0_PRECISION_0': 8, 'DATA_OUT_0_PRECISION_1': 5, 'DATA_OUT_0_TENSOR_SIZE_DIM_0': 3, 'DATA_OUT_0_PARALLELISM_DIM_0': 3, 'DATA_OUT_0_TENSOR_SIZE_DIM_1': 3, 'DATA_OUT_0_PARALLELISM_DIM_1': 3, 'DATA_OUT_0_TENSOR_SIZE_DIM_2': 2, 'DATA_OUT_0_PARALLELISM_DIM_2': 2, 'DATA_OUT_0_TENSOR_SIZE_DIM_3': 1, 'DATA_OUT_0_PARALLELISM_DIM_3': 1}\n",
      "nodes_in: [conv1]\n",
      "nodes_out: [conv1]\n",
      "parameter in VerilogParameterEmitter:     parameter conv1_DATA_IN_0_PRECISION_0 = 8,\n",
      "    parameter conv1_DATA_IN_0_PRECISION_1 = 5,\n",
      "    parameter conv1_DATA_IN_0_TENSOR_SIZE_DIM_0 = 3,\n",
      "    parameter conv1_DATA_IN_0_PARALLELISM_DIM_0 = 3,\n",
      "    parameter conv1_DATA_IN_0_TENSOR_SIZE_DIM_1 = 3,\n",
      "    parameter conv1_DATA_IN_0_PARALLELISM_DIM_1 = 3,\n",
      "    parameter conv1_DATA_IN_0_TENSOR_SIZE_DIM_2 = 1,\n",
      "    parameter conv1_DATA_IN_0_PARALLELISM_DIM_2 = 1,\n",
      "    parameter conv1_DATA_IN_0_TENSOR_SIZE_DIM_3 = 1,\n",
      "    parameter conv1_DATA_IN_0_PARALLELISM_DIM_3 = 1,\n",
      "    parameter conv1_WEIGHT_PRECISION_0 = 8,\n",
      "    parameter conv1_WEIGHT_PRECISION_1 = 5,\n",
      "    parameter conv1_WEIGHT_TENSOR_SIZE_DIM_0 = 3,\n",
      "    parameter conv1_WEIGHT_PARALLELISM_DIM_0 = 3,\n",
      "    parameter conv1_WEIGHT_TENSOR_SIZE_DIM_1 = 3,\n",
      "    parameter conv1_WEIGHT_PARALLELISM_DIM_1 = 3,\n",
      "    parameter conv1_WEIGHT_TENSOR_SIZE_DIM_2 = 1,\n",
      "    parameter conv1_WEIGHT_PARALLELISM_DIM_2 = 1,\n",
      "    parameter conv1_WEIGHT_TENSOR_SIZE_DIM_3 = 2,\n",
      "    parameter conv1_WEIGHT_PARALLELISM_DIM_3 = 2,\n",
      "    parameter conv1_BIAS_PRECISION_0 = 8,\n",
      "    parameter conv1_BIAS_PRECISION_1 = 5,\n",
      "    parameter conv1_BIAS_TENSOR_SIZE_DIM_0 = 2,\n",
      "    parameter conv1_BIAS_PARALLELISM_DIM_0 = 2,\n",
      "    parameter conv1_BIAS_TENSOR_SIZE_DIM_1 = 1,\n",
      "    parameter conv1_BIAS_PARALLELISM_DIM_1 = 1,\n",
      "    parameter conv1_DATA_OUT_0_PRECISION_0 = 8,\n",
      "    parameter conv1_DATA_OUT_0_PRECISION_1 = 5,\n",
      "    parameter conv1_DATA_OUT_0_TENSOR_SIZE_DIM_0 = 3,\n",
      "    parameter conv1_DATA_OUT_0_PARALLELISM_DIM_0 = 3,\n",
      "    parameter conv1_DATA_OUT_0_TENSOR_SIZE_DIM_1 = 3,\n",
      "    parameter conv1_DATA_OUT_0_PARALLELISM_DIM_1 = 3,\n",
      "    parameter conv1_DATA_OUT_0_TENSOR_SIZE_DIM_2 = 2,\n",
      "    parameter conv1_DATA_OUT_0_PARALLELISM_DIM_2 = 2,\n",
      "    parameter conv1_DATA_OUT_0_TENSOR_SIZE_DIM_3 = 1,\n",
      "    parameter conv1_DATA_OUT_0_PARALLELISM_DIM_3 = 1,\n",
      "    parameter DATA_IN_0_PRECISION_0 = 8,\n",
      "    parameter DATA_IN_0_PRECISION_1 = 5,\n",
      "    parameter DATA_IN_0_TENSOR_SIZE_DIM_0 = 3,\n",
      "    parameter DATA_IN_0_PARALLELISM_DIM_0 = 3,\n",
      "    parameter DATA_IN_0_TENSOR_SIZE_DIM_1 = 3,\n",
      "    parameter DATA_IN_0_PARALLELISM_DIM_1 = 3,\n",
      "    parameter DATA_IN_0_TENSOR_SIZE_DIM_2 = 1,\n",
      "    parameter DATA_IN_0_PARALLELISM_DIM_2 = 1,\n",
      "    parameter DATA_IN_0_TENSOR_SIZE_DIM_3 = 1,\n",
      "    parameter DATA_IN_0_PARALLELISM_DIM_3 = 1,\n",
      "    parameter DATA_OUT_0_PRECISION_0 = 8,\n",
      "    parameter DATA_OUT_0_PRECISION_1 = 5,\n",
      "    parameter DATA_OUT_0_TENSOR_SIZE_DIM_0 = 3,\n",
      "    parameter DATA_OUT_0_PARALLELISM_DIM_0 = 3,\n",
      "    parameter DATA_OUT_0_TENSOR_SIZE_DIM_1 = 3,\n",
      "    parameter DATA_OUT_0_PARALLELISM_DIM_1 = 3,\n",
      "    parameter DATA_OUT_0_TENSOR_SIZE_DIM_2 = 2,\n",
      "    parameter DATA_OUT_0_PARALLELISM_DIM_2 = 2,\n",
      "    parameter DATA_OUT_0_TENSOR_SIZE_DIM_3 = 1,\n",
      "    parameter DATA_OUT_0_PARALLELISM_DIM_3 = 1,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mg, _ = emit_verilog_top_transform_pass(mg)\n",
    "mg, _ = emit_internal_rtl_transform_pass(mg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mEmitting BRAM...\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[34mEmitting DAT file for node: conv1, parameter: weight\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[34mROM module weight successfully written into /root/.mase/top/hardware/rtl/conv1_weight_source.sv\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[34mInit data weight successfully written into /root/.mase/top/hardware/rtl/conv1_weight_rom.dat\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[34mEmitting DAT file for node: conv1, parameter: bias\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[34mROM module bias successfully written into /root/.mase/top/hardware/rtl/conv1_bias_source.sv\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[34mInit data bias successfully written into /root/.mase/top/hardware/rtl/conv1_bias_rom.dat\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 in emit_bram_transform_pass\n",
      "/root/.mase/top/hardware/rtl\n",
      "param_name in emit_bram_handshake: weight\n",
      "parameter in emit_bram_handshake: Parameter containing:\n",
      "tensor([[[[-0.1946,  0.2865,  0.1487],\n",
      "          [ 0.1616,  0.0175, -0.1709],\n",
      "          [ 0.0564, -0.3112, -0.2409]]],\n",
      "\n",
      "\n",
      "        [[[-0.1718,  0.2103,  0.1954],\n",
      "          [-0.1478, -0.0120,  0.2132],\n",
      "          [ 0.3314,  0.1323,  0.0450]]]], requires_grad=True)\n",
      "out_size in emit_parameters_in_mem_internal: 9\n",
      "conv1\n",
      "param_data in emit_parameters_in_dat_internal:  tensor([[[[-0.1946,  0.2865,  0.1487],\n",
      "          [ 0.1616,  0.0175, -0.1709],\n",
      "          [ 0.0564, -0.3112, -0.2409]]],\n",
      "\n",
      "\n",
      "        [[[-0.1718,  0.2103,  0.1954],\n",
      "          [-0.1478, -0.0120,  0.2132],\n",
      "          [ 0.3314,  0.1323,  0.0450]]]])\n",
      "out_depth:  2\n",
      "data_buff:  fa09050501fb02f6f8\n",
      "fb0706fb00070b0401\n",
      "\n",
      "param_name in emit_bram_handshake: bias\n",
      "parameter in emit_bram_handshake: Parameter containing:\n",
      "tensor([-0.3299, -0.2162], requires_grad=True)\n",
      "out_size in emit_parameters_in_mem_internal: 2\n",
      "conv1\n",
      "param_data in emit_parameters_in_dat_internal:  tensor([-0.3299, -0.2162])\n",
      "out_depth:  1\n",
      "data_buff:  f5f9\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n  param_data:  tensor([[[[-0.1946,  0.2865,  0.1487],\\n          [ 0.1616,  0.0175, -0.1709],\\n          [ 0.0564, -0.3112, -0.2409]]],\\n\\n\\n        [[[-0.1718,  0.2103,  0.1954],\\n          [-0.1478, -0.0120,  0.2132],\\n          [ 0.3314,  0.1323,  0.0450]]]])\\n  This would be weight, as I defined conv as (2,1,3,3)\\n  The kernel filter size is 3x3, and we have 2 filters, thus 9x2=18 elements\\n  Bias: depends on number of filter-> here 2 filters, thus 2 bias elements,\\n    as bias added after filter multiplies with section of pixel\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mg, _ = emit_bram_transform_pass(mg)\n",
    "\n",
    "\"\"\"\n",
    "  param_data:  tensor([[[[-0.1946,  0.2865,  0.1487],\n",
    "          [ 0.1616,  0.0175, -0.1709],\n",
    "          [ 0.0564, -0.3112, -0.2409]]],\n",
    "\n",
    "\n",
    "        [[[-0.1718,  0.2103,  0.1954],\n",
    "          [-0.1478, -0.0120,  0.2132],\n",
    "          [ 0.3314,  0.1323,  0.0450]]]])\n",
    "  This would be weight, as I defined conv as (2,1,3,3)\n",
    "  The kernel filter size is 3x3, and we have 2 filters, thus 9x2=18 elements\n",
    "  Bias: depends on number of filter-> here 2 filters, thus 2 bias elements,\n",
    "    as bias added after filter multiplies with section of pixel\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mEmitting testbench...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "mg, _ = emit_cocotb_transform_pass(mg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Running command perl /usr/local/bin/verilator -cc --exe -Mdir /workspace/docs/labs/sim_build -DCOCOTB_SIM=1 --top-module top --vpi --public-flat-rw --prefix Vtop -o top -LDFLAGS '-Wl,-rpath,/usr/local/lib/python3.11/dist-packages/cocotb/libs -L/usr/local/lib/python3.11/dist-packages/cocotb/libs -lcocotbvpi_verilator' -Wno-fatal -Wno-lint -Wno-style --trace-fst --trace-structs --trace-depth 3 -I/root/.mase/top/hardware/rtl -I/workspace/src/mase_components/interface/rtl -I/workspace/src/mase_components/language_models/rtl -I/workspace/src/mase_components/memory/rtl -I/workspace/src/mase_components/vivado/rtl -I/workspace/src/mase_components/convolution_layers/rtl -I/workspace/src/mase_components/cast/rtl -I/workspace/src/mase_components/systolic_arrays/rtl -I/workspace/src/mase_components/scalar_operators/rtl -I/workspace/src/mase_components/transformer_layers/rtl -I/workspace/src/mase_components/common/rtl -I/workspace/src/mase_components/hls/rtl -I/workspace/src/mase_components/vision_models/rtl -I/workspace/src/mase_components/linear_layers/rtl -I/workspace/src/mase_components/activation_layers/rtl -I/workspace/src/mase_components/normalization_layers/rtl -I/workspace/src/mase_components/helper/rtl /usr/local/lib/python3.11/dist-packages/cocotb/share/lib/verilator/verilator.cpp /root/.mase/top/hardware/rtl/register_slice.sv /root/.mase/top/hardware/rtl/fixed_adder_tree_layer.sv /root/.mase/top/hardware/rtl/unpacked_repeat_circular_buffer.sv /root/.mase/top/hardware/rtl/matmul.sv /root/.mase/top/hardware/rtl/join2.sv /root/.mase/top/hardware/rtl/sliding_window.sv /root/.mase/top/hardware/rtl/convolution.sv /root/.mase/top/hardware/rtl/matrix_unflatten.sv /root/.mase/top/hardware/rtl/fixed_signed_cast.sv /root/.mase/top/hardware/rtl/blk_mem_gen_0.sv /root/.mase/top/hardware/rtl/fixed_relu.sv /root/.mase/top/hardware/rtl/fixed_adder_tree.sv /root/.mase/top/hardware/rtl/matrix_fifo.sv /root/.mase/top/hardware/rtl/conv1_bias_source.sv /root/.mase/top/hardware/rtl/fc1_bias_source.sv /root/.mase/top/hardware/rtl/fixed_linear.sv /root/.mase/top/hardware/rtl/top.sv /root/.mase/top/hardware/rtl/fc1_weight_source.sv /root/.mase/top/hardware/rtl/fc1_1_bias_source.sv /root/.mase/top/hardware/rtl/conv1_weight_source.sv /root/.mase/top/hardware/rtl/transpose.sv /root/.mase/top/hardware/rtl/fixed_rounding.sv /root/.mase/top/hardware/rtl/input_buffer.sv /root/.mase/top/hardware/rtl/floor_round.sv /root/.mase/top/hardware/rtl/fc1_1_weight_source.sv /root/.mase/top/hardware/rtl/convolution_arith.sv /root/.mase/top/hardware/rtl/matrix_accumulator.sv /root/.mase/top/hardware/rtl/simple_matmul.sv /root/.mase/top/hardware/rtl/skid_buffer.sv /root/.mase/top/hardware/rtl/matrix_stream_transpose.sv /root/.mase/top/hardware/rtl/unpacked_skid_buffer.sv /root/.mase/top/hardware/rtl/fixed_leakyrelu.sv /root/.mase/top/hardware/rtl/fixed_accumulator.sv /root/.mase/top/hardware/rtl/fixed_vector_mult.sv /root/.mase/top/hardware/rtl/matrix_flatten.sv /root/.mase/top/hardware/rtl/fixed_dot_product.sv /root/.mase/top/hardware/rtl/padding.sv /root/.mase/top/hardware/rtl/fixed_cast.sv /root/.mase/top/hardware/rtl/roller.sv /root/.mase/top/hardware/rtl/fixed_mult.sv /root/.mase/top/hardware/rtl/signed_clamp.sv in directory /workspace/docs/labs/sim_build\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%Error: /root/.mase/top/hardware/rtl/top.sv:151:6: Slices of arrays in assignments have different unpacked dimensions, 18 versus 2\n",
      "  151 |     .data_out_0(conv1_data_out_0),\n",
      "      |      ^~~~~~~~~~\n",
      "%Error: /root/.mase/top/hardware/rtl/top.sv:143:13: Slices of arrays in assignments have different unpacked dimensions, 8 versus 18\n",
      "  143 |     .weight(conv1_weight),\n",
      "      |             ^~~~~~~~~~~~\n",
      "%Error: /root/.mase/top/hardware/rtl/top.sv:139:16: Slices of arrays in assignments have different unpacked dimensions, 2 versus 9\n",
      "  139 |     .data_in_0(conv1_data_in_0),\n",
      "      |                ^~~~~~~~~~~~~~~\n",
      "%Error: /root/.mase/top/hardware/rtl/top.sv:170:6: Slices of arrays in assignments have different unpacked dimensions, 18 versus 9\n",
      "  170 |     .data_out(conv1_weight),\n",
      "      |      ^~~~~~~~\n",
      "%Error: Exiting due to 4 error(s)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "Process 'perl' terminated with error 1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m Process 'perl' terminated with error 1\n"
     ]
    }
   ],
   "source": [
    "from chop.actions import simulate\n",
    "\n",
    "simulate(skip_build=False, skip_test=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
