{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hardware Emit Pass\n",
    "The `emit_verilog` transform pass generates a top-level RTL file and testbench file according to the `MaseGraph`, which includes a hardware implementation of each layer in the network. This top-level file instantiates modules from the `components` library in MASE and/or modules generated using [HLS](https://en.wikipedia.org/wiki/High-level_synthesis), when internal components are not available. The hardware can then be simulated using [Verilator](https://www.veripool.org/verilator/), or deployed on an FPGA.\n",
    "\n",
    "First, add Machop to your system PATH (if you haven't already done so) and import the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mSet logging level to debug\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage:\n",
      "        verilator --help\n",
      "        verilator --version\n",
      "        verilator --binary -j 0 [options] [source_files.v]... [opt_c_files.cpp/c/cc/a/o/so]\n",
      "        verilator --cc [options] [source_files.v]... [opt_c_files.cpp/c/cc/a/o/so]\n",
      "        verilator --sc [options] [source_files.v]... [opt_c_files.cpp/c/cc/a/o/so]\n",
      "        verilator --lint-only -Wall [source_files.v]...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "\n",
    "from chop.ir.graph.mase_graph import MaseGraph\n",
    "\n",
    "from chop.passes.graph.analysis import (\n",
    "    init_metadata_analysis_pass,\n",
    "    add_common_metadata_analysis_pass,\n",
    "    add_hardware_metadata_analysis_pass,\n",
    "    add_software_metadata_analysis_pass,\n",
    "    report_node_type_analysis_pass,\n",
    ")\n",
    "\n",
    "from chop.passes.graph.transforms import (\n",
    "    emit_verilog_top_transform_pass,\n",
    "    emit_internal_rtl_transform_pass,\n",
    "    emit_bram_transform_pass,\n",
    "    emit_cocotb_transform_pass,\n",
    "    quantize_transform_pass,\n",
    ")\n",
    "\n",
    "from chop.tools.logger import set_logging_verbosity\n",
    "\n",
    "set_logging_verbosity(\"debug\")\n",
    "\n",
    "import toml\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# TO DO: remove\n",
    "import os\n",
    "os.environ[\"PATH\"] = \"/opt/homebrew/bin:\" + os.environ[\"PATH\"]\n",
    "!verilator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "  def __init__(self, num_classes=10):\n",
    "    # initialize the parent class—in this case, the nn.Module class from PyTorch.\n",
    "    super().__init__()\n",
    "\n",
    "    # Define layers in the model\n",
    "    # When you instantiate a layer like nn.Conv2d inside the forward method,\n",
    "    # it is created anew each time forward is called. Because that layer is constructed at runtime during every forward pass,\n",
    "    # its weights are randomly re-initialized every time.\n",
    "    # Hence the weights will not be tracked by PyTorch’s parameter-registration mechanism (they won’t show up in model.parameters()), and\n",
    "    # Won’t get updated during backpropagation (since they’re re-created each time),\n",
    "    # Are randomly re-initialized on every forward pass, which makes learning impossible.\n",
    "\n",
    "    # Convolutional layers\n",
    "    # kernel_size: the size of the CNN filter of small matrix that has weights\n",
    "    # kernel_size=3: the kernel/filter will have both height and width of 3 (i.e., 3×3).\n",
    "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "\n",
    "    # Pooling layer\n",
    "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    # Fully-connected layers\n",
    "    # # After two 2x2 poolings on a 28x28 input, the spatial dimension is reduced to 7x7.\n",
    "    # Hence, the input to the first linear layer is 64 * 7 * 7.\n",
    "    self.fc1 = nn.Linear(in_features=64 * 7 * 7, out_features=128)\n",
    "    self.fc2 = nn.Linear(in_features=128, out_features=num_classes)\n",
    "\n",
    "  def forward(self, x):\n",
    "    # Convolution -> ReLU -> Pool\n",
    "    x = self.pool(F.relu(self.conv1(x)))\n",
    "    x = self.pool(F.relu(self.conv2(x)))\n",
    "\n",
    "    # Flatten\n",
    "    x = x.view(x.size(0), -1)  # same as x.view(-1, 64*7*7)\n",
    "\n",
    "    # Fully-connected -> ReLU\n",
    "    x = F.relu(self.fc1(x))\n",
    "\n",
    "    # Final layer (logits)\n",
    "    x = self.fc2(x)\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SingleConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # A single 2D convolution layer\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=4,\n",
    "            # input channel size of one example is 1, i.e. grey scale\n",
    "            # output channel size becomes 2.\n",
    "            # out_channels=2, that convolution layer learns two distinct filters\n",
    "            out_channels=4,\n",
    "            kernel_size=3,\n",
    "            padding=1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply convolution (and optionally an activation)\n",
    "        # Here we show it with a ReLU, but you can remove F.relu(...) if you want pure convolution\n",
    "        #So if x has shape [batch_size, D1, D2, ..., Dn],\n",
    "        # this operation will reshape x into [batch_size, D1,D2 * ... * Dn].\n",
    "        # x = torch.flatten(x, start_dim=2, end_dim=-1)\n",
    "        x=self.conv1(x)\n",
    "        # x = F.relu(self.conv1(x))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     # Create a random batch of 1 image, 4×4 (grayscale)\n",
    "#     x = torch.randn((1, 1, 4, 4))\n",
    "\n",
    "#     model = SingleConvNet()\n",
    "#     output = model(x)\n",
    "\n",
    "#     print(\"Input shape:\", x.shape)\n",
    "#     print(\"Input tensor:\\n\", x)        # Show the actual input values\n",
    "\n",
    "#     print(\"\\nOutput shape:\", output.shape)\n",
    "#     print(\"Output tensor:\\n\", output)  # Show the actual output values\n",
    "\n",
    "#     print(\"Weights:\\n\", model.conv1.weight)\n",
    "#     print(\"\\nBias:\\n\", model.conv1.bias)\n",
    "#     print(\"\\nPadding:\\n\", model.conv1.padding)\n",
    "\n",
    "# # Weights, bias are random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36mDEBUG   \u001b[0m \u001b[34mgraph():\n",
      "    %x : [num_users=1] = placeholder[target=x]\n",
      "    %conv1 : [num_users=1] = call_module[target=conv1](args = (%x,), kwargs = {})\n",
      "    return conv1\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hellos in add_common_metadata\n",
      "sigoyi in add_common_metadata\n",
      "graph_model:  GraphModule(\n",
      "  (conv1): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "def forward(self, x):\n",
      "    conv1 = self.conv1(x);  x = None\n",
      "    return conv1\n",
      "    \n",
      "# To see more debug info, please use `graph_module.print_readable()`\n",
      "wocao in add_common_metadata\n",
      "graph_iterator_for_metadata:  GraphModule(\n",
      "  (conv1): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "def forward(self, x):\n",
      "    conv1 = self.conv1(x);  x = None\n",
      "    return conv1\n",
      "    \n",
      "# To see more debug info, please use `graph_module.print_readable()`\n",
      "args in call_module:  (tensor([[[[ 0.2886,  0.3866, -0.2011, -0.1179],\n",
      "          [-0.8294, -1.4073,  1.6268,  0.1723],\n",
      "          [-0.7043,  0.3147,  0.1574,  0.3854],\n",
      "          [ 0.5737,  0.9979,  0.5436,  0.0788]],\n",
      "\n",
      "         [[ 0.9985, -0.4987,  0.7611,  0.6183],\n",
      "          [-0.2994, -0.1878,  1.9159,  0.6902],\n",
      "          [-0.3140, -1.0787,  0.2408, -1.3962],\n",
      "          [ 0.1136,  1.1047, -1.3952,  0.4751]],\n",
      "\n",
      "         [[ 1.0811,  0.1315,  1.5735,  0.7814],\n",
      "          [ 0.9874, -1.4878,  0.5867,  0.1583],\n",
      "          [ 0.6668, -0.9944, -1.1894, -1.1959],\n",
      "          [ 1.3119, -0.2098,  0.7817,  0.9897]],\n",
      "\n",
      "         [[ 0.1715,  0.8760, -0.2871,  1.0216],\n",
      "          [-0.5111, -1.7137, -0.5101, -0.4749],\n",
      "          [ 0.6623, -1.2063,  0.6074, -0.5472],\n",
      "          [-1.1005, -0.7201,  0.0119,  0.3398]]],\n",
      "\n",
      "\n",
      "        [[[-1.2537,  0.9868, -0.4947, -1.2830],\n",
      "          [ 0.4386, -0.0107,  1.3384, -0.2794],\n",
      "          [ 0.2877, -0.0334, -1.0619, -0.1144],\n",
      "          [ 0.1954, -0.7371,  1.7001,  0.3462]],\n",
      "\n",
      "         [[-0.1448,  0.6376, -0.2813, -1.3299],\n",
      "          [-0.6538,  1.7198, -0.9610, -0.6375],\n",
      "          [-0.8870,  0.8388,  1.1529, -1.7611],\n",
      "          [-1.1070, -1.7174,  1.5346, -0.0032]],\n",
      "\n",
      "         [[ 1.4403, -0.1106,  0.5769, -0.1692],\n",
      "          [ 1.1887, -0.1575, -0.0455,  0.6485],\n",
      "          [-0.8707,  0.1447,  1.9029,  0.3904],\n",
      "          [ 0.0331, -1.0234,  0.7335,  1.1177]],\n",
      "\n",
      "         [[ 0.5851, -1.1560, -0.1434, -0.1947],\n",
      "          [ 1.4903, -0.7005,  0.1806,  1.3615],\n",
      "          [-0.3661, -1.3271,  1.6953,  2.0655],\n",
      "          [ 0.2578, -0.5650,  0.9278,  0.4826]]]]),)\n",
      "kwargs in call_module:  {}\n",
      "HIIII from analyse_common_parameters_module\n",
      "args from analyse_common_parameters_module (tensor([[[[ 0.2886,  0.3866, -0.2011, -0.1179],\n",
      "          [-0.8294, -1.4073,  1.6268,  0.1723],\n",
      "          [-0.7043,  0.3147,  0.1574,  0.3854],\n",
      "          [ 0.5737,  0.9979,  0.5436,  0.0788]],\n",
      "\n",
      "         [[ 0.9985, -0.4987,  0.7611,  0.6183],\n",
      "          [-0.2994, -0.1878,  1.9159,  0.6902],\n",
      "          [-0.3140, -1.0787,  0.2408, -1.3962],\n",
      "          [ 0.1136,  1.1047, -1.3952,  0.4751]],\n",
      "\n",
      "         [[ 1.0811,  0.1315,  1.5735,  0.7814],\n",
      "          [ 0.9874, -1.4878,  0.5867,  0.1583],\n",
      "          [ 0.6668, -0.9944, -1.1894, -1.1959],\n",
      "          [ 1.3119, -0.2098,  0.7817,  0.9897]],\n",
      "\n",
      "         [[ 0.1715,  0.8760, -0.2871,  1.0216],\n",
      "          [-0.5111, -1.7137, -0.5101, -0.4749],\n",
      "          [ 0.6623, -1.2063,  0.6074, -0.5472],\n",
      "          [-1.1005, -0.7201,  0.0119,  0.3398]]],\n",
      "\n",
      "\n",
      "        [[[-1.2537,  0.9868, -0.4947, -1.2830],\n",
      "          [ 0.4386, -0.0107,  1.3384, -0.2794],\n",
      "          [ 0.2877, -0.0334, -1.0619, -0.1144],\n",
      "          [ 0.1954, -0.7371,  1.7001,  0.3462]],\n",
      "\n",
      "         [[-0.1448,  0.6376, -0.2813, -1.3299],\n",
      "          [-0.6538,  1.7198, -0.9610, -0.6375],\n",
      "          [-0.8870,  0.8388,  1.1529, -1.7611],\n",
      "          [-1.1070, -1.7174,  1.5346, -0.0032]],\n",
      "\n",
      "         [[ 1.4403, -0.1106,  0.5769, -0.1692],\n",
      "          [ 1.1887, -0.1575, -0.0455,  0.6485],\n",
      "          [-0.8707,  0.1447,  1.9029,  0.3904],\n",
      "          [ 0.0331, -1.0234,  0.7335,  1.1177]],\n",
      "\n",
      "         [[ 0.5851, -1.1560, -0.1434, -0.1947],\n",
      "          [ 1.4903, -0.7005,  0.1806,  1.3615],\n",
      "          [-0.3661, -1.3271,  1.6953,  2.0655],\n",
      "          [ 0.2578, -0.5650,  0.9278,  0.4826]]]]),)\n",
      "kwargs from analyse_common_parameters_module {}\n",
      "meta before _annotate_arg_metadata: {'mase_type': 'module_related_func', 'mase_op': 'conv2d'}\n",
      "args[i]: tensor([[[[ 0.2886,  0.3866, -0.2011, -0.1179],\n",
      "          [-0.8294, -1.4073,  1.6268,  0.1723],\n",
      "          [-0.7043,  0.3147,  0.1574,  0.3854],\n",
      "          [ 0.5737,  0.9979,  0.5436,  0.0788]],\n",
      "\n",
      "         [[ 0.9985, -0.4987,  0.7611,  0.6183],\n",
      "          [-0.2994, -0.1878,  1.9159,  0.6902],\n",
      "          [-0.3140, -1.0787,  0.2408, -1.3962],\n",
      "          [ 0.1136,  1.1047, -1.3952,  0.4751]],\n",
      "\n",
      "         [[ 1.0811,  0.1315,  1.5735,  0.7814],\n",
      "          [ 0.9874, -1.4878,  0.5867,  0.1583],\n",
      "          [ 0.6668, -0.9944, -1.1894, -1.1959],\n",
      "          [ 1.3119, -0.2098,  0.7817,  0.9897]],\n",
      "\n",
      "         [[ 0.1715,  0.8760, -0.2871,  1.0216],\n",
      "          [-0.5111, -1.7137, -0.5101, -0.4749],\n",
      "          [ 0.6623, -1.2063,  0.6074, -0.5472],\n",
      "          [-1.1005, -0.7201,  0.0119,  0.3398]]],\n",
      "\n",
      "\n",
      "        [[[-1.2537,  0.9868, -0.4947, -1.2830],\n",
      "          [ 0.4386, -0.0107,  1.3384, -0.2794],\n",
      "          [ 0.2877, -0.0334, -1.0619, -0.1144],\n",
      "          [ 0.1954, -0.7371,  1.7001,  0.3462]],\n",
      "\n",
      "         [[-0.1448,  0.6376, -0.2813, -1.3299],\n",
      "          [-0.6538,  1.7198, -0.9610, -0.6375],\n",
      "          [-0.8870,  0.8388,  1.1529, -1.7611],\n",
      "          [-1.1070, -1.7174,  1.5346, -0.0032]],\n",
      "\n",
      "         [[ 1.4403, -0.1106,  0.5769, -0.1692],\n",
      "          [ 1.1887, -0.1575, -0.0455,  0.6485],\n",
      "          [-0.8707,  0.1447,  1.9029,  0.3904],\n",
      "          [ 0.0331, -1.0234,  0.7335,  1.1177]],\n",
      "\n",
      "         [[ 0.5851, -1.1560, -0.1434, -0.1947],\n",
      "          [ 1.4903, -0.7005,  0.1806,  1.3615],\n",
      "          [-0.3661, -1.3271,  1.6953,  2.0655],\n",
      "          [ 0.2578, -0.5650,  0.9278,  0.4826]]]])\n",
      "get_shape(args[i]) [2, 4, 4, 4]\n",
      "kwargs:  {}\n",
      "meta after _annotate_arg_metadata: {'mase_type': 'module_related_func', 'mase_op': 'conv2d', 'args': OrderedDict([('data_in_0', {'shape': [2, 4, 4, 4], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]})])}\n",
      "meta after get_type_and_precision: {'mase_type': 'module_related_func', 'mase_op': 'conv2d', 'args': OrderedDict([('data_in_0', {'shape': [2, 4, 4, 4], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]})])}\n",
      "weight\n",
      "bias\n",
      "stride (1, 1)\n",
      "Padding (1, 1)\n",
      "meta after for: {'mase_type': 'module_related_func', 'mase_op': 'conv2d', 'args': OrderedDict([('data_in_0', {'shape': [2, 4, 4, 4], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]}), ('weight', {'type': 'float', 'precision': [32], 'shape': [4, 4, 3, 3], 'from': None}), ('bias', {'type': 'float', 'precision': [32], 'shape': [1, 4], 'from': None}), ('stride', (1, 1)), ('padding', (1, 1))])}\n",
      "wobucao in add_common_metadata\n",
      "nihappp in add_common_metadata\n"
     ]
    }
   ],
   "source": [
    "cnn = SingleConvNet()\n",
    "mg = MaseGraph(model=cnn)\n",
    "\n",
    "# Provide a dummy input for the graph so it can use for tracing\n",
    "batch_size = 2\n",
    "# x = torch.randn((batch_size, 2, 2))\n",
    "# batch_size: number of examples\n",
    "# 1, 4,4,: each example has 1 channel, each channel has a size of 4x4\n",
    "x = torch.randn((batch_size, 4, 4, 4))\n",
    "# print(x)\n",
    "dummy_in = {\"x\": x}\n",
    "\n",
    "mg, _ = init_metadata_analysis_pass(mg, None)\n",
    "mg, _ = add_common_metadata_analysis_pass(\n",
    "    mg, {\"dummy_in\": dummy_in, \"add_value\": False}\n",
    ")\n",
    "# for node in mg.nodes:\n",
    "#         mase_op = node.meta[\"mase\"][\"common\"][\"mase_op\"]\n",
    "#         print (\"node.op:\", node.op)\n",
    "#         print ('mase_op:', mase_op)\n",
    "#         print (\"common:\",node.meta[\"mase\"][\"common\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "placeholder\n",
      "node_config:  {'name': 'fixed', 'data_in_width': 8, 'data_in_frac_width': 5, 'weight_width': 8, 'weight_frac_width': 5, 'bias_width': 8, 'bias_frac_width': 5, 'data_out_width': 8, 'data_out_frac_width': 5, 'floor': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mInspecting graph [add_common_node_type_analysis_pass]\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Node name    Fx Node op    Mase type            Mase op      Value type\n",
      "-----------  ------------  -------------------  -----------  ------------\n",
      "x            placeholder   placeholder          placeholder  NA\n",
      "conv1        call_module   module_related_func  conv2d       fixed\n",
      "output       output        output               output       NA\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output\n"
     ]
    }
   ],
   "source": [
    "config_file = os.path.join(\n",
    "    os.path.abspath(\"\"),\n",
    "    \"..\",\n",
    "    \"..\",\n",
    "    \"configs\",\n",
    "    \"tests\",\n",
    "    \"quantize\",\n",
    "    \"fixed.toml\",\n",
    ")\n",
    "# Fixed.toml used to quantize the model\n",
    "with open(config_file, \"r\") as f:\n",
    "    quan_args = toml.load(f)[\"passes\"][\"quantize\"]\n",
    "mg, _ = quantize_transform_pass(mg, quan_args)\n",
    "\n",
    "_ = report_node_type_analysis_pass(mg)\n",
    "\n",
    "# Update the metadata\n",
    "for node in mg.fx_graph.nodes:\n",
    "    for arg, arg_info in node.meta[\"mase\"][\"common\"][\"args\"].items():\n",
    "        if isinstance(arg_info, dict):\n",
    "            arg_info[\"type\"] = \"fixed\"\n",
    "            arg_info[\"precision\"] = [8, 5]\n",
    "    for result, result_info in node.meta[\"mase\"][\"common\"][\"results\"].items():\n",
    "        if isinstance(result_info, dict):\n",
    "            result_info[\"type\"] = \"fixed\"\n",
    "            result_info[\"precision\"] = [8, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hardware Metapass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mase_op: conv2d\n",
      "2222\n",
      " I changed max_parallelism add_hardware_metadata_analysis_pass\n",
      "vp:  {}\n",
      "arg in add_verilog_param: data_in_0\n",
      "vp after for:  {'DATA_IN_0_PRECISION_0': 8, 'DATA_IN_0_PRECISION_1': 5, 'DATA_IN_0_TENSOR_SIZE_DIM_0': 4, 'DATA_IN_0_PARALLELISM_DIM_0': 2, 'DATA_IN_0_TENSOR_SIZE_DIM_1': 4, 'DATA_IN_0_PARALLELISM_DIM_1': 2, 'DATA_IN_0_TENSOR_SIZE_DIM_2': 4, 'DATA_IN_0_PARALLELISM_DIM_2': 2, 'DATA_IN_0_TENSOR_SIZE_DIM_3': 2, 'DATA_IN_0_PARALLELISM_DIM_3': 2}\n",
      "arg in add_verilog_param: weight\n",
      "vp after for:  {'DATA_IN_0_PRECISION_0': 8, 'DATA_IN_0_PRECISION_1': 5, 'DATA_IN_0_TENSOR_SIZE_DIM_0': 4, 'DATA_IN_0_PARALLELISM_DIM_0': 2, 'DATA_IN_0_TENSOR_SIZE_DIM_1': 4, 'DATA_IN_0_PARALLELISM_DIM_1': 2, 'DATA_IN_0_TENSOR_SIZE_DIM_2': 4, 'DATA_IN_0_PARALLELISM_DIM_2': 2, 'DATA_IN_0_TENSOR_SIZE_DIM_3': 2, 'DATA_IN_0_PARALLELISM_DIM_3': 2, 'WEIGHT_PRECISION_0': 8, 'WEIGHT_PRECISION_1': 5, 'WEIGHT_TENSOR_SIZE_DIM_0': 3, 'WEIGHT_PARALLELISM_DIM_0': 2, 'WEIGHT_TENSOR_SIZE_DIM_1': 3, 'WEIGHT_PARALLELISM_DIM_1': 2, 'WEIGHT_TENSOR_SIZE_DIM_2': 4, 'WEIGHT_PARALLELISM_DIM_2': 2, 'WEIGHT_TENSOR_SIZE_DIM_3': 4, 'WEIGHT_PARALLELISM_DIM_3': 2}\n",
      "arg in add_verilog_param: bias\n",
      "vp after for:  {'DATA_IN_0_PRECISION_0': 8, 'DATA_IN_0_PRECISION_1': 5, 'DATA_IN_0_TENSOR_SIZE_DIM_0': 4, 'DATA_IN_0_PARALLELISM_DIM_0': 2, 'DATA_IN_0_TENSOR_SIZE_DIM_1': 4, 'DATA_IN_0_PARALLELISM_DIM_1': 2, 'DATA_IN_0_TENSOR_SIZE_DIM_2': 4, 'DATA_IN_0_PARALLELISM_DIM_2': 2, 'DATA_IN_0_TENSOR_SIZE_DIM_3': 2, 'DATA_IN_0_PARALLELISM_DIM_3': 2, 'WEIGHT_PRECISION_0': 8, 'WEIGHT_PRECISION_1': 5, 'WEIGHT_TENSOR_SIZE_DIM_0': 3, 'WEIGHT_PARALLELISM_DIM_0': 2, 'WEIGHT_TENSOR_SIZE_DIM_1': 3, 'WEIGHT_PARALLELISM_DIM_1': 2, 'WEIGHT_TENSOR_SIZE_DIM_2': 4, 'WEIGHT_PARALLELISM_DIM_2': 2, 'WEIGHT_TENSOR_SIZE_DIM_3': 4, 'WEIGHT_PARALLELISM_DIM_3': 2, 'BIAS_PRECISION_0': 8, 'BIAS_PRECISION_1': 5, 'BIAS_TENSOR_SIZE_DIM_0': 4, 'BIAS_PARALLELISM_DIM_0': 2, 'BIAS_TENSOR_SIZE_DIM_1': 1, 'BIAS_PARALLELISM_DIM_1': 1}\n",
      "vp after for:  {'DATA_IN_0_PRECISION_0': 8, 'DATA_IN_0_PRECISION_1': 5, 'DATA_IN_0_TENSOR_SIZE_DIM_0': 4, 'DATA_IN_0_PARALLELISM_DIM_0': 2, 'DATA_IN_0_TENSOR_SIZE_DIM_1': 4, 'DATA_IN_0_PARALLELISM_DIM_1': 2, 'DATA_IN_0_TENSOR_SIZE_DIM_2': 4, 'DATA_IN_0_PARALLELISM_DIM_2': 2, 'DATA_IN_0_TENSOR_SIZE_DIM_3': 2, 'DATA_IN_0_PARALLELISM_DIM_3': 2, 'WEIGHT_PRECISION_0': 8, 'WEIGHT_PRECISION_1': 5, 'WEIGHT_TENSOR_SIZE_DIM_0': 3, 'WEIGHT_PARALLELISM_DIM_0': 2, 'WEIGHT_TENSOR_SIZE_DIM_1': 3, 'WEIGHT_PARALLELISM_DIM_1': 2, 'WEIGHT_TENSOR_SIZE_DIM_2': 4, 'WEIGHT_PARALLELISM_DIM_2': 2, 'WEIGHT_TENSOR_SIZE_DIM_3': 4, 'WEIGHT_PARALLELISM_DIM_3': 2, 'BIAS_PRECISION_0': 8, 'BIAS_PRECISION_1': 5, 'BIAS_TENSOR_SIZE_DIM_0': 4, 'BIAS_PARALLELISM_DIM_0': 2, 'BIAS_TENSOR_SIZE_DIM_1': 1, 'BIAS_PARALLELISM_DIM_1': 1, 'STRIDE_TENSOR_SIZE_DIM_0_VALUE': 1, 'STRIDE_TENSOR_SIZE_DIM_1_VALUE': 1}\n",
      "vp after for:  {'DATA_IN_0_PRECISION_0': 8, 'DATA_IN_0_PRECISION_1': 5, 'DATA_IN_0_TENSOR_SIZE_DIM_0': 4, 'DATA_IN_0_PARALLELISM_DIM_0': 2, 'DATA_IN_0_TENSOR_SIZE_DIM_1': 4, 'DATA_IN_0_PARALLELISM_DIM_1': 2, 'DATA_IN_0_TENSOR_SIZE_DIM_2': 4, 'DATA_IN_0_PARALLELISM_DIM_2': 2, 'DATA_IN_0_TENSOR_SIZE_DIM_3': 2, 'DATA_IN_0_PARALLELISM_DIM_3': 2, 'WEIGHT_PRECISION_0': 8, 'WEIGHT_PRECISION_1': 5, 'WEIGHT_TENSOR_SIZE_DIM_0': 3, 'WEIGHT_PARALLELISM_DIM_0': 2, 'WEIGHT_TENSOR_SIZE_DIM_1': 3, 'WEIGHT_PARALLELISM_DIM_1': 2, 'WEIGHT_TENSOR_SIZE_DIM_2': 4, 'WEIGHT_PARALLELISM_DIM_2': 2, 'WEIGHT_TENSOR_SIZE_DIM_3': 4, 'WEIGHT_PARALLELISM_DIM_3': 2, 'BIAS_PRECISION_0': 8, 'BIAS_PRECISION_1': 5, 'BIAS_TENSOR_SIZE_DIM_0': 4, 'BIAS_PARALLELISM_DIM_0': 2, 'BIAS_TENSOR_SIZE_DIM_1': 1, 'BIAS_PARALLELISM_DIM_1': 1, 'STRIDE_TENSOR_SIZE_DIM_0_VALUE': 1, 'STRIDE_TENSOR_SIZE_DIM_1_VALUE': 1, 'PADDING_TENSOR_SIZE_DIM_0_VALUE': 1, 'PADDING_TENSOR_SIZE_DIM_1_VALUE': 1}\n",
      "result in add_verilog_param: data_out_0\n",
      "result_info in add_verilog_param: {'type': 'fixed', 'precision': [8, 5], 'shape': [2, 4, 4, 4], 'torch_dtype': torch.float32}\n",
      "node.op: placeholder\n",
      "mase_op: placeholder\n",
      "common: {'mase_type': 'placeholder', 'mase_op': 'placeholder', 'args': {}, 'results': OrderedDict([('data_out_0', {'type': 'fixed', 'precision': [8, 5], 'shape': [2, 4, 4, 4], 'torch_dtype': torch.float32})])}\n",
      "hardware: {'is_implicit': True, 'device_id': 0, 'max_parallelism': [2, 2, 2, 2]}\n",
      "node.op: call_module\n",
      "mase_op: conv2d\n",
      "common: {'mase_type': 'module_related_func', 'mase_op': 'conv2d', 'args': OrderedDict([('data_in_0', {'shape': [2, 4, 4, 4], 'torch_dtype': torch.float32, 'type': 'fixed', 'precision': [8, 5]}), ('weight', {'type': 'fixed', 'precision': [8, 5], 'shape': [4, 4, 3, 3], 'from': None}), ('bias', {'type': 'fixed', 'precision': [8, 5], 'shape': [1, 4], 'from': None}), ('stride', (1, 1)), ('padding', (1, 1))]), 'results': OrderedDict([('data_out_0', {'type': 'fixed', 'precision': [8, 5], 'shape': [2, 4, 4, 4], 'torch_dtype': torch.float32})])}\n",
      "hardware: {'is_implicit': False, 'device_id': -1, 'interface': {'weight': {'storage': 'BRAM', 'transpose': False}, 'bias': {'storage': 'BRAM', 'transpose': False}, 'stride': {}, 'padding': {}}, 'toolchain': 'INTERNAL_RTL', 'module': 'convolution', 'dependence_files': ['linear_layers/fixed_operators/rtl/fixed_dot_product.sv', 'linear_layers/fixed_operators/rtl/fixed_vector_mult.sv', 'linear_layers/fixed_operators/rtl/fixed_adder_tree.sv', 'linear_layers/fixed_operators/rtl/fixed_adder_tree_layer.sv', 'linear_layers/fixed_operators/rtl/fixed_accumulator.sv', 'linear_layers/fixed_operators/rtl/fixed_mult.sv', 'memory/rtl/input_buffer.sv', 'memory/rtl/unpacked_skid_buffer.sv', 'memory/rtl/skid_buffer.sv', 'memory/rtl/blk_mem_gen_0.sv', 'memory/rtl/unpacked_skid_buffer.sv', 'common/rtl/join2.sv', 'cast/rtl/floor_round.sv', 'cast/rtl/signed_clamp.sv', 'cast/rtl/fixed_signed_cast.sv', 'cast/rtl/fixed_cast.sv', 'cast/rtl/fixed_rounding.sv', 'convolution_layers/rtl/convolution_arith.sv', 'convolution_layers/rtl/convolution_mase.sv', 'convolution_layers/rtl/padding.sv', 'convolution_layers/rtl/roller.sv', 'convolution_layers/rtl/sliding_window.sv'], 'max_parallelism': [2, 2, 2, 2], 'verilog_param': {'DATA_IN_0_PRECISION_0': 8, 'DATA_IN_0_PRECISION_1': 5, 'DATA_IN_0_TENSOR_SIZE_DIM_0': 4, 'DATA_IN_0_PARALLELISM_DIM_0': 2, 'DATA_IN_0_TENSOR_SIZE_DIM_1': 4, 'DATA_IN_0_PARALLELISM_DIM_1': 2, 'DATA_IN_0_TENSOR_SIZE_DIM_2': 4, 'DATA_IN_0_PARALLELISM_DIM_2': 2, 'DATA_IN_0_TENSOR_SIZE_DIM_3': 2, 'DATA_IN_0_PARALLELISM_DIM_3': 2, 'WEIGHT_PRECISION_0': 8, 'WEIGHT_PRECISION_1': 5, 'WEIGHT_TENSOR_SIZE_DIM_0': 3, 'WEIGHT_PARALLELISM_DIM_0': 2, 'WEIGHT_TENSOR_SIZE_DIM_1': 3, 'WEIGHT_PARALLELISM_DIM_1': 2, 'WEIGHT_TENSOR_SIZE_DIM_2': 4, 'WEIGHT_PARALLELISM_DIM_2': 2, 'WEIGHT_TENSOR_SIZE_DIM_3': 4, 'WEIGHT_PARALLELISM_DIM_3': 2, 'BIAS_PRECISION_0': 8, 'BIAS_PRECISION_1': 5, 'BIAS_TENSOR_SIZE_DIM_0': 4, 'BIAS_PARALLELISM_DIM_0': 2, 'BIAS_TENSOR_SIZE_DIM_1': 1, 'BIAS_PARALLELISM_DIM_1': 1, 'STRIDE_TENSOR_SIZE_DIM_0_VALUE': 1, 'STRIDE_TENSOR_SIZE_DIM_1_VALUE': 1, 'PADDING_TENSOR_SIZE_DIM_0_VALUE': 1, 'PADDING_TENSOR_SIZE_DIM_1_VALUE': 1, 'DATA_OUT_0_PRECISION_0': 8, 'DATA_OUT_0_PRECISION_1': 5, 'DATA_OUT_0_TENSOR_SIZE_DIM_0': 4, 'DATA_OUT_0_PARALLELISM_DIM_0': 2, 'DATA_OUT_0_TENSOR_SIZE_DIM_1': 4, 'DATA_OUT_0_PARALLELISM_DIM_1': 2, 'DATA_OUT_0_TENSOR_SIZE_DIM_2': 4, 'DATA_OUT_0_PARALLELISM_DIM_2': 2, 'DATA_OUT_0_TENSOR_SIZE_DIM_3': 2, 'DATA_OUT_0_PARALLELISM_DIM_3': 2}}\n",
      "node.op: output\n",
      "mase_op: output\n",
      "common: {'mase_type': 'output', 'mase_op': 'output', 'args': {}, 'results': OrderedDict([('data_out_0', {'type': 'fixed', 'precision': [8, 5], 'shape': [2, 4, 4, 4], 'torch_dtype': torch.float32})])}\n",
      "hardware: {'is_implicit': True, 'device_id': 0, 'max_parallelism': [2, 2, 2, 2]}\n",
      "param_name in CNN.jynb: weight\n",
      "parameter in CNN.jynb: Parameter containing:\n",
      "tensor([[[[-0.0012,  0.0894, -0.1372],\n",
      "          [-0.1227, -0.0642,  0.0447],\n",
      "          [-0.0033,  0.1321, -0.0148]],\n",
      "\n",
      "         [[ 0.0441, -0.0504, -0.0328],\n",
      "          [-0.1592, -0.1104, -0.0687],\n",
      "          [ 0.0062,  0.0659,  0.1000]],\n",
      "\n",
      "         [[-0.1130, -0.0726,  0.0605],\n",
      "          [ 0.1384, -0.0343,  0.1247],\n",
      "          [-0.0269,  0.0176,  0.1509]],\n",
      "\n",
      "         [[-0.1546, -0.1049, -0.0422],\n",
      "          [-0.0650,  0.1440, -0.1080],\n",
      "          [-0.0767, -0.1164, -0.1561]]],\n",
      "\n",
      "\n",
      "        [[[-0.0973,  0.1433,  0.0744],\n",
      "          [ 0.0808,  0.0088, -0.0854],\n",
      "          [ 0.0282, -0.1556, -0.1204]],\n",
      "\n",
      "         [[-0.0859,  0.1052,  0.0977],\n",
      "          [-0.0739, -0.0060,  0.1066],\n",
      "          [ 0.1657,  0.0661,  0.0225]],\n",
      "\n",
      "         [[ 0.1117, -0.0981,  0.0311],\n",
      "          [-0.1292, -0.1155, -0.0861],\n",
      "          [ 0.0754,  0.0670, -0.0987]],\n",
      "\n",
      "         [[ 0.0504,  0.0915, -0.0210],\n",
      "          [ 0.0064,  0.0386,  0.1034],\n",
      "          [ 0.1600, -0.1284, -0.0611]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0655,  0.1381,  0.1450],\n",
      "          [ 0.1471,  0.0332, -0.1449],\n",
      "          [ 0.0153, -0.1043, -0.1553]],\n",
      "\n",
      "         [[ 0.1481,  0.1267, -0.1663],\n",
      "          [ 0.0312, -0.0281, -0.0274],\n",
      "          [-0.0763,  0.0641, -0.0987]],\n",
      "\n",
      "         [[ 0.0611,  0.0843,  0.1193],\n",
      "          [ 0.0623, -0.1650, -0.1081],\n",
      "          [ 0.0832,  0.0349, -0.1300]],\n",
      "\n",
      "         [[-0.0960,  0.1568,  0.1123],\n",
      "          [-0.0727, -0.0419, -0.1588],\n",
      "          [-0.0030, -0.1255, -0.1286]]],\n",
      "\n",
      "\n",
      "        [[[-0.0092,  0.0250, -0.0683],\n",
      "          [ 0.0989, -0.1014,  0.1512],\n",
      "          [ 0.1142, -0.1405, -0.0415]],\n",
      "\n",
      "         [[ 0.0075,  0.0243,  0.0395],\n",
      "          [ 0.0654,  0.0100, -0.0813],\n",
      "          [ 0.0789, -0.1599, -0.0988]],\n",
      "\n",
      "         [[-0.0417, -0.0812, -0.0583],\n",
      "          [-0.1366, -0.0355,  0.0356],\n",
      "          [-0.1086, -0.0086,  0.1193]],\n",
      "\n",
      "         [[-0.0171,  0.0046, -0.0144],\n",
      "          [ 0.0337,  0.1060,  0.1579],\n",
      "          [ 0.1058,  0.1582, -0.0121]]]], requires_grad=True)\n",
      "param_name in CNN.jynb: bias\n",
      "parameter in CNN.jynb: Parameter containing:\n",
      "tensor([ 0.0089, -0.1029,  0.0085,  0.0799], requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nweights and bias in the Conv/linear in Maze\\nparam_data = node.meta[\"mase\"].module.get_parameter(param_name).data\\nprint (\"param_data: \", param_data)\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mg, _ = add_hardware_metadata_analysis_pass(mg)\n",
    "for node in mg.nodes:\n",
    "        mase_op = node.meta[\"mase\"][\"common\"][\"mase_op\"]\n",
    "        print (\"node.op:\", node.op)\n",
    "        print ('mase_op:', mase_op)\n",
    "        print (\"common:\",node.meta[\"mase\"][\"common\"])\n",
    "        print (\"hardware:\",node.meta[\"mase\"][\"hardware\"])\n",
    "\n",
    "for node in mg.fx_graph.nodes:\n",
    "        if node.meta[\"mase\"].parameters[\"hardware\"][\"is_implicit\"]:\n",
    "            continue\n",
    "        # Only modules have internal parameters\n",
    "        if node.meta[\"mase\"].module is None:\n",
    "            continue\n",
    "        # print (node.meta[\"mase\"].parameters[\"hardware\"])\n",
    "        # Only checks the hardware data that contains the key toolchain\n",
    "        if \"INTERNAL\" in node.meta[\"mase\"].parameters[\"hardware\"][\"toolchain\"]:\n",
    "                for param_name, parameter in node.meta[\"mase\"].module.named_parameters():\n",
    "                        print (\"param_name in CNN.jynb:\",param_name)\n",
    "                        print (\"parameter in CNN.jynb:\", parameter)\n",
    "\n",
    "\"\"\"\n",
    "weights and bias in the Conv/linear in Maze\n",
    "param_data = node.meta[\"mase\"].module.get_parameter(param_name).data\n",
    "print (\"param_data: \", param_data)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emit for SV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mEmitting Verilog...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEmitting internal components...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter_map in VerilogEmitter: {'conv1_DATA_IN_0_PRECISION_0': 8, 'conv1_DATA_IN_0_PRECISION_1': 5, 'conv1_DATA_IN_0_TENSOR_SIZE_DIM_0': 4, 'conv1_DATA_IN_0_PARALLELISM_DIM_0': 2, 'conv1_DATA_IN_0_TENSOR_SIZE_DIM_1': 4, 'conv1_DATA_IN_0_PARALLELISM_DIM_1': 2, 'conv1_DATA_IN_0_TENSOR_SIZE_DIM_2': 4, 'conv1_DATA_IN_0_PARALLELISM_DIM_2': 2, 'conv1_DATA_IN_0_TENSOR_SIZE_DIM_3': 2, 'conv1_DATA_IN_0_PARALLELISM_DIM_3': 2, 'conv1_WEIGHT_PRECISION_0': 8, 'conv1_WEIGHT_PRECISION_1': 5, 'conv1_WEIGHT_TENSOR_SIZE_DIM_0': 3, 'conv1_WEIGHT_PARALLELISM_DIM_0': 2, 'conv1_WEIGHT_TENSOR_SIZE_DIM_1': 3, 'conv1_WEIGHT_PARALLELISM_DIM_1': 2, 'conv1_WEIGHT_TENSOR_SIZE_DIM_2': 4, 'conv1_WEIGHT_PARALLELISM_DIM_2': 2, 'conv1_WEIGHT_TENSOR_SIZE_DIM_3': 4, 'conv1_WEIGHT_PARALLELISM_DIM_3': 2, 'conv1_BIAS_PRECISION_0': 8, 'conv1_BIAS_PRECISION_1': 5, 'conv1_BIAS_TENSOR_SIZE_DIM_0': 4, 'conv1_BIAS_PARALLELISM_DIM_0': 2, 'conv1_BIAS_TENSOR_SIZE_DIM_1': 1, 'conv1_BIAS_PARALLELISM_DIM_1': 1, 'conv1_STRIDE_TENSOR_SIZE_DIM_0_VALUE': 1, 'conv1_STRIDE_TENSOR_SIZE_DIM_1_VALUE': 1, 'conv1_PADDING_TENSOR_SIZE_DIM_0_VALUE': 1, 'conv1_PADDING_TENSOR_SIZE_DIM_1_VALUE': 1, 'conv1_DATA_OUT_0_PRECISION_0': 8, 'conv1_DATA_OUT_0_PRECISION_1': 5, 'conv1_DATA_OUT_0_TENSOR_SIZE_DIM_0': 4, 'conv1_DATA_OUT_0_PARALLELISM_DIM_0': 2, 'conv1_DATA_OUT_0_TENSOR_SIZE_DIM_1': 4, 'conv1_DATA_OUT_0_PARALLELISM_DIM_1': 2, 'conv1_DATA_OUT_0_TENSOR_SIZE_DIM_2': 4, 'conv1_DATA_OUT_0_PARALLELISM_DIM_2': 2, 'conv1_DATA_OUT_0_TENSOR_SIZE_DIM_3': 2, 'conv1_DATA_OUT_0_PARALLELISM_DIM_3': 2, 'DATA_IN_0_PRECISION_0': 8, 'DATA_IN_0_PRECISION_1': 5, 'DATA_IN_0_TENSOR_SIZE_DIM_0': 4, 'DATA_IN_0_PARALLELISM_DIM_0': 2, 'DATA_IN_0_TENSOR_SIZE_DIM_1': 4, 'DATA_IN_0_PARALLELISM_DIM_1': 2, 'DATA_IN_0_TENSOR_SIZE_DIM_2': 4, 'DATA_IN_0_PARALLELISM_DIM_2': 2, 'DATA_IN_0_TENSOR_SIZE_DIM_3': 2, 'DATA_IN_0_PARALLELISM_DIM_3': 2, 'DATA_OUT_0_PRECISION_0': 8, 'DATA_OUT_0_PRECISION_1': 5, 'DATA_OUT_0_TENSOR_SIZE_DIM_0': 4, 'DATA_OUT_0_PARALLELISM_DIM_0': 2, 'DATA_OUT_0_TENSOR_SIZE_DIM_1': 4, 'DATA_OUT_0_PARALLELISM_DIM_1': 2, 'DATA_OUT_0_TENSOR_SIZE_DIM_2': 4, 'DATA_OUT_0_PARALLELISM_DIM_2': 2, 'DATA_OUT_0_TENSOR_SIZE_DIM_3': 2, 'DATA_OUT_0_PARALLELISM_DIM_3': 2}\n",
      "nodes_in: [conv1]\n",
      "nodes_out: [conv1]\n",
      "parameter in VerilogParameterEmitter:     parameter conv1_DATA_IN_0_PRECISION_0 = 8,\n",
      "    parameter conv1_DATA_IN_0_PRECISION_1 = 5,\n",
      "    parameter conv1_DATA_IN_0_TENSOR_SIZE_DIM_0 = 4,\n",
      "    parameter conv1_DATA_IN_0_PARALLELISM_DIM_0 = 2,\n",
      "    parameter conv1_DATA_IN_0_TENSOR_SIZE_DIM_1 = 4,\n",
      "    parameter conv1_DATA_IN_0_PARALLELISM_DIM_1 = 2,\n",
      "    parameter conv1_DATA_IN_0_TENSOR_SIZE_DIM_2 = 4,\n",
      "    parameter conv1_DATA_IN_0_PARALLELISM_DIM_2 = 2,\n",
      "    parameter conv1_DATA_IN_0_TENSOR_SIZE_DIM_3 = 2,\n",
      "    parameter conv1_DATA_IN_0_PARALLELISM_DIM_3 = 2,\n",
      "    parameter conv1_WEIGHT_PRECISION_0 = 8,\n",
      "    parameter conv1_WEIGHT_PRECISION_1 = 5,\n",
      "    parameter conv1_WEIGHT_TENSOR_SIZE_DIM_0 = 3,\n",
      "    parameter conv1_WEIGHT_PARALLELISM_DIM_0 = 2,\n",
      "    parameter conv1_WEIGHT_TENSOR_SIZE_DIM_1 = 3,\n",
      "    parameter conv1_WEIGHT_PARALLELISM_DIM_1 = 2,\n",
      "    parameter conv1_WEIGHT_TENSOR_SIZE_DIM_2 = 4,\n",
      "    parameter conv1_WEIGHT_PARALLELISM_DIM_2 = 2,\n",
      "    parameter conv1_WEIGHT_TENSOR_SIZE_DIM_3 = 4,\n",
      "    parameter conv1_WEIGHT_PARALLELISM_DIM_3 = 2,\n",
      "    parameter conv1_BIAS_PRECISION_0 = 8,\n",
      "    parameter conv1_BIAS_PRECISION_1 = 5,\n",
      "    parameter conv1_BIAS_TENSOR_SIZE_DIM_0 = 4,\n",
      "    parameter conv1_BIAS_PARALLELISM_DIM_0 = 2,\n",
      "    parameter conv1_BIAS_TENSOR_SIZE_DIM_1 = 1,\n",
      "    parameter conv1_BIAS_PARALLELISM_DIM_1 = 1,\n",
      "    parameter conv1_STRIDE_TENSOR_SIZE_DIM_0_VALUE = 1,\n",
      "    parameter conv1_STRIDE_TENSOR_SIZE_DIM_1_VALUE = 1,\n",
      "    parameter conv1_PADDING_TENSOR_SIZE_DIM_0_VALUE = 1,\n",
      "    parameter conv1_PADDING_TENSOR_SIZE_DIM_1_VALUE = 1,\n",
      "    parameter conv1_DATA_OUT_0_PRECISION_0 = 8,\n",
      "    parameter conv1_DATA_OUT_0_PRECISION_1 = 5,\n",
      "    parameter conv1_DATA_OUT_0_TENSOR_SIZE_DIM_0 = 4,\n",
      "    parameter conv1_DATA_OUT_0_PARALLELISM_DIM_0 = 2,\n",
      "    parameter conv1_DATA_OUT_0_TENSOR_SIZE_DIM_1 = 4,\n",
      "    parameter conv1_DATA_OUT_0_PARALLELISM_DIM_1 = 2,\n",
      "    parameter conv1_DATA_OUT_0_TENSOR_SIZE_DIM_2 = 4,\n",
      "    parameter conv1_DATA_OUT_0_PARALLELISM_DIM_2 = 2,\n",
      "    parameter conv1_DATA_OUT_0_TENSOR_SIZE_DIM_3 = 2,\n",
      "    parameter conv1_DATA_OUT_0_PARALLELISM_DIM_3 = 2,\n",
      "    parameter DATA_IN_0_PRECISION_0 = 8,\n",
      "    parameter DATA_IN_0_PRECISION_1 = 5,\n",
      "    parameter DATA_IN_0_TENSOR_SIZE_DIM_0 = 4,\n",
      "    parameter DATA_IN_0_PARALLELISM_DIM_0 = 2,\n",
      "    parameter DATA_IN_0_TENSOR_SIZE_DIM_1 = 4,\n",
      "    parameter DATA_IN_0_PARALLELISM_DIM_1 = 2,\n",
      "    parameter DATA_IN_0_TENSOR_SIZE_DIM_2 = 4,\n",
      "    parameter DATA_IN_0_PARALLELISM_DIM_2 = 2,\n",
      "    parameter DATA_IN_0_TENSOR_SIZE_DIM_3 = 2,\n",
      "    parameter DATA_IN_0_PARALLELISM_DIM_3 = 2,\n",
      "    parameter DATA_OUT_0_PRECISION_0 = 8,\n",
      "    parameter DATA_OUT_0_PRECISION_1 = 5,\n",
      "    parameter DATA_OUT_0_TENSOR_SIZE_DIM_0 = 4,\n",
      "    parameter DATA_OUT_0_PARALLELISM_DIM_0 = 2,\n",
      "    parameter DATA_OUT_0_TENSOR_SIZE_DIM_1 = 4,\n",
      "    parameter DATA_OUT_0_PARALLELISM_DIM_1 = 2,\n",
      "    parameter DATA_OUT_0_TENSOR_SIZE_DIM_2 = 4,\n",
      "    parameter DATA_OUT_0_PARALLELISM_DIM_2 = 2,\n",
      "    parameter DATA_OUT_0_TENSOR_SIZE_DIM_3 = 2,\n",
      "    parameter DATA_OUT_0_PARALLELISM_DIM_3 = 2,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mg, _ = emit_verilog_top_transform_pass(mg)\n",
    "mg, _ = emit_internal_rtl_transform_pass(mg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mEmitting BRAM...\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[34mEmitting DAT file for node: conv1, parameter: weight\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[34mROM module weight successfully written into /root/.mase/top/hardware/rtl/conv1_weight_source.sv\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[34mInit data weight successfully written into /root/.mase/top/hardware/rtl/conv1_weight_rom.dat\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[34mEmitting DAT file for node: conv1, parameter: bias\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[34mROM module bias successfully written into /root/.mase/top/hardware/rtl/conv1_bias_source.sv\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[34mInit data bias successfully written into /root/.mase/top/hardware/rtl/conv1_bias_rom.dat\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 in emit_bram_transform_pass\n",
      "/root/.mase/top/hardware/rtl\n",
      "param_name in emit_bram_handshake: weight\n",
      "out_size: 16\n",
      "out_size in emit_parameters_in_mem_internal: 16\n",
      "conv1\n",
      "verilog_param_name weight\n",
      "total_size: 144\n",
      "shape: [4, 4, 3, 3]\n",
      " node.meta[mase].parameters[hardware][verilog_param] {'DATA_IN_0_PRECISION_0': 8, 'DATA_IN_0_PRECISION_1': 5, 'DATA_IN_0_TENSOR_SIZE_DIM_0': 4, 'DATA_IN_0_PARALLELISM_DIM_0': 2, 'DATA_IN_0_TENSOR_SIZE_DIM_1': 4, 'DATA_IN_0_PARALLELISM_DIM_1': 2, 'DATA_IN_0_TENSOR_SIZE_DIM_2': 4, 'DATA_IN_0_PARALLELISM_DIM_2': 2, 'DATA_IN_0_TENSOR_SIZE_DIM_3': 2, 'DATA_IN_0_PARALLELISM_DIM_3': 2, 'WEIGHT_PRECISION_0': 8, 'WEIGHT_PRECISION_1': 5, 'WEIGHT_TENSOR_SIZE_DIM_0': 3, 'WEIGHT_PARALLELISM_DIM_0': 2, 'WEIGHT_TENSOR_SIZE_DIM_1': 3, 'WEIGHT_PARALLELISM_DIM_1': 2, 'WEIGHT_TENSOR_SIZE_DIM_2': 4, 'WEIGHT_PARALLELISM_DIM_2': 2, 'WEIGHT_TENSOR_SIZE_DIM_3': 4, 'WEIGHT_PARALLELISM_DIM_3': 2, 'BIAS_PRECISION_0': 8, 'BIAS_PRECISION_1': 5, 'BIAS_TENSOR_SIZE_DIM_0': 4, 'BIAS_PARALLELISM_DIM_0': 2, 'BIAS_TENSOR_SIZE_DIM_1': 1, 'BIAS_PARALLELISM_DIM_1': 1, 'STRIDE_TENSOR_SIZE_DIM_0_VALUE': 1, 'STRIDE_TENSOR_SIZE_DIM_1_VALUE': 1, 'PADDING_TENSOR_SIZE_DIM_0_VALUE': 1, 'PADDING_TENSOR_SIZE_DIM_1_VALUE': 1, 'DATA_OUT_0_PRECISION_0': 8, 'DATA_OUT_0_PRECISION_1': 5, 'DATA_OUT_0_TENSOR_SIZE_DIM_0': 4, 'DATA_OUT_0_PARALLELISM_DIM_0': 2, 'DATA_OUT_0_TENSOR_SIZE_DIM_1': 4, 'DATA_OUT_0_PARALLELISM_DIM_1': 2, 'DATA_OUT_0_TENSOR_SIZE_DIM_2': 4, 'DATA_OUT_0_PARALLELISM_DIM_2': 2, 'DATA_OUT_0_TENSOR_SIZE_DIM_3': 2, 'DATA_OUT_0_PARALLELISM_DIM_3': 2}\n",
      "out_size: 16\n",
      "param_data in emit_parameters_in_dat_internal:  tensor([[[[-0.0012,  0.0894, -0.1372],\n",
      "          [-0.1227, -0.0642,  0.0447],\n",
      "          [-0.0033,  0.1321, -0.0148]],\n",
      "\n",
      "         [[ 0.0441, -0.0504, -0.0328],\n",
      "          [-0.1592, -0.1104, -0.0687],\n",
      "          [ 0.0062,  0.0659,  0.1000]],\n",
      "\n",
      "         [[-0.1130, -0.0726,  0.0605],\n",
      "          [ 0.1384, -0.0343,  0.1247],\n",
      "          [-0.0269,  0.0176,  0.1509]],\n",
      "\n",
      "         [[-0.1546, -0.1049, -0.0422],\n",
      "          [-0.0650,  0.1440, -0.1080],\n",
      "          [-0.0767, -0.1164, -0.1561]]],\n",
      "\n",
      "\n",
      "        [[[-0.0973,  0.1433,  0.0744],\n",
      "          [ 0.0808,  0.0088, -0.0854],\n",
      "          [ 0.0282, -0.1556, -0.1204]],\n",
      "\n",
      "         [[-0.0859,  0.1052,  0.0977],\n",
      "          [-0.0739, -0.0060,  0.1066],\n",
      "          [ 0.1657,  0.0661,  0.0225]],\n",
      "\n",
      "         [[ 0.1117, -0.0981,  0.0311],\n",
      "          [-0.1292, -0.1155, -0.0861],\n",
      "          [ 0.0754,  0.0670, -0.0987]],\n",
      "\n",
      "         [[ 0.0504,  0.0915, -0.0210],\n",
      "          [ 0.0064,  0.0386,  0.1034],\n",
      "          [ 0.1600, -0.1284, -0.0611]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0655,  0.1381,  0.1450],\n",
      "          [ 0.1471,  0.0332, -0.1449],\n",
      "          [ 0.0153, -0.1043, -0.1553]],\n",
      "\n",
      "         [[ 0.1481,  0.1267, -0.1663],\n",
      "          [ 0.0312, -0.0281, -0.0274],\n",
      "          [-0.0763,  0.0641, -0.0987]],\n",
      "\n",
      "         [[ 0.0611,  0.0843,  0.1193],\n",
      "          [ 0.0623, -0.1650, -0.1081],\n",
      "          [ 0.0832,  0.0349, -0.1300]],\n",
      "\n",
      "         [[-0.0960,  0.1568,  0.1123],\n",
      "          [-0.0727, -0.0419, -0.1588],\n",
      "          [-0.0030, -0.1255, -0.1286]]],\n",
      "\n",
      "\n",
      "        [[[-0.0092,  0.0250, -0.0683],\n",
      "          [ 0.0989, -0.1014,  0.1512],\n",
      "          [ 0.1142, -0.1405, -0.0415]],\n",
      "\n",
      "         [[ 0.0075,  0.0243,  0.0395],\n",
      "          [ 0.0654,  0.0100, -0.0813],\n",
      "          [ 0.0789, -0.1599, -0.0988]],\n",
      "\n",
      "         [[-0.0417, -0.0812, -0.0583],\n",
      "          [-0.1366, -0.0355,  0.0356],\n",
      "          [-0.1086, -0.0086,  0.1193]],\n",
      "\n",
      "         [[-0.0171,  0.0046, -0.0144],\n",
      "          [ 0.0337,  0.1060,  0.1579],\n",
      "          [ 0.1058,  0.1582, -0.0121]]]])\n",
      "param_data in emit_parameters_in_dat_internal after flatten:  [-0.0012478083372116089, 0.08940728008747101, -0.13717418909072876, -0.12265650928020477, -0.06419239938259125, 0.04469288885593414, -0.0033022016286849976, 0.13214825093746185, -0.014790669083595276, 0.04410208761692047, -0.05036884546279907, -0.03276090323925018, -0.1592247486114502, -0.11038035154342651, -0.06870385259389877, 0.00617392361164093, 0.06588919460773468, 0.10000379383563995, -0.11299018561840057, -0.07257714122533798, 0.06053619086742401, 0.13839800655841827, -0.034300029277801514, 0.12471862137317657, -0.026863887906074524, 0.017635688185691833, 0.15091271698474884, -0.154611736536026, -0.10492299497127533, -0.04219420999288559, -0.06496666371822357, 0.1440001279115677, -0.10802994668483734, -0.0767221450805664, -0.11644008010625839, -0.1560935080051422, -0.09729008376598358, 0.14326633512973785, 0.07436972856521606, 0.08077876269817352, 0.008765265345573425, -0.08544725179672241, 0.028197452425956726, -0.15561579167842865, -0.12042771279811859, -0.08592166751623154, 0.1051563173532486, 0.09772022068500519, -0.07391583919525146, -0.006013736128807068, 0.10659344494342804, 0.16568885743618011, 0.06614702939987183, 0.022515475749969482, 0.11174772679805756, -0.09813372790813446, 0.031057342886924744, -0.12921759486198425, -0.1155143603682518, -0.08609726279973984, 0.07541216909885406, 0.06702673435211182, -0.09872542321681976, 0.05035118758678436, 0.09149535000324249, -0.021036222577095032, 0.006363585591316223, 0.03861744701862335, 0.10339610278606415, 0.16003234684467316, -0.12843726575374603, -0.06107829511165619, 0.06550164520740509, 0.138091579079628, 0.1450345665216446, 0.14705945551395416, 0.03316909074783325, -0.14493045210838318, 0.015332087874412537, -0.10426755994558334, -0.15532569587230682, 0.14808209240436554, 0.1267266422510147, -0.1662546694278717, 0.031195342540740967, -0.028076663613319397, -0.02742685377597809, -0.07629281282424927, 0.06409269571304321, -0.09871725738048553, 0.06109856069087982, 0.08428467810153961, 0.11931194365024567, 0.06231851875782013, -0.16495588421821594, -0.10811614990234375, 0.08321917057037354, 0.03488355875015259, -0.13001400232315063, -0.09596991539001465, 0.156791552901268, 0.11230297386646271, -0.07267086207866669, -0.04194746911525726, -0.15876635909080505, -0.0029956847429275513, -0.1255098283290863, -0.12855945527553558, -0.00918327271938324, 0.0250241756439209, -0.06825505197048187, 0.09889627993106842, -0.10142318904399872, 0.15122835338115692, 0.1142166405916214, -0.14054715633392334, -0.04148072004318237, 0.007520437240600586, 0.024316847324371338, 0.039529040455818176, 0.06540471315383911, 0.009983360767364502, -0.08132146298885345, 0.07886482775211334, -0.159874826669693, -0.0987844467163086, -0.0417216420173645, -0.08118556439876556, -0.058305561542510986, -0.13660362362861633, -0.03545252978801727, 0.03562606871128082, -0.10857763141393661, -0.008553221821784973, 0.1193084865808487, -0.01713337004184723, 0.004632040858268738, -0.014378145337104797, 0.03373022377490997, 0.1059732586145401, 0.15787436068058014, 0.10584266483783722, 0.1582355946302414, -0.012053608894348145]\n",
      "out_depth:  9\n",
      "value in dec: 0.0062\n",
      "value in signed fixed: 0\n",
      "value in binary: 0b0\n",
      "value_bits: 00\n",
      "value in dec: -0.0687\n",
      "value in signed fixed: 254\n",
      "value in binary: 0b11111110\n",
      "value_bits: fe\n",
      "value in dec: -0.1104\n",
      "value in signed fixed: 252\n",
      "value in binary: 0b11111100\n",
      "value_bits: fc\n",
      "value in dec: -0.1592\n",
      "value in signed fixed: 251\n",
      "value in binary: 0b11111011\n",
      "value_bits: fb\n",
      "value in dec: -0.0328\n",
      "value in signed fixed: 255\n",
      "value in binary: 0b11111111\n",
      "value_bits: ff\n",
      "value in dec: -0.0504\n",
      "value in signed fixed: 254\n",
      "value in binary: 0b11111110\n",
      "value_bits: fe\n",
      "value in dec: 0.0441\n",
      "value in signed fixed: 1\n",
      "value in binary: 0b1\n",
      "value_bits: 01\n",
      "value in dec: -0.0148\n",
      "value in signed fixed: 0\n",
      "value in binary: 0b0\n",
      "value_bits: 00\n",
      "value in dec: 0.1321\n",
      "value in signed fixed: 4\n",
      "value in binary: 0b100\n",
      "value_bits: 04\n",
      "value in dec: -0.0033\n",
      "value in signed fixed: 0\n",
      "value in binary: 0b0\n",
      "value_bits: 00\n",
      "value in dec: 0.0447\n",
      "value in signed fixed: 1\n",
      "value in binary: 0b1\n",
      "value_bits: 01\n",
      "value in dec: -0.0642\n",
      "value in signed fixed: 254\n",
      "value in binary: 0b11111110\n",
      "value_bits: fe\n",
      "value in dec: -0.1227\n",
      "value in signed fixed: 252\n",
      "value in binary: 0b11111100\n",
      "value_bits: fc\n",
      "value in dec: -0.1372\n",
      "value in signed fixed: 252\n",
      "value in binary: 0b11111100\n",
      "value_bits: fc\n",
      "value in dec: 0.0894\n",
      "value in signed fixed: 3\n",
      "value in binary: 0b11\n",
      "value_bits: 03\n",
      "value in dec: -0.0012\n",
      "value in signed fixed: 0\n",
      "value in binary: 0b0\n",
      "value_bits: 00\n",
      "value in dec: 0.144\n",
      "value in signed fixed: 5\n",
      "value in binary: 0b101\n",
      "value_bits: 05\n",
      "value in dec: -0.065\n",
      "value in signed fixed: 254\n",
      "value in binary: 0b11111110\n",
      "value_bits: fe\n",
      "value in dec: -0.0422\n",
      "value in signed fixed: 255\n",
      "value in binary: 0b11111111\n",
      "value_bits: ff\n",
      "value in dec: -0.1049\n",
      "value in signed fixed: 253\n",
      "value in binary: 0b11111101\n",
      "value_bits: fd\n",
      "value in dec: -0.1546\n",
      "value in signed fixed: 251\n",
      "value in binary: 0b11111011\n",
      "value_bits: fb\n",
      "value in dec: 0.1509\n",
      "value in signed fixed: 5\n",
      "value in binary: 0b101\n",
      "value_bits: 05\n",
      "value in dec: 0.0176\n",
      "value in signed fixed: 1\n",
      "value in binary: 0b1\n",
      "value_bits: 01\n",
      "value in dec: -0.0269\n",
      "value in signed fixed: 255\n",
      "value in binary: 0b11111111\n",
      "value_bits: ff\n",
      "value in dec: 0.1247\n",
      "value in signed fixed: 4\n",
      "value in binary: 0b100\n",
      "value_bits: 04\n",
      "value in dec: -0.0343\n",
      "value in signed fixed: 255\n",
      "value in binary: 0b11111111\n",
      "value_bits: ff\n",
      "value in dec: 0.1384\n",
      "value in signed fixed: 4\n",
      "value in binary: 0b100\n",
      "value_bits: 04\n",
      "value in dec: 0.0605\n",
      "value in signed fixed: 2\n",
      "value in binary: 0b10\n",
      "value_bits: 02\n",
      "value in dec: -0.0726\n",
      "value in signed fixed: 254\n",
      "value in binary: 0b11111110\n",
      "value_bits: fe\n",
      "value in dec: -0.113\n",
      "value in signed fixed: 252\n",
      "value in binary: 0b11111100\n",
      "value_bits: fc\n",
      "value in dec: 0.1\n",
      "value in signed fixed: 3\n",
      "value in binary: 0b11\n",
      "value_bits: 03\n",
      "value in dec: 0.0659\n",
      "value in signed fixed: 2\n",
      "value in binary: 0b10\n",
      "value_bits: 02\n",
      "value in dec: 0.0977\n",
      "value in signed fixed: 3\n",
      "value in binary: 0b11\n",
      "value_bits: 03\n",
      "value in dec: 0.1052\n",
      "value in signed fixed: 3\n",
      "value in binary: 0b11\n",
      "value_bits: 03\n",
      "value in dec: -0.0859\n",
      "value in signed fixed: 253\n",
      "value in binary: 0b11111101\n",
      "value_bits: fd\n",
      "value in dec: -0.1204\n",
      "value in signed fixed: 252\n",
      "value in binary: 0b11111100\n",
      "value_bits: fc\n",
      "value in dec: -0.1556\n",
      "value in signed fixed: 251\n",
      "value in binary: 0b11111011\n",
      "value_bits: fb\n",
      "value in dec: 0.0282\n",
      "value in signed fixed: 1\n",
      "value in binary: 0b1\n",
      "value_bits: 01\n",
      "value in dec: -0.0854\n",
      "value in signed fixed: 253\n",
      "value in binary: 0b11111101\n",
      "value_bits: fd\n",
      "value in dec: 0.0088\n",
      "value in signed fixed: 0\n",
      "value in binary: 0b0\n",
      "value_bits: 00\n",
      "value in dec: 0.0808\n",
      "value in signed fixed: 3\n",
      "value in binary: 0b11\n",
      "value_bits: 03\n",
      "value in dec: 0.0744\n",
      "value in signed fixed: 2\n",
      "value in binary: 0b10\n",
      "value_bits: 02\n",
      "value in dec: 0.1433\n",
      "value in signed fixed: 5\n",
      "value in binary: 0b101\n",
      "value_bits: 05\n",
      "value in dec: -0.0973\n",
      "value in signed fixed: 253\n",
      "value in binary: 0b11111101\n",
      "value_bits: fd\n",
      "value in dec: -0.1561\n",
      "value in signed fixed: 251\n",
      "value in binary: 0b11111011\n",
      "value_bits: fb\n",
      "value in dec: -0.1164\n",
      "value in signed fixed: 252\n",
      "value in binary: 0b11111100\n",
      "value_bits: fc\n",
      "value in dec: -0.0767\n",
      "value in signed fixed: 254\n",
      "value in binary: 0b11111110\n",
      "value_bits: fe\n",
      "value in dec: -0.108\n",
      "value in signed fixed: 253\n",
      "value in binary: 0b11111101\n",
      "value_bits: fd\n",
      "value in dec: 0.0504\n",
      "value in signed fixed: 2\n",
      "value in binary: 0b10\n",
      "value_bits: 02\n",
      "value in dec: -0.0987\n",
      "value in signed fixed: 253\n",
      "value in binary: 0b11111101\n",
      "value_bits: fd\n",
      "value in dec: 0.067\n",
      "value in signed fixed: 2\n",
      "value in binary: 0b10\n",
      "value_bits: 02\n",
      "value in dec: 0.0754\n",
      "value in signed fixed: 2\n",
      "value in binary: 0b10\n",
      "value_bits: 02\n",
      "value in dec: -0.0861\n",
      "value in signed fixed: 253\n",
      "value in binary: 0b11111101\n",
      "value_bits: fd\n",
      "value in dec: -0.1155\n",
      "value in signed fixed: 252\n",
      "value in binary: 0b11111100\n",
      "value_bits: fc\n",
      "value in dec: -0.1292\n",
      "value in signed fixed: 252\n",
      "value in binary: 0b11111100\n",
      "value_bits: fc\n",
      "value in dec: 0.0311\n",
      "value in signed fixed: 1\n",
      "value in binary: 0b1\n",
      "value_bits: 01\n",
      "value in dec: -0.0981\n",
      "value in signed fixed: 253\n",
      "value in binary: 0b11111101\n",
      "value_bits: fd\n",
      "value in dec: 0.1117\n",
      "value in signed fixed: 4\n",
      "value in binary: 0b100\n",
      "value_bits: 04\n",
      "value in dec: 0.0225\n",
      "value in signed fixed: 1\n",
      "value in binary: 0b1\n",
      "value_bits: 01\n",
      "value in dec: 0.0661\n",
      "value in signed fixed: 2\n",
      "value in binary: 0b10\n",
      "value_bits: 02\n",
      "value in dec: 0.1657\n",
      "value in signed fixed: 5\n",
      "value in binary: 0b101\n",
      "value_bits: 05\n",
      "value in dec: 0.1066\n",
      "value in signed fixed: 3\n",
      "value in binary: 0b11\n",
      "value_bits: 03\n",
      "value in dec: -0.006\n",
      "value in signed fixed: 0\n",
      "value in binary: 0b0\n",
      "value_bits: 00\n",
      "value in dec: -0.0739\n",
      "value in signed fixed: 254\n",
      "value in binary: 0b11111110\n",
      "value_bits: fe\n",
      "value in dec: -0.1043\n",
      "value in signed fixed: 253\n",
      "value in binary: 0b11111101\n",
      "value_bits: fd\n",
      "value in dec: 0.0153\n",
      "value in signed fixed: 0\n",
      "value in binary: 0b0\n",
      "value_bits: 00\n",
      "value in dec: -0.1449\n",
      "value in signed fixed: 251\n",
      "value in binary: 0b11111011\n",
      "value_bits: fb\n",
      "value in dec: 0.0332\n",
      "value in signed fixed: 1\n",
      "value in binary: 0b1\n",
      "value_bits: 01\n",
      "value in dec: 0.1471\n",
      "value in signed fixed: 5\n",
      "value in binary: 0b101\n",
      "value_bits: 05\n",
      "value in dec: 0.145\n",
      "value in signed fixed: 5\n",
      "value in binary: 0b101\n",
      "value_bits: 05\n",
      "value in dec: 0.1381\n",
      "value in signed fixed: 4\n",
      "value in binary: 0b100\n",
      "value_bits: 04\n",
      "value in dec: 0.0655\n",
      "value in signed fixed: 2\n",
      "value in binary: 0b10\n",
      "value_bits: 02\n",
      "value in dec: -0.0611\n",
      "value in signed fixed: 254\n",
      "value in binary: 0b11111110\n",
      "value_bits: fe\n",
      "value in dec: -0.1284\n",
      "value in signed fixed: 252\n",
      "value in binary: 0b11111100\n",
      "value_bits: fc\n",
      "value in dec: 0.16\n",
      "value in signed fixed: 5\n",
      "value in binary: 0b101\n",
      "value_bits: 05\n",
      "value in dec: 0.1034\n",
      "value in signed fixed: 3\n",
      "value in binary: 0b11\n",
      "value_bits: 03\n",
      "value in dec: 0.0386\n",
      "value in signed fixed: 1\n",
      "value in binary: 0b1\n",
      "value_bits: 01\n",
      "value in dec: 0.0064\n",
      "value in signed fixed: 0\n",
      "value in binary: 0b0\n",
      "value_bits: 00\n",
      "value in dec: -0.021\n",
      "value in signed fixed: 255\n",
      "value in binary: 0b11111111\n",
      "value_bits: ff\n",
      "value in dec: 0.0915\n",
      "value in signed fixed: 3\n",
      "value in binary: 0b11\n",
      "value_bits: 03\n",
      "value in dec: -0.1081\n",
      "value in signed fixed: 253\n",
      "value in binary: 0b11111101\n",
      "value_bits: fd\n",
      "value in dec: -0.165\n",
      "value in signed fixed: 251\n",
      "value in binary: 0b11111011\n",
      "value_bits: fb\n",
      "value in dec: 0.0623\n",
      "value in signed fixed: 2\n",
      "value in binary: 0b10\n",
      "value_bits: 02\n",
      "value in dec: 0.1193\n",
      "value in signed fixed: 4\n",
      "value in binary: 0b100\n",
      "value_bits: 04\n",
      "value in dec: 0.0843\n",
      "value in signed fixed: 3\n",
      "value in binary: 0b11\n",
      "value_bits: 03\n",
      "value in dec: 0.0611\n",
      "value in signed fixed: 2\n",
      "value in binary: 0b10\n",
      "value_bits: 02\n",
      "value in dec: -0.0987\n",
      "value in signed fixed: 253\n",
      "value in binary: 0b11111101\n",
      "value_bits: fd\n",
      "value in dec: 0.0641\n",
      "value in signed fixed: 2\n",
      "value in binary: 0b10\n",
      "value_bits: 02\n",
      "value in dec: -0.0763\n",
      "value in signed fixed: 254\n",
      "value in binary: 0b11111110\n",
      "value_bits: fe\n",
      "value in dec: -0.0274\n",
      "value in signed fixed: 255\n",
      "value in binary: 0b11111111\n",
      "value_bits: ff\n",
      "value in dec: -0.0281\n",
      "value in signed fixed: 255\n",
      "value in binary: 0b11111111\n",
      "value_bits: ff\n",
      "value in dec: 0.0312\n",
      "value in signed fixed: 1\n",
      "value in binary: 0b1\n",
      "value_bits: 01\n",
      "value in dec: -0.1663\n",
      "value in signed fixed: 251\n",
      "value in binary: 0b11111011\n",
      "value_bits: fb\n",
      "value in dec: 0.1267\n",
      "value in signed fixed: 4\n",
      "value in binary: 0b100\n",
      "value_bits: 04\n",
      "value in dec: 0.1481\n",
      "value in signed fixed: 5\n",
      "value in binary: 0b101\n",
      "value_bits: 05\n",
      "value in dec: -0.1553\n",
      "value in signed fixed: 251\n",
      "value in binary: 0b11111011\n",
      "value_bits: fb\n",
      "value in dec: 0.0989\n",
      "value in signed fixed: 3\n",
      "value in binary: 0b11\n",
      "value_bits: 03\n",
      "value in dec: -0.0683\n",
      "value in signed fixed: 254\n",
      "value in binary: 0b11111110\n",
      "value_bits: fe\n",
      "value in dec: 0.025\n",
      "value in signed fixed: 1\n",
      "value in binary: 0b1\n",
      "value_bits: 01\n",
      "value in dec: -0.0092\n",
      "value in signed fixed: 0\n",
      "value in binary: 0b0\n",
      "value_bits: 00\n",
      "value in dec: -0.1286\n",
      "value in signed fixed: 252\n",
      "value in binary: 0b11111100\n",
      "value_bits: fc\n",
      "value in dec: -0.1255\n",
      "value in signed fixed: 252\n",
      "value in binary: 0b11111100\n",
      "value_bits: fc\n",
      "value in dec: -0.003\n",
      "value in signed fixed: 0\n",
      "value in binary: 0b0\n",
      "value_bits: 00\n",
      "value in dec: -0.1588\n",
      "value in signed fixed: 251\n",
      "value in binary: 0b11111011\n",
      "value_bits: fb\n",
      "value in dec: -0.0419\n",
      "value in signed fixed: 255\n",
      "value in binary: 0b11111111\n",
      "value_bits: ff\n",
      "value in dec: -0.0727\n",
      "value in signed fixed: 254\n",
      "value in binary: 0b11111110\n",
      "value_bits: fe\n",
      "value in dec: 0.1123\n",
      "value in signed fixed: 4\n",
      "value in binary: 0b100\n",
      "value_bits: 04\n",
      "value in dec: 0.1568\n",
      "value in signed fixed: 5\n",
      "value in binary: 0b101\n",
      "value_bits: 05\n",
      "value in dec: -0.096\n",
      "value in signed fixed: 253\n",
      "value in binary: 0b11111101\n",
      "value_bits: fd\n",
      "value in dec: -0.13\n",
      "value in signed fixed: 252\n",
      "value in binary: 0b11111100\n",
      "value_bits: fc\n",
      "value in dec: 0.0349\n",
      "value in signed fixed: 1\n",
      "value in binary: 0b1\n",
      "value_bits: 01\n",
      "value in dec: 0.0832\n",
      "value in signed fixed: 3\n",
      "value in binary: 0b11\n",
      "value_bits: 03\n",
      "value in dec: -0.0812\n",
      "value in signed fixed: 253\n",
      "value in binary: 0b11111101\n",
      "value_bits: fd\n",
      "value in dec: -0.0417\n",
      "value in signed fixed: 255\n",
      "value in binary: 0b11111111\n",
      "value_bits: ff\n",
      "value in dec: -0.0988\n",
      "value in signed fixed: 253\n",
      "value in binary: 0b11111101\n",
      "value_bits: fd\n",
      "value in dec: -0.1599\n",
      "value in signed fixed: 251\n",
      "value in binary: 0b11111011\n",
      "value_bits: fb\n",
      "value in dec: 0.0789\n",
      "value in signed fixed: 3\n",
      "value in binary: 0b11\n",
      "value_bits: 03\n",
      "value in dec: -0.0813\n",
      "value in signed fixed: 253\n",
      "value in binary: 0b11111101\n",
      "value_bits: fd\n",
      "value in dec: 0.01\n",
      "value in signed fixed: 0\n",
      "value in binary: 0b0\n",
      "value_bits: 00\n",
      "value in dec: 0.0654\n",
      "value in signed fixed: 2\n",
      "value in binary: 0b10\n",
      "value_bits: 02\n",
      "value in dec: 0.0395\n",
      "value in signed fixed: 1\n",
      "value in binary: 0b1\n",
      "value_bits: 01\n",
      "value in dec: 0.0243\n",
      "value in signed fixed: 1\n",
      "value in binary: 0b1\n",
      "value_bits: 01\n",
      "value in dec: 0.0075\n",
      "value in signed fixed: 0\n",
      "value in binary: 0b0\n",
      "value_bits: 00\n",
      "value in dec: -0.0415\n",
      "value in signed fixed: 255\n",
      "value in binary: 0b11111111\n",
      "value_bits: ff\n",
      "value in dec: -0.1405\n",
      "value in signed fixed: 252\n",
      "value in binary: 0b11111100\n",
      "value_bits: fc\n",
      "value in dec: 0.1142\n",
      "value in signed fixed: 4\n",
      "value in binary: 0b100\n",
      "value_bits: 04\n",
      "value in dec: 0.1512\n",
      "value in signed fixed: 5\n",
      "value in binary: 0b101\n",
      "value_bits: 05\n",
      "value in dec: -0.1014\n",
      "value in signed fixed: 253\n",
      "value in binary: 0b11111101\n",
      "value_bits: fd\n",
      "value in dec: -0.0121\n",
      "value in signed fixed: 0\n",
      "value in binary: 0b0\n",
      "value_bits: 00\n",
      "value in dec: 0.1582\n",
      "value in signed fixed: 5\n",
      "value in binary: 0b101\n",
      "value_bits: 05\n",
      "value in dec: 0.1058\n",
      "value in signed fixed: 3\n",
      "value in binary: 0b11\n",
      "value_bits: 03\n",
      "value in dec: 0.1579\n",
      "value in signed fixed: 5\n",
      "value in binary: 0b101\n",
      "value_bits: 05\n",
      "value in dec: 0.106\n",
      "value in signed fixed: 3\n",
      "value in binary: 0b11\n",
      "value_bits: 03\n",
      "value in dec: 0.0337\n",
      "value in signed fixed: 1\n",
      "value in binary: 0b1\n",
      "value_bits: 01\n",
      "value in dec: -0.0144\n",
      "value in signed fixed: 0\n",
      "value in binary: 0b0\n",
      "value_bits: 00\n",
      "value in dec: 0.0046\n",
      "value in signed fixed: 0\n",
      "value in binary: 0b0\n",
      "value_bits: 00\n",
      "value in dec: -0.0171\n",
      "value in signed fixed: 255\n",
      "value in binary: 0b11111111\n",
      "value_bits: ff\n",
      "value in dec: 0.1193\n",
      "value in signed fixed: 4\n",
      "value in binary: 0b100\n",
      "value_bits: 04\n",
      "value in dec: -0.0086\n",
      "value in signed fixed: 0\n",
      "value in binary: 0b0\n",
      "value_bits: 00\n",
      "value in dec: -0.1086\n",
      "value in signed fixed: 253\n",
      "value in binary: 0b11111101\n",
      "value_bits: fd\n",
      "value in dec: 0.0356\n",
      "value in signed fixed: 1\n",
      "value in binary: 0b1\n",
      "value_bits: 01\n",
      "value in dec: -0.0355\n",
      "value in signed fixed: 255\n",
      "value in binary: 0b11111111\n",
      "value_bits: ff\n",
      "value in dec: -0.1366\n",
      "value in signed fixed: 252\n",
      "value in binary: 0b11111100\n",
      "value_bits: fc\n",
      "value in dec: -0.0583\n",
      "value in signed fixed: 254\n",
      "value in binary: 0b11111110\n",
      "value_bits: fe\n",
      "data_buff:  0003fcfcfe0100040001fefffbfcfe00\n",
      "0203fcfe0204ff04ff0105fbfdfffe05\n",
      "fdfefcfbfd05020300fd01fbfcfd0303\n",
      "fe000305020104fd01fcfcfd0202fd02\n",
      "03ff00010305fcfe0204050501fb00fd\n",
      "fb0504fb01fffffe02fd02030402fbfd\n",
      "0301fcfd0504fefffb00fcfc0001fe03\n",
      "fd0504fcff0001010200fd03fbfdfffd\n",
      "fefcff01fd0004ff0000010305030500\n",
      "\n",
      "param_name in emit_bram_handshake: bias\n",
      "out_size: 2\n",
      "out_size in emit_parameters_in_mem_internal: 2\n",
      "conv1\n",
      "verilog_param_name bias\n",
      "total_size: 4\n",
      "shape: [1, 4]\n",
      " node.meta[mase].parameters[hardware][verilog_param] {'DATA_IN_0_PRECISION_0': 8, 'DATA_IN_0_PRECISION_1': 5, 'DATA_IN_0_TENSOR_SIZE_DIM_0': 4, 'DATA_IN_0_PARALLELISM_DIM_0': 2, 'DATA_IN_0_TENSOR_SIZE_DIM_1': 4, 'DATA_IN_0_PARALLELISM_DIM_1': 2, 'DATA_IN_0_TENSOR_SIZE_DIM_2': 4, 'DATA_IN_0_PARALLELISM_DIM_2': 2, 'DATA_IN_0_TENSOR_SIZE_DIM_3': 2, 'DATA_IN_0_PARALLELISM_DIM_3': 2, 'WEIGHT_PRECISION_0': 8, 'WEIGHT_PRECISION_1': 5, 'WEIGHT_TENSOR_SIZE_DIM_0': 3, 'WEIGHT_PARALLELISM_DIM_0': 2, 'WEIGHT_TENSOR_SIZE_DIM_1': 3, 'WEIGHT_PARALLELISM_DIM_1': 2, 'WEIGHT_TENSOR_SIZE_DIM_2': 4, 'WEIGHT_PARALLELISM_DIM_2': 2, 'WEIGHT_TENSOR_SIZE_DIM_3': 4, 'WEIGHT_PARALLELISM_DIM_3': 2, 'BIAS_PRECISION_0': 8, 'BIAS_PRECISION_1': 5, 'BIAS_TENSOR_SIZE_DIM_0': 4, 'BIAS_PARALLELISM_DIM_0': 2, 'BIAS_TENSOR_SIZE_DIM_1': 1, 'BIAS_PARALLELISM_DIM_1': 1, 'STRIDE_TENSOR_SIZE_DIM_0_VALUE': 1, 'STRIDE_TENSOR_SIZE_DIM_1_VALUE': 1, 'PADDING_TENSOR_SIZE_DIM_0_VALUE': 1, 'PADDING_TENSOR_SIZE_DIM_1_VALUE': 1, 'DATA_OUT_0_PRECISION_0': 8, 'DATA_OUT_0_PRECISION_1': 5, 'DATA_OUT_0_TENSOR_SIZE_DIM_0': 4, 'DATA_OUT_0_PARALLELISM_DIM_0': 2, 'DATA_OUT_0_TENSOR_SIZE_DIM_1': 4, 'DATA_OUT_0_PARALLELISM_DIM_1': 2, 'DATA_OUT_0_TENSOR_SIZE_DIM_2': 4, 'DATA_OUT_0_PARALLELISM_DIM_2': 2, 'DATA_OUT_0_TENSOR_SIZE_DIM_3': 2, 'DATA_OUT_0_PARALLELISM_DIM_3': 2}\n",
      "out_size: 2\n",
      "param_data in emit_parameters_in_dat_internal:  tensor([ 0.0089, -0.1029,  0.0085,  0.0799])\n",
      "param_data in emit_parameters_in_dat_internal after flatten:  [0.008923396468162537, -0.10290666669607162, 0.008542373776435852, 0.07991452515125275]\n",
      "out_depth:  2\n",
      "value in dec: -0.1029\n",
      "value in signed fixed: 253\n",
      "value in binary: 0b11111101\n",
      "value_bits: fd\n",
      "value in dec: 0.0089\n",
      "value in signed fixed: 0\n",
      "value in binary: 0b0\n",
      "value_bits: 00\n",
      "value in dec: 0.0799\n",
      "value in signed fixed: 3\n",
      "value in binary: 0b11\n",
      "value_bits: 03\n",
      "value in dec: 0.0085\n",
      "value in signed fixed: 0\n",
      "value in binary: 0b0\n",
      "value_bits: 00\n",
      "data_buff:  00fd\n",
      "0003\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n  param_data:  tensor([[[[-0.1946,  0.2865,  0.1487],\\n          [ 0.1616,  0.0175, -0.1709],\\n          [ 0.0564, -0.3112, -0.2409]]],\\n\\n\\n        [[[-0.1718,  0.2103,  0.1954],\\n          [-0.1478, -0.0120,  0.2132],\\n          [ 0.3314,  0.1323,  0.0450]]]])\\n  This would be weight, as I defined conv as (2,1,3,3)\\n  The kernel filter size is 3x3, and we have 2 filters, thus 9x2=18 elements\\n  Bias: depends on number of filter-> here 2 filters, thus 2 bias elements,\\n    as bias added after filter multiplies with section of pixel\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mg, _ = emit_bram_transform_pass(mg)\n",
    "\n",
    "\"\"\"\n",
    "  param_data:  tensor([[[[-0.1946,  0.2865,  0.1487],\n",
    "          [ 0.1616,  0.0175, -0.1709],\n",
    "          [ 0.0564, -0.3112, -0.2409]]],\n",
    "\n",
    "\n",
    "        [[[-0.1718,  0.2103,  0.1954],\n",
    "          [-0.1478, -0.0120,  0.2132],\n",
    "          [ 0.3314,  0.1323,  0.0450]]]])\n",
    "  This would be weight, as I defined conv as (2,1,3,3)\n",
    "  The kernel filter size is 3x3, and we have 2 filters, thus 9x2=18 elements\n",
    "  Bias: depends on number of filter-> here 2 filters, thus 2 bias elements,\n",
    "    as bias added after filter multiplies with section of pixel\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mEmitting testbench...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "mg, _ = emit_cocotb_transform_pass(mg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Running command perl /usr/local/bin/verilator -cc --exe -Mdir /workspace/docs/labs/sim_build -DCOCOTB_SIM=1 --top-module top --vpi --public-flat-rw --prefix Vtop -o top -LDFLAGS '-Wl,-rpath,/usr/local/lib/python3.11/dist-packages/cocotb/libs -L/usr/local/lib/python3.11/dist-packages/cocotb/libs -lcocotbvpi_verilator' -Wno-fatal -Wno-lint -Wno-style --trace-fst --trace-structs --trace-depth 3 -I/root/.mase/top/hardware/rtl -I/workspace/src/mase_components/interface/rtl -I/workspace/src/mase_components/language_models/rtl -I/workspace/src/mase_components/memory/rtl -I/workspace/src/mase_components/vivado/rtl -I/workspace/src/mase_components/convolution_layers/rtl -I/workspace/src/mase_components/cast/rtl -I/workspace/src/mase_components/systolic_arrays/rtl -I/workspace/src/mase_components/scalar_operators/rtl -I/workspace/src/mase_components/transformer_layers/rtl -I/workspace/src/mase_components/common/rtl -I/workspace/src/mase_components/hls/rtl -I/workspace/src/mase_components/vision_models/rtl -I/workspace/src/mase_components/linear_layers/rtl -I/workspace/src/mase_components/activation_layers/rtl -I/workspace/src/mase_components/normalization_layers/rtl -I/workspace/src/mase_components/helper/rtl /usr/local/lib/python3.11/dist-packages/cocotb/share/lib/verilator/verilator.cpp /root/.mase/top/hardware/rtl/register_slice.sv /root/.mase/top/hardware/rtl/fixed_adder_tree_layer.sv /root/.mase/top/hardware/rtl/unpacked_repeat_circular_buffer.sv /root/.mase/top/hardware/rtl/matmul.sv /root/.mase/top/hardware/rtl/join2.sv /root/.mase/top/hardware/rtl/sliding_window.sv /root/.mase/top/hardware/rtl/convolution.sv /root/.mase/top/hardware/rtl/matrix_unflatten.sv /root/.mase/top/hardware/rtl/fixed_signed_cast.sv /root/.mase/top/hardware/rtl/blk_mem_gen_0.sv /root/.mase/top/hardware/rtl/fixed_relu.sv /root/.mase/top/hardware/rtl/fixed_adder_tree.sv /root/.mase/top/hardware/rtl/matrix_fifo.sv /root/.mase/top/hardware/rtl/conv1_bias_source.sv /root/.mase/top/hardware/rtl/fc1_bias_source.sv /root/.mase/top/hardware/rtl/fixed_linear.sv /root/.mase/top/hardware/rtl/top.sv /root/.mase/top/hardware/rtl/fc1_weight_source.sv /root/.mase/top/hardware/rtl/fc1_1_bias_source.sv /root/.mase/top/hardware/rtl/conv1_weight_source.sv /root/.mase/top/hardware/rtl/transpose.sv /root/.mase/top/hardware/rtl/fixed_rounding.sv /root/.mase/top/hardware/rtl/input_buffer.sv /root/.mase/top/hardware/rtl/floor_round.sv /root/.mase/top/hardware/rtl/convolution_mase.sv /root/.mase/top/hardware/rtl/fc1_1_weight_source.sv /root/.mase/top/hardware/rtl/convolution_arith.sv /root/.mase/top/hardware/rtl/matrix_accumulator.sv /root/.mase/top/hardware/rtl/simple_matmul.sv /root/.mase/top/hardware/rtl/skid_buffer.sv /root/.mase/top/hardware/rtl/matrix_stream_transpose.sv /root/.mase/top/hardware/rtl/unpacked_skid_buffer.sv /root/.mase/top/hardware/rtl/fixed_leakyrelu.sv /root/.mase/top/hardware/rtl/fixed_accumulator.sv /root/.mase/top/hardware/rtl/fixed_vector_mult.sv /root/.mase/top/hardware/rtl/matrix_flatten.sv /root/.mase/top/hardware/rtl/fixed_dot_product.sv /root/.mase/top/hardware/rtl/padding.sv /root/.mase/top/hardware/rtl/fixed_cast.sv /root/.mase/top/hardware/rtl/roller.sv /root/.mase/top/hardware/rtl/fixed_mult.sv /root/.mase/top/hardware/rtl/signed_clamp.sv in directory /workspace/docs/labs/sim_build\n",
      "INFO: Running command make -C /workspace/docs/labs/sim_build -f Vtop.mk in directory /workspace/docs/labs/sim_build\n",
      "make: Entering directory '/workspace/docs/labs/sim_build'\n",
      "ccache g++  -I.  -MMD -I/usr/local/share/verilator/include -I/usr/local/share/verilator/include/vltstd -DVM_COVERAGE=0 -DVM_SC=0 -DVM_TRACE=1 -DVM_TRACE_FST=1 -DVM_TRACE_VCD=0 -faligned-new -fcf-protection=none -Wno-bool-operation -Wno-overloaded-virtual -Wno-shadow -Wno-sign-compare -Wno-uninitialized -Wno-unused-but-set-parameter -Wno-unused-but-set-variable -Wno-unused-parameter -Wno-unused-variable       -Os -c -o verilator.o /usr/local/lib/python3.11/dist-packages/cocotb/share/lib/verilator/verilator.cpp\n",
      "ccache g++ -Os  -I.  -MMD -I/usr/local/share/verilator/include -I/usr/local/share/verilator/include/vltstd -DVM_COVERAGE=0 -DVM_SC=0 -DVM_TRACE=1 -DVM_TRACE_FST=1 -DVM_TRACE_VCD=0 -faligned-new -fcf-protection=none -Wno-bool-operation -Wno-overloaded-virtual -Wno-shadow -Wno-sign-compare -Wno-uninitialized -Wno-unused-but-set-parameter -Wno-unused-but-set-variable -Wno-unused-parameter -Wno-unused-variable       -c -o verilated.o /usr/local/share/verilator/include/verilated.cpp\n",
      "ccache g++ -Os  -I.  -MMD -I/usr/local/share/verilator/include -I/usr/local/share/verilator/include/vltstd -DVM_COVERAGE=0 -DVM_SC=0 -DVM_TRACE=1 -DVM_TRACE_FST=1 -DVM_TRACE_VCD=0 -faligned-new -fcf-protection=none -Wno-bool-operation -Wno-overloaded-virtual -Wno-shadow -Wno-sign-compare -Wno-uninitialized -Wno-unused-but-set-parameter -Wno-unused-but-set-variable -Wno-unused-parameter -Wno-unused-variable       -c -o verilated_dpi.o /usr/local/share/verilator/include/verilated_dpi.cpp\n",
      "ccache g++ -Os  -I.  -MMD -I/usr/local/share/verilator/include -I/usr/local/share/verilator/include/vltstd -DVM_COVERAGE=0 -DVM_SC=0 -DVM_TRACE=1 -DVM_TRACE_FST=1 -DVM_TRACE_VCD=0 -faligned-new -fcf-protection=none -Wno-bool-operation -Wno-overloaded-virtual -Wno-shadow -Wno-sign-compare -Wno-uninitialized -Wno-unused-but-set-parameter -Wno-unused-but-set-variable -Wno-unused-parameter -Wno-unused-variable       -c -o verilated_vpi.o /usr/local/share/verilator/include/verilated_vpi.cpp\n",
      "ccache g++ -Os  -I.  -MMD -I/usr/local/share/verilator/include -I/usr/local/share/verilator/include/vltstd -DVM_COVERAGE=0 -DVM_SC=0 -DVM_TRACE=1 -DVM_TRACE_FST=1 -DVM_TRACE_VCD=0 -faligned-new -fcf-protection=none -Wno-bool-operation -Wno-overloaded-virtual -Wno-shadow -Wno-sign-compare -Wno-uninitialized -Wno-unused-but-set-parameter -Wno-unused-but-set-variable -Wno-unused-parameter -Wno-unused-variable       -c -o verilated_fst_c.o /usr/local/share/verilator/include/verilated_fst_c.cpp\n",
      "ccache g++ -Os  -I.  -MMD -I/usr/local/share/verilator/include -I/usr/local/share/verilator/include/vltstd -DVM_COVERAGE=0 -DVM_SC=0 -DVM_TRACE=1 -DVM_TRACE_FST=1 -DVM_TRACE_VCD=0 -faligned-new -fcf-protection=none -Wno-bool-operation -Wno-overloaded-virtual -Wno-shadow -Wno-sign-compare -Wno-uninitialized -Wno-unused-but-set-parameter -Wno-unused-but-set-variable -Wno-unused-parameter -Wno-unused-variable       -c -o verilated_threads.o /usr/local/share/verilator/include/verilated_threads.cpp\n",
      "/usr/bin/python3 /usr/local/share/verilator/bin/verilator_includer -DVL_INCLUDE_OPT=include Vtop.cpp Vtop___024root__DepSet_h84412442__0.cpp Vtop___024root__DepSet_heccd7ead__0.cpp Vtop__Dpi.cpp Vtop__Trace__0.cpp Vtop__ConstPool_0.cpp Vtop___024root__Slow.cpp Vtop___024root__DepSet_h84412442__0__Slow.cpp Vtop___024root__DepSet_heccd7ead__0__Slow.cpp Vtop__Syms.cpp Vtop__Trace__0__Slow.cpp Vtop__TraceDecls__0__Slow.cpp > Vtop__ALL.cpp\n",
      "ccache g++ -Os  -I.  -MMD -I/usr/local/share/verilator/include -I/usr/local/share/verilator/include/vltstd -DVM_COVERAGE=0 -DVM_SC=0 -DVM_TRACE=1 -DVM_TRACE_FST=1 -DVM_TRACE_VCD=0 -faligned-new -fcf-protection=none -Wno-bool-operation -Wno-overloaded-virtual -Wno-shadow -Wno-sign-compare -Wno-uninitialized -Wno-unused-but-set-parameter -Wno-unused-but-set-variable -Wno-unused-parameter -Wno-unused-variable       -c -o Vtop__ALL.o Vtop__ALL.cpp\n",
      "Archive ar -rcs Vtop__ALL.a Vtop__ALL.o\n",
      "g++     verilator.o verilated.o verilated_dpi.o verilated_vpi.o verilated_fst_c.o verilated_threads.o Vtop__ALL.a   -Wl,-rpath,/usr/local/lib/python3.11/dist-packages/cocotb/libs -L/usr/local/lib/python3.11/dist-packages/cocotb/libs -lcocotbvpi_verilator -lz  -pthread -lpthread -latomic   -o top\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mBuild finished. Time taken: 2.62s\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make: Leaving directory '/workspace/docs/labs/sim_build'\n",
      "sys in simulate.py:  <module 'sys' (built-in)>\n",
      "cmd: [['/workspace/docs/labs/sim_build/top']]\n",
      "INFO: Running command /workspace/docs/labs/sim_build/top in directory /workspace/docs/labs/sim_build\n",
      "     -.--ns INFO     gpi                                ..mbed/gpi_embed.cpp:76   in set_program_name_in_venv        Did not detect Python virtual environment. Using system-wide Python interpreter\n",
      "     -.--ns INFO     gpi                                ../gpi/GpiCommon.cpp:101  in gpi_print_registered_impl       VPI registered\n",
      "     0.00ns INFO     cocotb                             Running on Verilator version 5.020 2024-01-01\n",
      "     0.00ns INFO     cocotb                             Running tests with cocotb v1.8.0 from /usr/local/lib/python3.11/dist-packages/cocotb\n",
      "     0.00ns INFO     cocotb                             Seeding Python random module with 1741614936\n",
      "     0.00ns INFO     cocotb.regression                  Found test mase_top_tb.test.test\n",
      "     0.00ns INFO     cocotb.regression                  running test (1/1)\n",
      "arg in _emit_cocotb: data_in_0\n",
      "getattr(dut, arg) top.data_in_0\n",
      "getattr(dut, arg).value [00000000, 00000000, 00000000, 00000000, 00000000, 00000000, 00000000, 00000000, 00000000, 00000000, 00000000, 00000000, 00000000, 00000000, 00000000, 00000000]\n",
      "arg in _emit_cocotb: weight\n",
      "arg in _emit_cocotb: bias\n",
      "arg in _emit_cocotb: stride\n",
      "arg in _emit_cocotb: padding\n",
      "nihap in generate_inputs\n",
      "          0\n",
      "          2\n",
      "         14\n",
      "         16\n",
      "load_drivers in emit_tb.py\n",
      "tensor_dim: 4\n",
      "parallelism_list: [2, 2, 2, 2]\n",
      "parallelism in fixed_process_tensor: [2, 2, 2, 2]\n",
      "tensor before tensor: tensor([[[[0.4963, 0.7682, 0.0885, 0.1320],\n",
      "          [0.3074, 0.6341, 0.4901, 0.8964],\n",
      "          [0.4556, 0.6323, 0.3489, 0.4017],\n",
      "          [0.0223, 0.1689, 0.2939, 0.5185]],\n",
      "\n",
      "         [[0.6977, 0.8000, 0.1610, 0.2823],\n",
      "          [0.6816, 0.9152, 0.3971, 0.8742],\n",
      "          [0.4194, 0.5529, 0.9527, 0.0362],\n",
      "          [0.1852, 0.3734, 0.3051, 0.9320]],\n",
      "\n",
      "         [[0.1759, 0.2698, 0.1507, 0.0317],\n",
      "          [0.2081, 0.9298, 0.7231, 0.7423],\n",
      "          [0.5263, 0.2437, 0.5846, 0.0332],\n",
      "          [0.1387, 0.2422, 0.8155, 0.7932]],\n",
      "\n",
      "         [[0.2783, 0.4820, 0.8198, 0.9971],\n",
      "          [0.6984, 0.5675, 0.8352, 0.2056],\n",
      "          [0.5932, 0.1123, 0.1535, 0.2417],\n",
      "          [0.7262, 0.7011, 0.2038, 0.6511]]]])\n",
      "nihhhhhjhj\n",
      "tensor after tensor: tensor([[[[0.4963, 0.7682, 0.0885, 0.1320],\n",
      "          [0.3074, 0.6341, 0.4901, 0.8964],\n",
      "          [0.4556, 0.6323, 0.3489, 0.4017],\n",
      "          [0.0223, 0.1689, 0.2939, 0.5185]],\n",
      "\n",
      "         [[0.6977, 0.8000, 0.1610, 0.2823],\n",
      "          [0.6816, 0.9152, 0.3971, 0.8742],\n",
      "          [0.4194, 0.5529, 0.9527, 0.0362],\n",
      "          [0.1852, 0.3734, 0.3051, 0.9320]],\n",
      "\n",
      "         [[0.1759, 0.2698, 0.1507, 0.0317],\n",
      "          [0.2081, 0.9298, 0.7231, 0.7423],\n",
      "          [0.5263, 0.2437, 0.5846, 0.0332],\n",
      "          [0.1387, 0.2422, 0.8155, 0.7932]],\n",
      "\n",
      "         [[0.2783, 0.4820, 0.8198, 0.9971],\n",
      "          [0.6984, 0.5675, 0.8352, 0.2056],\n",
      "          [0.5932, 0.1123, 0.1535, 0.2417],\n",
      "          [0.7262, 0.7011, 0.2038, 0.6511]]]])\n",
      "q_tensor in fixed_preprocess_tensor: tensor([[[[15, 24,  2,  4],\n",
      "          [ 9, 20, 15, 28],\n",
      "          [14, 20, 11, 12],\n",
      "          [ 0,  5,  9, 16]],\n",
      "\n",
      "         [[22, 25,  5,  9],\n",
      "          [21, 29, 12, 27],\n",
      "          [13, 17, 30,  1],\n",
      "          [ 5, 11,  9, 29]],\n",
      "\n",
      "         [[ 5,  8,  4,  1],\n",
      "          [ 6, 29, 23, 23],\n",
      "          [16,  7, 18,  1],\n",
      "          [ 4,  7, 26, 25]],\n",
      "\n",
      "         [[ 8, 15, 26, 31],\n",
      "          [22, 18, 26,  6],\n",
      "          [18,  3,  4,  7],\n",
      "          [23, 22,  6, 20]]]], dtype=torch.int32)\n",
      "Final splitted result: [tensor([[[[15, 24],\n",
      "          [ 9, 20]],\n",
      "\n",
      "         [[22, 25],\n",
      "          [21, 29]]]], dtype=torch.int32), tensor([[[[ 2,  4],\n",
      "          [15, 28]],\n",
      "\n",
      "         [[ 5,  9],\n",
      "          [12, 27]]]], dtype=torch.int32), tensor([[[[14, 20],\n",
      "          [ 0,  5]],\n",
      "\n",
      "         [[13, 17],\n",
      "          [ 5, 11]]]], dtype=torch.int32), tensor([[[[11, 12],\n",
      "          [ 9, 16]],\n",
      "\n",
      "         [[30,  1],\n",
      "          [ 9, 29]]]], dtype=torch.int32), tensor([[[[ 5,  8],\n",
      "          [ 6, 29]],\n",
      "\n",
      "         [[ 8, 15],\n",
      "          [22, 18]]]], dtype=torch.int32), tensor([[[[ 4,  1],\n",
      "          [23, 23]],\n",
      "\n",
      "         [[26, 31],\n",
      "          [26,  6]]]], dtype=torch.int32), tensor([[[[16,  7],\n",
      "          [ 4,  7]],\n",
      "\n",
      "         [[18,  3],\n",
      "          [23, 22]]]], dtype=torch.int32), tensor([[[[18,  1],\n",
      "          [26, 25]],\n",
      "\n",
      "         [[ 4,  7],\n",
      "          [ 6, 20]]]], dtype=torch.int32)]\n",
      "blocks = [[15, 24, 9, 20, 22, 25, 21, 29], [2, 4, 15, 28, 5, 9, 12, 27], [14, 20, 0, 5, 13, 17, 5, 11], [11, 12, 9, 16, 30, 1, 9, 29], [5, 8, 6, 29, 8, 15, 22, 18], [4, 1, 23, 23, 26, 31, 26, 6], [16, 7, 4, 7, 18, 3, 23, 22], [18, 1, 26, 25, 4, 7, 6, 20]]\n",
      "block_size: 16\n",
      "in_data_blocks: [[15, 24, 9, 20, 22, 25, 21, 29], [2, 4, 15, 28, 5, 9, 12, 27], [14, 20, 0, 5, 13, 17, 5, 11], [11, 12, 9, 16, 30, 1, 9, 29], [5, 8, 6, 29, 8, 15, 22, 18], [4, 1, 23, 23, 26, 31, 26, 6], [16, 7, 4, 7, 18, 3, 23, 22], [18, 1, 26, 25, 4, 7, 6, 20]]\n",
      "block sending in: [15, 24, 9, 20, 22, 25, 21, 29, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "block sending in: [2, 4, 15, 28, 5, 9, 12, 27, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "block sending in: [14, 20, 0, 5, 13, 17, 5, 11, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "block sending in: [11, 12, 9, 16, 30, 1, 9, 29, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "block sending in: [5, 8, 6, 29, 8, 15, 22, 18, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "block sending in: [4, 1, 23, 23, 26, 31, 26, 6, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "block sending in: [16, 7, 4, 7, 18, 3, 23, 22, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "block sending in: [18, 1, 26, 25, 4, 7, 6, 20, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "expectations: tensor([[[[ 0.0322, -0.2510, -0.1201,  0.1338],\n",
      "          [-0.0332, -0.1641, -0.2334, -0.4932],\n",
      "          [-0.2607, -0.4199, -0.5547, -0.3340],\n",
      "          [-0.1230, -0.1396, -0.3125, -0.1270]],\n",
      "\n",
      "         [[-0.3389, -0.0508,  0.0293,  0.1016],\n",
      "          [-0.0186, -0.0234, -0.2188,  0.0625],\n",
      "          [-0.0156, -0.0010,  0.1406,  0.1260],\n",
      "          [ 0.1875,  0.1025, -0.1523, -0.2148]],\n",
      "\n",
      "         [[-0.7266, -0.5039, -0.5215, -0.0547],\n",
      "          [-0.3438, -0.1299,  0.0791,  0.0645],\n",
      "          [-0.1152,  0.2598,  0.1660,  0.5049],\n",
      "          [ 0.0947,  0.0049,  0.0508,  0.2227]],\n",
      "\n",
      "         [[ 0.1689,  0.3145,  0.5273,  0.0957],\n",
      "          [ 0.1602,  0.2490,  0.1475,  0.0674],\n",
      "          [ 0.1729,  0.1074,  0.1016, -0.0654],\n",
      "          [ 0.1992,  0.1807,  0.1592,  0.0195]]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n",
      "shape of expectations: 4\n",
      "parallelism in fixed_process_tensor: [2, 2, 2, 2]\n",
      "tensor before tensor: tensor([[[[ 0.0322, -0.2510, -0.1201,  0.1338],\n",
      "          [-0.0332, -0.1641, -0.2334, -0.4932],\n",
      "          [-0.2607, -0.4199, -0.5547, -0.3340],\n",
      "          [-0.1230, -0.1396, -0.3125, -0.1270]],\n",
      "\n",
      "         [[-0.3389, -0.0508,  0.0293,  0.1016],\n",
      "          [-0.0186, -0.0234, -0.2188,  0.0625],\n",
      "          [-0.0156, -0.0010,  0.1406,  0.1260],\n",
      "          [ 0.1875,  0.1025, -0.1523, -0.2148]],\n",
      "\n",
      "         [[-0.7266, -0.5039, -0.5215, -0.0547],\n",
      "          [-0.3438, -0.1299,  0.0791,  0.0645],\n",
      "          [-0.1152,  0.2598,  0.1660,  0.5049],\n",
      "          [ 0.0947,  0.0049,  0.0508,  0.2227]],\n",
      "\n",
      "         [[ 0.1689,  0.3145,  0.5273,  0.0957],\n",
      "          [ 0.1602,  0.2490,  0.1475,  0.0674],\n",
      "          [ 0.1729,  0.1074,  0.1016, -0.0654],\n",
      "          [ 0.1992,  0.1807,  0.1592,  0.0195]]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n",
      "nihhhhhjhj\n",
      "tensor after tensor: tensor([[[[ 0.0322, -0.2510, -0.1201,  0.1338],\n",
      "          [-0.0332, -0.1641, -0.2334, -0.4932],\n",
      "          [-0.2607, -0.4199, -0.5547, -0.3340],\n",
      "          [-0.1230, -0.1396, -0.3125, -0.1270]],\n",
      "\n",
      "         [[-0.3389, -0.0508,  0.0293,  0.1016],\n",
      "          [-0.0186, -0.0234, -0.2188,  0.0625],\n",
      "          [-0.0156, -0.0010,  0.1406,  0.1260],\n",
      "          [ 0.1875,  0.1025, -0.1523, -0.2148]],\n",
      "\n",
      "         [[-0.7266, -0.5039, -0.5215, -0.0547],\n",
      "          [-0.3438, -0.1299,  0.0791,  0.0645],\n",
      "          [-0.1152,  0.2598,  0.1660,  0.5049],\n",
      "          [ 0.0947,  0.0049,  0.0508,  0.2227]],\n",
      "\n",
      "         [[ 0.1689,  0.3145,  0.5273,  0.0957],\n",
      "          [ 0.1602,  0.2490,  0.1475,  0.0674],\n",
      "          [ 0.1729,  0.1074,  0.1016, -0.0654],\n",
      "          [ 0.1992,  0.1807,  0.1592,  0.0195]]]], grad_fn=<ViewBackward0>)\n",
      "q_tensor in fixed_preprocess_tensor: tensor([[[[  1,  -9,  -4,   4],\n",
      "          [ -2,  -6,  -8, -16],\n",
      "          [ -9, -14, -18, -11],\n",
      "          [ -4,  -5, -10,  -5]],\n",
      "\n",
      "         [[-11,  -2,   0,   3],\n",
      "          [ -1,  -1,  -7,   2],\n",
      "          [ -1,  -1,   4,   4],\n",
      "          [  6,   3,  -5,  -7]],\n",
      "\n",
      "         [[-24, -17, -17,  -2],\n",
      "          [-11,  -5,   2,   2],\n",
      "          [ -4,   8,   5,  16],\n",
      "          [  3,   0,   1,   7]],\n",
      "\n",
      "         [[  5,  10,  16,   3],\n",
      "          [  5,   7,   4,   2],\n",
      "          [  5,   3,   3,  -3],\n",
      "          [  6,   5,   5,   0]]]], dtype=torch.int32)\n",
      "Final splitted result: [tensor([[[[  1,  -9],\n",
      "          [ -2,  -6]],\n",
      "\n",
      "         [[-11,  -2],\n",
      "          [ -1,  -1]]]], dtype=torch.int32), tensor([[[[ -4,   4],\n",
      "          [ -8, -16]],\n",
      "\n",
      "         [[  0,   3],\n",
      "          [ -7,   2]]]], dtype=torch.int32), tensor([[[[ -9, -14],\n",
      "          [ -4,  -5]],\n",
      "\n",
      "         [[ -1,  -1],\n",
      "          [  6,   3]]]], dtype=torch.int32), tensor([[[[-18, -11],\n",
      "          [-10,  -5]],\n",
      "\n",
      "         [[  4,   4],\n",
      "          [ -5,  -7]]]], dtype=torch.int32), tensor([[[[-24, -17],\n",
      "          [-11,  -5]],\n",
      "\n",
      "         [[  5,  10],\n",
      "          [  5,   7]]]], dtype=torch.int32), tensor([[[[-17,  -2],\n",
      "          [  2,   2]],\n",
      "\n",
      "         [[ 16,   3],\n",
      "          [  4,   2]]]], dtype=torch.int32), tensor([[[[-4,  8],\n",
      "          [ 3,  0]],\n",
      "\n",
      "         [[ 5,  3],\n",
      "          [ 6,  5]]]], dtype=torch.int32), tensor([[[[ 5, 16],\n",
      "          [ 1,  7]],\n",
      "\n",
      "         [[ 3, -3],\n",
      "          [ 5,  0]]]], dtype=torch.int32)]\n",
      "blocks = [[1, -9, -2, -6, -11, -2, -1, -1], [-4, 4, -8, -16, 0, 3, -7, 2], [-9, -14, -4, -5, -1, -1, 6, 3], [-18, -11, -10, -5, 4, 4, -5, -7], [-24, -17, -11, -5, 5, 10, 5, 7], [-17, -2, 2, 2, 16, 3, 4, 2], [-4, 8, 3, 0, 5, 3, 6, 5], [5, 16, 1, 7, 3, -3, 5, 0]]\n",
      "output_blocks in load_monitors: [[1, -9, -2, -6, -11, -2, -1, -1], [-4, 4, -8, -16, 0, 3, -7, 2], [-9, -14, -4, -5, -1, -1, 6, 3], [-18, -11, -10, -5, 4, 4, -5, -7], [-24, -17, -11, -5, 5, 10, 5, 7], [-17, -2, 2, 2, 16, 3, 4, 2], [-4, 8, 3, 0, 5, 3, 6, 5], [5, 16, 1, 7, 3, -3, 5, 0]]\n",
      "block in load_monitors in emit_tb.py: [1, -9, -2, -6, -11, -2, -1, -1]\n",
      "block in load_monitors in emit_tb.py: [-4, 4, -8, -16, 0, 3, -7, 2]\n",
      "block in load_monitors in emit_tb.py: [-9, -14, -4, -5, -1, -1, 6, 3]\n",
      "block in load_monitors in emit_tb.py: [-18, -11, -10, -5, 4, 4, -5, -7]\n",
      "block in load_monitors in emit_tb.py: [-24, -17, -11, -5, 5, 10, 5, 7]\n",
      "block in load_monitors in emit_tb.py: [-17, -2, 2, 2, 16, 3, 4, 2]\n",
      "block in load_monitors in emit_tb.py: [-4, 8, 3, 0, 5, 3, 6, 5]\n",
      "block in load_monitors in emit_tb.py: [5, 16, 1, 7, 3, -3, 5, 0]\n",
      "    60.00ns DEBUG    cocotb.driver.StreamDriver         Sent from streamping.py StreamDriver [15, 24, 9, 20, 22, 25, 21, 29, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "    80.00ns DEBUG    cocotb.driver.StreamDriver         Sent from streamping.py StreamDriver [2, 4, 15, 28, 5, 9, 12, 27, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/src/mase_cocotb/driver.py:25: DeprecationWarning: This method is now private.\n",
      "  self._thread = cocotb.scheduler.add(self._send_thread())\n",
      "/workspace/src/mase_cocotb/monitor.py:27: DeprecationWarning: This method is now private.\n",
      "  self._thread = cocotb.scheduler.add(self._recv_thread())\n",
      "[W310 13:55:48.051530978 NNPACK.cpp:62] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000020.00ns INFO     cocotb.regression                  test failed\n",
      "                                                         Traceback (most recent call last):\n",
      "                                                           File \"/root/.mase/top/hardware/test/mase_top_tb/test.py\", line 28, in test\n",
      "                                                             await tb.wait_end(timeout=2, timeout_unit=\"ms\")\n",
      "                                                           File \"/workspace/src/mase_cocotb/testbench.py\", line 76, in wait_end\n",
      "                                                             raise TimeoutError(\"Timed out waiting for test to end.\")\n",
      "                                                         TimeoutError: Timed out waiting for test to end.\n",
      "2000020.00ns INFO     cocotb.regression                  **************************************************************************************\n",
      "                                                         ** TEST                          STATUS  SIM TIME (ns)  REAL TIME (s)  RATIO (ns/s) **\n",
      "                                                         **************************************************************************************\n",
      "                                                         ** mase_top_tb.test.test          FAIL     2000020.00          47.22      42353.88  **\n",
      "                                                         **************************************************************************************\n",
      "                                                         ** TESTS=1 PASS=0 FAIL=1 SKIP=0            2000020.00          47.49      42118.63  **\n",
      "                                                         **************************************************************************************\n",
      "                                                         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.11/tempfile.py:1073: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpf8ni7col'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- :0: Verilog $finish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mTest finished. Time taken: 48.98s\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Results file: /workspace/docs/labs/sim_build/results.xml\n"
     ]
    }
   ],
   "source": [
    "from chop.actions import simulate\n",
    "\n",
    "simulate(skip_build=False, skip_test=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
