{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hardware Emit Pass\n",
    "The `emit_verilog` transform pass generates a top-level RTL file and testbench file according to the `MaseGraph`, which includes a hardware implementation of each layer in the network. This top-level file instantiates modules from the `components` library in MASE and/or modules generated using [HLS](https://en.wikipedia.org/wiki/High-level_synthesis), when internal components are not available. The hardware can then be simulated using [Verilator](https://www.veripool.org/verilator/), or deployed on an FPGA.\n",
    "\n",
    "First, add Machop to your system PATH (if you haven't already done so) and import the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mSet logging level to debug\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage:\n",
      "        verilator --help\n",
      "        verilator --version\n",
      "        verilator --binary -j 0 [options] [source_files.v]... [opt_c_files.cpp/c/cc/a/o/so]\n",
      "        verilator --cc [options] [source_files.v]... [opt_c_files.cpp/c/cc/a/o/so]\n",
      "        verilator --sc [options] [source_files.v]... [opt_c_files.cpp/c/cc/a/o/so]\n",
      "        verilator --lint-only -Wall [source_files.v]...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "\n",
    "from chop.ir.graph.mase_graph import MaseGraph\n",
    "\n",
    "from chop.passes.graph.analysis import (\n",
    "    init_metadata_analysis_pass,\n",
    "    add_common_metadata_analysis_pass,\n",
    "    add_hardware_metadata_analysis_pass,\n",
    "    add_software_metadata_analysis_pass,\n",
    "    report_node_type_analysis_pass,\n",
    ")\n",
    "\n",
    "from chop.passes.graph.transforms import (\n",
    "    emit_verilog_top_transform_pass,\n",
    "    emit_internal_rtl_transform_pass,\n",
    "    emit_bram_transform_pass,\n",
    "    emit_cocotb_transform_pass,\n",
    "    quantize_transform_pass,\n",
    ")\n",
    "\n",
    "from chop.tools.logger import set_logging_verbosity\n",
    "\n",
    "set_logging_verbosity(\"debug\")\n",
    "\n",
    "import toml\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# TO DO: remove\n",
    "import os\n",
    "os.environ[\"PATH\"] = \"/opt/homebrew/bin:\" + os.environ[\"PATH\"]\n",
    "!verilator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "  def __init__(self, num_classes=10):\n",
    "    # initialize the parent class—in this case, the nn.Module class from PyTorch.\n",
    "    super().__init__()\n",
    "\n",
    "    # Define layers in the model\n",
    "    # When you instantiate a layer like nn.Conv2d inside the forward method,\n",
    "    # it is created anew each time forward is called. Because that layer is constructed at runtime during every forward pass,\n",
    "    # its weights are randomly re-initialized every time.\n",
    "    # Hence the weights will not be tracked by PyTorch’s parameter-registration mechanism (they won’t show up in model.parameters()), and\n",
    "    # Won’t get updated during backpropagation (since they’re re-created each time),\n",
    "    # Are randomly re-initialized on every forward pass, which makes learning impossible.\n",
    "\n",
    "    # Convolutional layers\n",
    "    # kernel_size: the size of the CNN filter of small matrix that has weights\n",
    "    # kernel_size=3: the kernel/filter will have both height and width of 3 (i.e., 3×3).\n",
    "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "\n",
    "    # Pooling layer\n",
    "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    # Fully-connected layers\n",
    "    # # After two 2x2 poolings on a 28x28 input, the spatial dimension is reduced to 7x7.\n",
    "    # Hence, the input to the first linear layer is 64 * 7 * 7.\n",
    "    self.fc1 = nn.Linear(in_features=64 * 7 * 7, out_features=128)\n",
    "    self.fc2 = nn.Linear(in_features=128, out_features=num_classes)\n",
    "\n",
    "  def forward(self, x):\n",
    "    # Convolution -> ReLU -> Pool\n",
    "    x = self.pool(F.relu(self.conv1(x)))\n",
    "    x = self.pool(F.relu(self.conv2(x)))\n",
    "\n",
    "    # Flatten\n",
    "    x = x.view(x.size(0), -1)  # same as x.view(-1, 64*7*7)\n",
    "\n",
    "    # Fully-connected -> ReLU\n",
    "    x = F.relu(self.fc1(x))\n",
    "\n",
    "    # Final layer (logits)\n",
    "    x = self.fc2(x)\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SingleConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # A single 2D convolution layer\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=1,\n",
    "            # input channel size of one example is 1, i.e. grey scale\n",
    "            # output channel size becomes 2.\n",
    "            # out_channels=2, that convolution layer learns two distinct filters\n",
    "            out_channels=2,\n",
    "            kernel_size=3,\n",
    "            padding=1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply convolution (and optionally an activation)\n",
    "        # Here we show it with a ReLU, but you can remove F.relu(...) if you want pure convolution\n",
    "        x=self.conv1(x)\n",
    "        # x = F.relu(self.conv1(x))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 1, 4, 4])\n",
      "Input tensor:\n",
      " tensor([[[[-1.1258, -1.1524, -0.2506, -0.4339],\n",
      "          [ 0.8487,  0.6920, -0.3160, -2.1152],\n",
      "          [ 0.3223, -1.2633,  0.3500,  0.3081],\n",
      "          [ 0.1198,  1.2377,  1.1168, -0.2473]]]])\n",
      "\n",
      "Output shape: torch.Size([1, 2, 4, 4])\n",
      "Output tensor:\n",
      " tensor([[[[-0.5136, -0.1470, -0.2287, -0.7550],\n",
      "          [ 0.2449, -1.0380, -0.9036, -0.5101],\n",
      "          [-0.5668,  0.2264,  0.7911, -0.8494],\n",
      "          [ 0.4742, -0.0806, -0.5119, -0.3172]],\n",
      "\n",
      "         [[-0.3570,  0.1973,  0.5993,  0.1430],\n",
      "          [-0.3330, -0.5056, -0.6247, -0.1729],\n",
      "          [-0.3489, -0.3864,  0.6195, -0.6861],\n",
      "          [ 0.0048, -1.0650, -0.6682, -0.4203]]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n",
      "Weights:\n",
      " Parameter containing:\n",
      "tensor([[[[ 0.1318,  0.2000, -0.2260],\n",
      "          [-0.1452,  0.1211,  0.2768],\n",
      "          [-0.0686,  0.2494, -0.0537]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0353,  0.3018, -0.3092],\n",
      "          [-0.2098, -0.0844, -0.1299],\n",
      "          [ 0.2880, -0.2161, -0.1534]]]], requires_grad=True)\n",
      "\n",
      "Bias:\n",
      " Parameter containing:\n",
      "tensor([-0.2329, -0.3122], requires_grad=True)\n",
      "\n",
      "Padding:\n",
      " (1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W305 20:45:35.668674979 NNPACK.cpp:62] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Create a random batch of 1 image, 4×4 (grayscale)\n",
    "    x = torch.randn((1, 1, 4, 4))\n",
    "\n",
    "    model = SingleConvNet()\n",
    "    output = model(x)\n",
    "\n",
    "    print(\"Input shape:\", x.shape)\n",
    "    print(\"Input tensor:\\n\", x)        # Show the actual input values\n",
    "\n",
    "    print(\"\\nOutput shape:\", output.shape)\n",
    "    print(\"Output tensor:\\n\", output)  # Show the actual output values\n",
    "\n",
    "    print(\"Weights:\\n\", model.conv1.weight)\n",
    "    print(\"\\nBias:\\n\", model.conv1.bias)\n",
    "    print(\"\\nPadding:\\n\", model.conv1.padding)\n",
    "\n",
    "# Weights, bias are random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36mDEBUG   \u001b[0m \u001b[34mgraph():\n",
      "    %x : [num_users=1] = placeholder[target=x]\n",
      "    %conv1 : [num_users=1] = call_module[target=conv1](args = (%x,), kwargs = {})\n",
      "    return conv1\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.0209, -0.7185,  0.5186],\n",
      "          [-1.3125,  0.1920,  0.5428],\n",
      "          [-2.2188,  0.2590, -1.0297]]]])\n",
      "Hellos in add_common_metadata\n",
      "sigoyi in add_common_metadata\n",
      "graph_model:  GraphModule(\n",
      "  (conv1): Conv2d(1, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "def forward(self, x):\n",
      "    conv1 = self.conv1(x);  x = None\n",
      "    return conv1\n",
      "    \n",
      "# To see more debug info, please use `graph_module.print_readable()`\n",
      "wocao in add_common_metadata\n",
      "graph_iterator_for_metadata:  GraphModule(\n",
      "  (conv1): Conv2d(1, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "def forward(self, x):\n",
      "    conv1 = self.conv1(x);  x = None\n",
      "    return conv1\n",
      "    \n",
      "# To see more debug info, please use `graph_module.print_readable()`\n",
      "args in call_module:  (tensor([[[[-0.0209, -0.7185,  0.5186],\n",
      "          [-1.3125,  0.1920,  0.5428],\n",
      "          [-2.2188,  0.2590, -1.0297]]]]),)\n",
      "kwargs in call_module:  {}\n",
      "HIIII from analyse_common_parameters_module\n",
      "args from analyse_common_parameters_module (tensor([[[[-0.0209, -0.7185,  0.5186],\n",
      "          [-1.3125,  0.1920,  0.5428],\n",
      "          [-2.2188,  0.2590, -1.0297]]]]),)\n",
      "kwargs from analyse_common_parameters_module {}\n",
      "meta before _annotate_arg_metadata: {'mase_type': 'module_related_func', 'mase_op': 'conv2d'}\n",
      "kwargs:  {}\n",
      "meta after _annotate_arg_metadata: {'mase_type': 'module_related_func', 'mase_op': 'conv2d', 'args': OrderedDict([('data_in_0', {'shape': [1, 1, 3, 3], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]})])}\n",
      "meta after get_type_and_precision: {'mase_type': 'module_related_func', 'mase_op': 'conv2d', 'args': OrderedDict([('data_in_0', {'shape': [1, 1, 3, 3], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]})])}\n",
      "weight\n",
      "bias\n",
      "stride (1, 1)\n",
      "Padding (1, 1)\n",
      "meta after for: {'mase_type': 'module_related_func', 'mase_op': 'conv2d', 'args': OrderedDict([('data_in_0', {'shape': [1, 1, 3, 3], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]}), ('weight', {'type': 'float', 'precision': [32], 'shape': [2, 1, 3, 3], 'from': None}), ('bias', {'type': 'float', 'precision': [32], 'shape': [1, 2], 'from': None}), ('stride', (1, 1)), ('padding', (1, 1))])}\n",
      "wobucao in add_common_metadata\n",
      "nihappp in add_common_metadata\n",
      "node.op: placeholder\n",
      "mase_op: placeholder\n",
      "common: {'mase_type': 'placeholder', 'mase_op': 'placeholder', 'args': {}, 'results': OrderedDict([('data_out_0', {'type': 'float', 'precision': [32], 'shape': [1, 1, 3, 3], 'torch_dtype': torch.float32})])}\n",
      "node.op: call_module\n",
      "mase_op: conv2d\n",
      "common: {'mase_type': 'module_related_func', 'mase_op': 'conv2d', 'args': OrderedDict([('data_in_0', {'shape': [1, 1, 3, 3], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]}), ('weight', {'type': 'float', 'precision': [32], 'shape': [2, 1, 3, 3], 'from': None}), ('bias', {'type': 'float', 'precision': [32], 'shape': [1, 2], 'from': None}), ('stride', (1, 1)), ('padding', (1, 1))]), 'results': OrderedDict([('data_out_0', {'type': 'float', 'precision': [32], 'shape': [1, 2, 3, 3], 'torch_dtype': torch.float32})])}\n",
      "node.op: output\n",
      "mase_op: output\n",
      "common: {'mase_type': 'output', 'mase_op': 'output', 'args': {}, 'results': OrderedDict([('data_out_0', {'type': 'float', 'precision': [32], 'shape': [1, 2, 3, 3], 'torch_dtype': torch.float32})])}\n"
     ]
    }
   ],
   "source": [
    "cnn = SingleConvNet()\n",
    "mg = MaseGraph(model=cnn)\n",
    "\n",
    "# Provide a dummy input for the graph so it can use for tracing\n",
    "batch_size = 1\n",
    "# x = torch.randn((batch_size, 2, 2))\n",
    "# batch_size: number of examples\n",
    "# 1, 4,4,: each example has 1 channel, each channel has a size of 4x4\n",
    "x = torch.randn((batch_size, 1, 3, 3))\n",
    "print(x)\n",
    "dummy_in = {\"x\": x}\n",
    "\n",
    "mg, _ = init_metadata_analysis_pass(mg, None)\n",
    "mg, _ = add_common_metadata_analysis_pass(\n",
    "    mg, {\"dummy_in\": dummy_in, \"add_value\": False}\n",
    ")\n",
    "for node in mg.nodes:\n",
    "        mase_op = node.meta[\"mase\"][\"common\"][\"mase_op\"]\n",
    "        print (\"node.op:\", node.op)\n",
    "        print ('mase_op:', mase_op)\n",
    "        print (\"common:\",node.meta[\"mase\"][\"common\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mInspecting graph [add_common_node_type_analysis_pass]\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Node name    Fx Node op    Mase type            Mase op      Value type\n",
      "-----------  ------------  -------------------  -----------  ------------\n",
      "x            placeholder   placeholder          placeholder  NA\n",
      "conv1        call_module   module_related_func  conv2d       fixed\n",
      "output       output        output               output       NA\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "placeholder\n",
      "node_config:  {'name': 'fixed', 'data_in_width': 8, 'data_in_frac_width': 5, 'weight_width': 8, 'weight_frac_width': 5, 'bias_width': 8, 'bias_frac_width': 5, 'data_out_width': 8, 'data_out_frac_width': 5, 'floor': True}\n",
      "output\n"
     ]
    }
   ],
   "source": [
    "config_file = os.path.join(\n",
    "    os.path.abspath(\"\"),\n",
    "    \"..\",\n",
    "    \"..\",\n",
    "    \"configs\",\n",
    "    \"tests\",\n",
    "    \"quantize\",\n",
    "    \"fixed.toml\",\n",
    ")\n",
    "# Fixed.toml used to quantize the model\n",
    "with open(config_file, \"r\") as f:\n",
    "    quan_args = toml.load(f)[\"passes\"][\"quantize\"]\n",
    "mg, _ = quantize_transform_pass(mg, quan_args)\n",
    "\n",
    "_ = report_node_type_analysis_pass(mg)\n",
    "\n",
    "# Update the metadata\n",
    "for node in mg.fx_graph.nodes:\n",
    "    for arg, arg_info in node.meta[\"mase\"][\"common\"][\"args\"].items():\n",
    "        if isinstance(arg_info, dict):\n",
    "            arg_info[\"type\"] = \"fixed\"\n",
    "            arg_info[\"precision\"] = [8, 5]\n",
    "    for result, result_info in node.meta[\"mase\"][\"common\"][\"results\"].items():\n",
    "        if isinstance(result_info, dict):\n",
    "            result_info[\"type\"] = \"fixed\"\n",
    "            result_info[\"precision\"] = [8, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hardware Metapass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mase_op: conv2d\n",
      "2222\n",
      "vp:  {}\n",
      "arg in add_verilog_param: data_in_0\n",
      "vp after for:  {'DATA_IN_0_PRECISION_0': 8, 'DATA_IN_0_PRECISION_1': 5, 'DATA_IN_0_TENSOR_SIZE_DIM_0': 3, 'DATA_IN_0_PARALLELISM_DIM_0': 3, 'DATA_IN_0_TENSOR_SIZE_DIM_1': 3, 'DATA_IN_0_PARALLELISM_DIM_1': 3, 'DATA_IN_0_TENSOR_SIZE_DIM_2': 1, 'DATA_IN_0_PARALLELISM_DIM_2': 1, 'DATA_IN_0_TENSOR_SIZE_DIM_3': 1, 'DATA_IN_0_PARALLELISM_DIM_3': 1}\n",
      "arg in add_verilog_param: weight\n",
      "vp after for:  {'DATA_IN_0_PRECISION_0': 8, 'DATA_IN_0_PRECISION_1': 5, 'DATA_IN_0_TENSOR_SIZE_DIM_0': 3, 'DATA_IN_0_PARALLELISM_DIM_0': 3, 'DATA_IN_0_TENSOR_SIZE_DIM_1': 3, 'DATA_IN_0_PARALLELISM_DIM_1': 3, 'DATA_IN_0_TENSOR_SIZE_DIM_2': 1, 'DATA_IN_0_PARALLELISM_DIM_2': 1, 'DATA_IN_0_TENSOR_SIZE_DIM_3': 1, 'DATA_IN_0_PARALLELISM_DIM_3': 1, 'WEIGHT_PRECISION_0': 8, 'WEIGHT_PRECISION_1': 5, 'WEIGHT_TENSOR_SIZE_DIM_0': 3, 'WEIGHT_PARALLELISM_DIM_0': 3, 'WEIGHT_TENSOR_SIZE_DIM_1': 3, 'WEIGHT_PARALLELISM_DIM_1': 3, 'WEIGHT_TENSOR_SIZE_DIM_2': 1, 'WEIGHT_PARALLELISM_DIM_2': 1, 'WEIGHT_TENSOR_SIZE_DIM_3': 2, 'WEIGHT_PARALLELISM_DIM_3': 2}\n",
      "arg in add_verilog_param: bias\n",
      "vp after for:  {'DATA_IN_0_PRECISION_0': 8, 'DATA_IN_0_PRECISION_1': 5, 'DATA_IN_0_TENSOR_SIZE_DIM_0': 3, 'DATA_IN_0_PARALLELISM_DIM_0': 3, 'DATA_IN_0_TENSOR_SIZE_DIM_1': 3, 'DATA_IN_0_PARALLELISM_DIM_1': 3, 'DATA_IN_0_TENSOR_SIZE_DIM_2': 1, 'DATA_IN_0_PARALLELISM_DIM_2': 1, 'DATA_IN_0_TENSOR_SIZE_DIM_3': 1, 'DATA_IN_0_PARALLELISM_DIM_3': 1, 'WEIGHT_PRECISION_0': 8, 'WEIGHT_PRECISION_1': 5, 'WEIGHT_TENSOR_SIZE_DIM_0': 3, 'WEIGHT_PARALLELISM_DIM_0': 3, 'WEIGHT_TENSOR_SIZE_DIM_1': 3, 'WEIGHT_PARALLELISM_DIM_1': 3, 'WEIGHT_TENSOR_SIZE_DIM_2': 1, 'WEIGHT_PARALLELISM_DIM_2': 1, 'WEIGHT_TENSOR_SIZE_DIM_3': 2, 'WEIGHT_PARALLELISM_DIM_3': 2, 'BIAS_PRECISION_0': 8, 'BIAS_PRECISION_1': 5, 'BIAS_TENSOR_SIZE_DIM_0': 2, 'BIAS_PARALLELISM_DIM_0': 2, 'BIAS_TENSOR_SIZE_DIM_1': 1, 'BIAS_PARALLELISM_DIM_1': 1}\n",
      "vp after for:  {'DATA_IN_0_PRECISION_0': 8, 'DATA_IN_0_PRECISION_1': 5, 'DATA_IN_0_TENSOR_SIZE_DIM_0': 3, 'DATA_IN_0_PARALLELISM_DIM_0': 3, 'DATA_IN_0_TENSOR_SIZE_DIM_1': 3, 'DATA_IN_0_PARALLELISM_DIM_1': 3, 'DATA_IN_0_TENSOR_SIZE_DIM_2': 1, 'DATA_IN_0_PARALLELISM_DIM_2': 1, 'DATA_IN_0_TENSOR_SIZE_DIM_3': 1, 'DATA_IN_0_PARALLELISM_DIM_3': 1, 'WEIGHT_PRECISION_0': 8, 'WEIGHT_PRECISION_1': 5, 'WEIGHT_TENSOR_SIZE_DIM_0': 3, 'WEIGHT_PARALLELISM_DIM_0': 3, 'WEIGHT_TENSOR_SIZE_DIM_1': 3, 'WEIGHT_PARALLELISM_DIM_1': 3, 'WEIGHT_TENSOR_SIZE_DIM_2': 1, 'WEIGHT_PARALLELISM_DIM_2': 1, 'WEIGHT_TENSOR_SIZE_DIM_3': 2, 'WEIGHT_PARALLELISM_DIM_3': 2, 'BIAS_PRECISION_0': 8, 'BIAS_PRECISION_1': 5, 'BIAS_TENSOR_SIZE_DIM_0': 2, 'BIAS_PARALLELISM_DIM_0': 2, 'BIAS_TENSOR_SIZE_DIM_1': 1, 'BIAS_PARALLELISM_DIM_1': 1, 'STRIDE_TENSOR_SIZE_DIM_0_VALUE': 1, 'STRIDE_TENSOR_SIZE_DIM_1_VALUE': 1}\n",
      "vp after for:  {'DATA_IN_0_PRECISION_0': 8, 'DATA_IN_0_PRECISION_1': 5, 'DATA_IN_0_TENSOR_SIZE_DIM_0': 3, 'DATA_IN_0_PARALLELISM_DIM_0': 3, 'DATA_IN_0_TENSOR_SIZE_DIM_1': 3, 'DATA_IN_0_PARALLELISM_DIM_1': 3, 'DATA_IN_0_TENSOR_SIZE_DIM_2': 1, 'DATA_IN_0_PARALLELISM_DIM_2': 1, 'DATA_IN_0_TENSOR_SIZE_DIM_3': 1, 'DATA_IN_0_PARALLELISM_DIM_3': 1, 'WEIGHT_PRECISION_0': 8, 'WEIGHT_PRECISION_1': 5, 'WEIGHT_TENSOR_SIZE_DIM_0': 3, 'WEIGHT_PARALLELISM_DIM_0': 3, 'WEIGHT_TENSOR_SIZE_DIM_1': 3, 'WEIGHT_PARALLELISM_DIM_1': 3, 'WEIGHT_TENSOR_SIZE_DIM_2': 1, 'WEIGHT_PARALLELISM_DIM_2': 1, 'WEIGHT_TENSOR_SIZE_DIM_3': 2, 'WEIGHT_PARALLELISM_DIM_3': 2, 'BIAS_PRECISION_0': 8, 'BIAS_PRECISION_1': 5, 'BIAS_TENSOR_SIZE_DIM_0': 2, 'BIAS_PARALLELISM_DIM_0': 2, 'BIAS_TENSOR_SIZE_DIM_1': 1, 'BIAS_PARALLELISM_DIM_1': 1, 'STRIDE_TENSOR_SIZE_DIM_0_VALUE': 1, 'STRIDE_TENSOR_SIZE_DIM_1_VALUE': 1, 'PADDING_TENSOR_SIZE_DIM_0_VALUE': 1, 'PADDING_TENSOR_SIZE_DIM_1_VALUE': 1}\n",
      "result in add_verilog_param: data_out_0\n",
      "result_info in add_verilog_param: {'type': 'fixed', 'precision': [8, 5], 'shape': [1, 2, 3, 3], 'torch_dtype': torch.float32}\n",
      "node.op: placeholder\n",
      "mase_op: placeholder\n",
      "common: {'mase_type': 'placeholder', 'mase_op': 'placeholder', 'args': {}, 'results': OrderedDict([('data_out_0', {'type': 'fixed', 'precision': [8, 5], 'shape': [1, 1, 3, 3], 'torch_dtype': torch.float32})])}\n",
      "hardware: {'is_implicit': True, 'device_id': 0, 'max_parallelism': [4, 4, 4, 4]}\n",
      "node.op: call_module\n",
      "mase_op: conv2d\n",
      "common: {'mase_type': 'module_related_func', 'mase_op': 'conv2d', 'args': OrderedDict([('data_in_0', {'shape': [1, 1, 3, 3], 'torch_dtype': torch.float32, 'type': 'fixed', 'precision': [8, 5]}), ('weight', {'type': 'fixed', 'precision': [8, 5], 'shape': [2, 1, 3, 3], 'from': None}), ('bias', {'type': 'fixed', 'precision': [8, 5], 'shape': [1, 2], 'from': None}), ('stride', (1, 1)), ('padding', (1, 1))]), 'results': OrderedDict([('data_out_0', {'type': 'fixed', 'precision': [8, 5], 'shape': [1, 2, 3, 3], 'torch_dtype': torch.float32})])}\n",
      "hardware: {'is_implicit': False, 'device_id': -1, 'interface': {'weight': {'storage': 'BRAM', 'transpose': False}, 'bias': {'storage': 'BRAM', 'transpose': False}, 'stride': {}, 'padding': {}}, 'toolchain': 'INTERNAL_RTL', 'module': 'convolution', 'dependence_files': ['linear_layers/fixed_operators/rtl/fixed_dot_product.sv', 'linear_layers/fixed_operators/rtl/fixed_vector_mult.sv', 'linear_layers/fixed_operators/rtl/fixed_adder_tree.sv', 'linear_layers/fixed_operators/rtl/fixed_adder_tree_layer.sv', 'linear_layers/fixed_operators/rtl/fixed_accumulator.sv', 'linear_layers/fixed_operators/rtl/fixed_mult.sv', 'memory/rtl/input_buffer.sv', 'memory/rtl/unpacked_skid_buffer.sv', 'memory/rtl/skid_buffer.sv', 'memory/rtl/blk_mem_gen_0.sv', 'memory/rtl/unpacked_skid_buffer.sv', 'common/rtl/join2.sv', 'cast/rtl/floor_round.sv', 'cast/rtl/signed_clamp.sv', 'cast/rtl/fixed_signed_cast.sv', 'cast/rtl/fixed_cast.sv', 'cast/rtl/fixed_rounding.sv', 'convolution_layers/rtl/convolution_arith.sv', 'convolution_layers/rtl/convolution_mase.sv', 'convolution_layers/rtl/padding.sv', 'convolution_layers/rtl/roller.sv', 'convolution_layers/rtl/sliding_window.sv'], 'max_parallelism': [4, 4, 4, 4], 'verilog_param': {'DATA_IN_0_PRECISION_0': 8, 'DATA_IN_0_PRECISION_1': 5, 'DATA_IN_0_TENSOR_SIZE_DIM_0': 3, 'DATA_IN_0_PARALLELISM_DIM_0': 3, 'DATA_IN_0_TENSOR_SIZE_DIM_1': 3, 'DATA_IN_0_PARALLELISM_DIM_1': 3, 'DATA_IN_0_TENSOR_SIZE_DIM_2': 1, 'DATA_IN_0_PARALLELISM_DIM_2': 1, 'DATA_IN_0_TENSOR_SIZE_DIM_3': 1, 'DATA_IN_0_PARALLELISM_DIM_3': 1, 'WEIGHT_PRECISION_0': 8, 'WEIGHT_PRECISION_1': 5, 'WEIGHT_TENSOR_SIZE_DIM_0': 3, 'WEIGHT_PARALLELISM_DIM_0': 3, 'WEIGHT_TENSOR_SIZE_DIM_1': 3, 'WEIGHT_PARALLELISM_DIM_1': 3, 'WEIGHT_TENSOR_SIZE_DIM_2': 1, 'WEIGHT_PARALLELISM_DIM_2': 1, 'WEIGHT_TENSOR_SIZE_DIM_3': 2, 'WEIGHT_PARALLELISM_DIM_3': 2, 'BIAS_PRECISION_0': 8, 'BIAS_PRECISION_1': 5, 'BIAS_TENSOR_SIZE_DIM_0': 2, 'BIAS_PARALLELISM_DIM_0': 2, 'BIAS_TENSOR_SIZE_DIM_1': 1, 'BIAS_PARALLELISM_DIM_1': 1, 'STRIDE_TENSOR_SIZE_DIM_0_VALUE': 1, 'STRIDE_TENSOR_SIZE_DIM_1_VALUE': 1, 'PADDING_TENSOR_SIZE_DIM_0_VALUE': 1, 'PADDING_TENSOR_SIZE_DIM_1_VALUE': 1, 'DATA_OUT_0_PRECISION_0': 8, 'DATA_OUT_0_PRECISION_1': 5, 'DATA_OUT_0_TENSOR_SIZE_DIM_0': 3, 'DATA_OUT_0_PARALLELISM_DIM_0': 3, 'DATA_OUT_0_TENSOR_SIZE_DIM_1': 3, 'DATA_OUT_0_PARALLELISM_DIM_1': 3, 'DATA_OUT_0_TENSOR_SIZE_DIM_2': 2, 'DATA_OUT_0_PARALLELISM_DIM_2': 2, 'DATA_OUT_0_TENSOR_SIZE_DIM_3': 1, 'DATA_OUT_0_PARALLELISM_DIM_3': 1}}\n",
      "node.op: output\n",
      "mase_op: output\n",
      "common: {'mase_type': 'output', 'mase_op': 'output', 'args': {}, 'results': OrderedDict([('data_out_0', {'type': 'fixed', 'precision': [8, 5], 'shape': [1, 2, 3, 3], 'torch_dtype': torch.float32})])}\n",
      "hardware: {'is_implicit': True, 'device_id': 0, 'max_parallelism': [4, 4, 4, 4]}\n",
      "param_name in CNN.jynb: weight\n",
      "parameter in CNN.jynb: Parameter containing:\n",
      "tensor([[[[-0.1946,  0.2865,  0.1487],\n",
      "          [ 0.1616,  0.0175, -0.1709],\n",
      "          [ 0.0564, -0.3112, -0.2409]]],\n",
      "\n",
      "\n",
      "        [[[-0.1718,  0.2103,  0.1954],\n",
      "          [-0.1478, -0.0120,  0.2132],\n",
      "          [ 0.3314,  0.1323,  0.0450]]]], requires_grad=True)\n",
      "param_name in CNN.jynb: bias\n",
      "parameter in CNN.jynb: Parameter containing:\n",
      "tensor([-0.3299, -0.2162], requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nweights and bias in the Conv/linear in Maze\\nparam_data = node.meta[\"mase\"].module.get_parameter(param_name).data\\nprint (\"param_data: \", param_data)\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mg, _ = add_hardware_metadata_analysis_pass(mg)\n",
    "for node in mg.nodes:\n",
    "        mase_op = node.meta[\"mase\"][\"common\"][\"mase_op\"]\n",
    "        print (\"node.op:\", node.op)\n",
    "        print ('mase_op:', mase_op)\n",
    "        print (\"common:\",node.meta[\"mase\"][\"common\"])\n",
    "        print (\"hardware:\",node.meta[\"mase\"][\"hardware\"])\n",
    "\n",
    "for node in mg.fx_graph.nodes:\n",
    "        if node.meta[\"mase\"].parameters[\"hardware\"][\"is_implicit\"]:\n",
    "            continue\n",
    "        # Only modules have internal parameters\n",
    "        if node.meta[\"mase\"].module is None:\n",
    "            continue\n",
    "        # print (node.meta[\"mase\"].parameters[\"hardware\"])\n",
    "        # Only checks the hardware data that contains the key toolchain\n",
    "        if \"INTERNAL\" in node.meta[\"mase\"].parameters[\"hardware\"][\"toolchain\"]:\n",
    "                for param_name, parameter in node.meta[\"mase\"].module.named_parameters():\n",
    "                        print (\"param_name in CNN.jynb:\",param_name)\n",
    "                        print (\"parameter in CNN.jynb:\", parameter)\n",
    "\n",
    "\"\"\"\n",
    "weights and bias in the Conv/linear in Maze\n",
    "param_data = node.meta[\"mase\"].module.get_parameter(param_name).data\n",
    "print (\"param_data: \", param_data)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emit for SV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mEmitting Verilog...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEmitting internal components...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter_map in VerilogEmitter: {'conv1_DATA_IN_0_PRECISION_0': 8, 'conv1_DATA_IN_0_PRECISION_1': 5, 'conv1_DATA_IN_0_TENSOR_SIZE_DIM_0': 3, 'conv1_DATA_IN_0_PARALLELISM_DIM_0': 3, 'conv1_DATA_IN_0_TENSOR_SIZE_DIM_1': 3, 'conv1_DATA_IN_0_PARALLELISM_DIM_1': 3, 'conv1_DATA_IN_0_TENSOR_SIZE_DIM_2': 1, 'conv1_DATA_IN_0_PARALLELISM_DIM_2': 1, 'conv1_DATA_IN_0_TENSOR_SIZE_DIM_3': 1, 'conv1_DATA_IN_0_PARALLELISM_DIM_3': 1, 'conv1_WEIGHT_PRECISION_0': 8, 'conv1_WEIGHT_PRECISION_1': 5, 'conv1_WEIGHT_TENSOR_SIZE_DIM_0': 3, 'conv1_WEIGHT_PARALLELISM_DIM_0': 3, 'conv1_WEIGHT_TENSOR_SIZE_DIM_1': 3, 'conv1_WEIGHT_PARALLELISM_DIM_1': 3, 'conv1_WEIGHT_TENSOR_SIZE_DIM_2': 1, 'conv1_WEIGHT_PARALLELISM_DIM_2': 1, 'conv1_WEIGHT_TENSOR_SIZE_DIM_3': 2, 'conv1_WEIGHT_PARALLELISM_DIM_3': 2, 'conv1_BIAS_PRECISION_0': 8, 'conv1_BIAS_PRECISION_1': 5, 'conv1_BIAS_TENSOR_SIZE_DIM_0': 2, 'conv1_BIAS_PARALLELISM_DIM_0': 2, 'conv1_BIAS_TENSOR_SIZE_DIM_1': 1, 'conv1_BIAS_PARALLELISM_DIM_1': 1, 'conv1_STRIDE_TENSOR_SIZE_DIM_0_VALUE': 1, 'conv1_STRIDE_TENSOR_SIZE_DIM_1_VALUE': 1, 'conv1_PADDING_TENSOR_SIZE_DIM_0_VALUE': 1, 'conv1_PADDING_TENSOR_SIZE_DIM_1_VALUE': 1, 'conv1_DATA_OUT_0_PRECISION_0': 8, 'conv1_DATA_OUT_0_PRECISION_1': 5, 'conv1_DATA_OUT_0_TENSOR_SIZE_DIM_0': 3, 'conv1_DATA_OUT_0_PARALLELISM_DIM_0': 3, 'conv1_DATA_OUT_0_TENSOR_SIZE_DIM_1': 3, 'conv1_DATA_OUT_0_PARALLELISM_DIM_1': 3, 'conv1_DATA_OUT_0_TENSOR_SIZE_DIM_2': 2, 'conv1_DATA_OUT_0_PARALLELISM_DIM_2': 2, 'conv1_DATA_OUT_0_TENSOR_SIZE_DIM_3': 1, 'conv1_DATA_OUT_0_PARALLELISM_DIM_3': 1, 'DATA_IN_0_PRECISION_0': 8, 'DATA_IN_0_PRECISION_1': 5, 'DATA_IN_0_TENSOR_SIZE_DIM_0': 3, 'DATA_IN_0_PARALLELISM_DIM_0': 3, 'DATA_IN_0_TENSOR_SIZE_DIM_1': 3, 'DATA_IN_0_PARALLELISM_DIM_1': 3, 'DATA_IN_0_TENSOR_SIZE_DIM_2': 1, 'DATA_IN_0_PARALLELISM_DIM_2': 1, 'DATA_IN_0_TENSOR_SIZE_DIM_3': 1, 'DATA_IN_0_PARALLELISM_DIM_3': 1, 'DATA_OUT_0_PRECISION_0': 8, 'DATA_OUT_0_PRECISION_1': 5, 'DATA_OUT_0_TENSOR_SIZE_DIM_0': 3, 'DATA_OUT_0_PARALLELISM_DIM_0': 3, 'DATA_OUT_0_TENSOR_SIZE_DIM_1': 3, 'DATA_OUT_0_PARALLELISM_DIM_1': 3, 'DATA_OUT_0_TENSOR_SIZE_DIM_2': 2, 'DATA_OUT_0_PARALLELISM_DIM_2': 2, 'DATA_OUT_0_TENSOR_SIZE_DIM_3': 1, 'DATA_OUT_0_PARALLELISM_DIM_3': 1}\n",
      "nodes_in: [conv1]\n",
      "nodes_out: [conv1]\n",
      "parameter in VerilogParameterEmitter:     parameter conv1_DATA_IN_0_PRECISION_0 = 8,\n",
      "    parameter conv1_DATA_IN_0_PRECISION_1 = 5,\n",
      "    parameter conv1_DATA_IN_0_TENSOR_SIZE_DIM_0 = 3,\n",
      "    parameter conv1_DATA_IN_0_PARALLELISM_DIM_0 = 3,\n",
      "    parameter conv1_DATA_IN_0_TENSOR_SIZE_DIM_1 = 3,\n",
      "    parameter conv1_DATA_IN_0_PARALLELISM_DIM_1 = 3,\n",
      "    parameter conv1_DATA_IN_0_TENSOR_SIZE_DIM_2 = 1,\n",
      "    parameter conv1_DATA_IN_0_PARALLELISM_DIM_2 = 1,\n",
      "    parameter conv1_DATA_IN_0_TENSOR_SIZE_DIM_3 = 1,\n",
      "    parameter conv1_DATA_IN_0_PARALLELISM_DIM_3 = 1,\n",
      "    parameter conv1_WEIGHT_PRECISION_0 = 8,\n",
      "    parameter conv1_WEIGHT_PRECISION_1 = 5,\n",
      "    parameter conv1_WEIGHT_TENSOR_SIZE_DIM_0 = 3,\n",
      "    parameter conv1_WEIGHT_PARALLELISM_DIM_0 = 3,\n",
      "    parameter conv1_WEIGHT_TENSOR_SIZE_DIM_1 = 3,\n",
      "    parameter conv1_WEIGHT_PARALLELISM_DIM_1 = 3,\n",
      "    parameter conv1_WEIGHT_TENSOR_SIZE_DIM_2 = 1,\n",
      "    parameter conv1_WEIGHT_PARALLELISM_DIM_2 = 1,\n",
      "    parameter conv1_WEIGHT_TENSOR_SIZE_DIM_3 = 2,\n",
      "    parameter conv1_WEIGHT_PARALLELISM_DIM_3 = 2,\n",
      "    parameter conv1_BIAS_PRECISION_0 = 8,\n",
      "    parameter conv1_BIAS_PRECISION_1 = 5,\n",
      "    parameter conv1_BIAS_TENSOR_SIZE_DIM_0 = 2,\n",
      "    parameter conv1_BIAS_PARALLELISM_DIM_0 = 2,\n",
      "    parameter conv1_BIAS_TENSOR_SIZE_DIM_1 = 1,\n",
      "    parameter conv1_BIAS_PARALLELISM_DIM_1 = 1,\n",
      "    parameter conv1_STRIDE_TENSOR_SIZE_DIM_0_VALUE = 1,\n",
      "    parameter conv1_STRIDE_TENSOR_SIZE_DIM_1_VALUE = 1,\n",
      "    parameter conv1_PADDING_TENSOR_SIZE_DIM_0_VALUE = 1,\n",
      "    parameter conv1_PADDING_TENSOR_SIZE_DIM_1_VALUE = 1,\n",
      "    parameter conv1_DATA_OUT_0_PRECISION_0 = 8,\n",
      "    parameter conv1_DATA_OUT_0_PRECISION_1 = 5,\n",
      "    parameter conv1_DATA_OUT_0_TENSOR_SIZE_DIM_0 = 3,\n",
      "    parameter conv1_DATA_OUT_0_PARALLELISM_DIM_0 = 3,\n",
      "    parameter conv1_DATA_OUT_0_TENSOR_SIZE_DIM_1 = 3,\n",
      "    parameter conv1_DATA_OUT_0_PARALLELISM_DIM_1 = 3,\n",
      "    parameter conv1_DATA_OUT_0_TENSOR_SIZE_DIM_2 = 2,\n",
      "    parameter conv1_DATA_OUT_0_PARALLELISM_DIM_2 = 2,\n",
      "    parameter conv1_DATA_OUT_0_TENSOR_SIZE_DIM_3 = 1,\n",
      "    parameter conv1_DATA_OUT_0_PARALLELISM_DIM_3 = 1,\n",
      "    parameter DATA_IN_0_PRECISION_0 = 8,\n",
      "    parameter DATA_IN_0_PRECISION_1 = 5,\n",
      "    parameter DATA_IN_0_TENSOR_SIZE_DIM_0 = 3,\n",
      "    parameter DATA_IN_0_PARALLELISM_DIM_0 = 3,\n",
      "    parameter DATA_IN_0_TENSOR_SIZE_DIM_1 = 3,\n",
      "    parameter DATA_IN_0_PARALLELISM_DIM_1 = 3,\n",
      "    parameter DATA_IN_0_TENSOR_SIZE_DIM_2 = 1,\n",
      "    parameter DATA_IN_0_PARALLELISM_DIM_2 = 1,\n",
      "    parameter DATA_IN_0_TENSOR_SIZE_DIM_3 = 1,\n",
      "    parameter DATA_IN_0_PARALLELISM_DIM_3 = 1,\n",
      "    parameter DATA_OUT_0_PRECISION_0 = 8,\n",
      "    parameter DATA_OUT_0_PRECISION_1 = 5,\n",
      "    parameter DATA_OUT_0_TENSOR_SIZE_DIM_0 = 3,\n",
      "    parameter DATA_OUT_0_PARALLELISM_DIM_0 = 3,\n",
      "    parameter DATA_OUT_0_TENSOR_SIZE_DIM_1 = 3,\n",
      "    parameter DATA_OUT_0_PARALLELISM_DIM_1 = 3,\n",
      "    parameter DATA_OUT_0_TENSOR_SIZE_DIM_2 = 2,\n",
      "    parameter DATA_OUT_0_PARALLELISM_DIM_2 = 2,\n",
      "    parameter DATA_OUT_0_TENSOR_SIZE_DIM_3 = 1,\n",
      "    parameter DATA_OUT_0_PARALLELISM_DIM_3 = 1,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mg, _ = emit_verilog_top_transform_pass(mg)\n",
    "mg, _ = emit_internal_rtl_transform_pass(mg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mEmitting BRAM...\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[34mEmitting DAT file for node: conv1, parameter: weight\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[34mROM module weight successfully written into /root/.mase/top/hardware/rtl/conv1_weight_source.sv\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[34mInit data weight successfully written into /root/.mase/top/hardware/rtl/conv1_weight_rom.dat\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[34mEmitting DAT file for node: conv1, parameter: bias\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[34mROM module bias successfully written into /root/.mase/top/hardware/rtl/conv1_bias_source.sv\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[34mInit data bias successfully written into /root/.mase/top/hardware/rtl/conv1_bias_rom.dat\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 in emit_bram_transform_pass\n",
      "/root/.mase/top/hardware/rtl\n",
      "param_name in emit_bram_handshake: weight\n",
      "parameter in emit_bram_handshake: Parameter containing:\n",
      "tensor([[[[-0.1946,  0.2865,  0.1487],\n",
      "          [ 0.1616,  0.0175, -0.1709],\n",
      "          [ 0.0564, -0.3112, -0.2409]]],\n",
      "\n",
      "\n",
      "        [[[-0.1718,  0.2103,  0.1954],\n",
      "          [-0.1478, -0.0120,  0.2132],\n",
      "          [ 0.3314,  0.1323,  0.0450]]]], requires_grad=True)\n",
      "out_size in emit_parameters_in_mem_internal: 9\n",
      "conv1\n",
      "param_data in emit_parameters_in_dat_internal:  tensor([[[[-0.1946,  0.2865,  0.1487],\n",
      "          [ 0.1616,  0.0175, -0.1709],\n",
      "          [ 0.0564, -0.3112, -0.2409]]],\n",
      "\n",
      "\n",
      "        [[[-0.1718,  0.2103,  0.1954],\n",
      "          [-0.1478, -0.0120,  0.2132],\n",
      "          [ 0.3314,  0.1323,  0.0450]]]])\n",
      "out_depth:  2\n",
      "data_buff:  fa09050501fb02f6f8\n",
      "fb0706fb00070b0401\n",
      "\n",
      "param_name in emit_bram_handshake: bias\n",
      "parameter in emit_bram_handshake: Parameter containing:\n",
      "tensor([-0.3299, -0.2162], requires_grad=True)\n",
      "out_size in emit_parameters_in_mem_internal: 2\n",
      "conv1\n",
      "param_data in emit_parameters_in_dat_internal:  tensor([-0.3299, -0.2162])\n",
      "out_depth:  1\n",
      "data_buff:  f5f9\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n  param_data:  tensor([[[[-0.1946,  0.2865,  0.1487],\\n          [ 0.1616,  0.0175, -0.1709],\\n          [ 0.0564, -0.3112, -0.2409]]],\\n\\n\\n        [[[-0.1718,  0.2103,  0.1954],\\n          [-0.1478, -0.0120,  0.2132],\\n          [ 0.3314,  0.1323,  0.0450]]]])\\n  This would be weight, as I defined conv as (2,1,3,3)\\n  The kernel filter size is 3x3, and we have 2 filters, thus 9x2=18 elements\\n  Bias: depends on number of filter-> here 2 filters, thus 2 bias elements,\\n    as bias added after filter multiplies with section of pixel\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mg, _ = emit_bram_transform_pass(mg)\n",
    "\n",
    "\"\"\"\n",
    "  param_data:  tensor([[[[-0.1946,  0.2865,  0.1487],\n",
    "          [ 0.1616,  0.0175, -0.1709],\n",
    "          [ 0.0564, -0.3112, -0.2409]]],\n",
    "\n",
    "\n",
    "        [[[-0.1718,  0.2103,  0.1954],\n",
    "          [-0.1478, -0.0120,  0.2132],\n",
    "          [ 0.3314,  0.1323,  0.0450]]]])\n",
    "  This would be weight, as I defined conv as (2,1,3,3)\n",
    "  The kernel filter size is 3x3, and we have 2 filters, thus 9x2=18 elements\n",
    "  Bias: depends on number of filter-> here 2 filters, thus 2 bias elements,\n",
    "    as bias added after filter multiplies with section of pixel\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mEmitting testbench...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "mg, _ = emit_cocotb_transform_pass(mg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Running command perl /usr/local/bin/verilator -cc --exe -Mdir /workspace/docs/labs/sim_build -DCOCOTB_SIM=1 --top-module top --vpi --public-flat-rw --prefix Vtop -o top -LDFLAGS '-Wl,-rpath,/usr/local/lib/python3.11/dist-packages/cocotb/libs -L/usr/local/lib/python3.11/dist-packages/cocotb/libs -lcocotbvpi_verilator' -Wno-fatal -Wno-lint -Wno-style --trace-fst --trace-structs --trace-depth 3 -I/root/.mase/top/hardware/rtl -I/workspace/src/mase_components/interface/rtl -I/workspace/src/mase_components/language_models/rtl -I/workspace/src/mase_components/memory/rtl -I/workspace/src/mase_components/vivado/rtl -I/workspace/src/mase_components/convolution_layers/rtl -I/workspace/src/mase_components/cast/rtl -I/workspace/src/mase_components/systolic_arrays/rtl -I/workspace/src/mase_components/scalar_operators/rtl -I/workspace/src/mase_components/transformer_layers/rtl -I/workspace/src/mase_components/common/rtl -I/workspace/src/mase_components/hls/rtl -I/workspace/src/mase_components/vision_models/rtl -I/workspace/src/mase_components/linear_layers/rtl -I/workspace/src/mase_components/activation_layers/rtl -I/workspace/src/mase_components/normalization_layers/rtl -I/workspace/src/mase_components/helper/rtl /usr/local/lib/python3.11/dist-packages/cocotb/share/lib/verilator/verilator.cpp /root/.mase/top/hardware/rtl/register_slice.sv /root/.mase/top/hardware/rtl/fixed_adder_tree_layer.sv /root/.mase/top/hardware/rtl/unpacked_repeat_circular_buffer.sv /root/.mase/top/hardware/rtl/matmul.sv /root/.mase/top/hardware/rtl/join2.sv /root/.mase/top/hardware/rtl/sliding_window.sv /root/.mase/top/hardware/rtl/convolution.sv /root/.mase/top/hardware/rtl/matrix_unflatten.sv /root/.mase/top/hardware/rtl/fixed_signed_cast.sv /root/.mase/top/hardware/rtl/blk_mem_gen_0.sv /root/.mase/top/hardware/rtl/fixed_relu.sv /root/.mase/top/hardware/rtl/fixed_adder_tree.sv /root/.mase/top/hardware/rtl/matrix_fifo.sv /root/.mase/top/hardware/rtl/conv1_bias_source.sv /root/.mase/top/hardware/rtl/fc1_bias_source.sv /root/.mase/top/hardware/rtl/fixed_linear.sv /root/.mase/top/hardware/rtl/top.sv /root/.mase/top/hardware/rtl/fc1_weight_source.sv /root/.mase/top/hardware/rtl/fc1_1_bias_source.sv /root/.mase/top/hardware/rtl/conv1_weight_source.sv /root/.mase/top/hardware/rtl/transpose.sv /root/.mase/top/hardware/rtl/fixed_rounding.sv /root/.mase/top/hardware/rtl/input_buffer.sv /root/.mase/top/hardware/rtl/floor_round.sv /root/.mase/top/hardware/rtl/convolution_mase.sv /root/.mase/top/hardware/rtl/fc1_1_weight_source.sv /root/.mase/top/hardware/rtl/convolution_arith.sv /root/.mase/top/hardware/rtl/matrix_accumulator.sv /root/.mase/top/hardware/rtl/simple_matmul.sv /root/.mase/top/hardware/rtl/skid_buffer.sv /root/.mase/top/hardware/rtl/matrix_stream_transpose.sv /root/.mase/top/hardware/rtl/unpacked_skid_buffer.sv /root/.mase/top/hardware/rtl/fixed_leakyrelu.sv /root/.mase/top/hardware/rtl/fixed_accumulator.sv /root/.mase/top/hardware/rtl/fixed_vector_mult.sv /root/.mase/top/hardware/rtl/matrix_flatten.sv /root/.mase/top/hardware/rtl/fixed_dot_product.sv /root/.mase/top/hardware/rtl/padding.sv /root/.mase/top/hardware/rtl/fixed_cast.sv /root/.mase/top/hardware/rtl/roller.sv /root/.mase/top/hardware/rtl/fixed_mult.sv /root/.mase/top/hardware/rtl/signed_clamp.sv in directory /workspace/docs/labs/sim_build\n",
      "INFO: Running command make -C /workspace/docs/labs/sim_build -f Vtop.mk in directory /workspace/docs/labs/sim_build\n",
      "make: Entering directory '/workspace/docs/labs/sim_build'\n",
      "ccache g++  -I.  -MMD -I/usr/local/share/verilator/include -I/usr/local/share/verilator/include/vltstd -DVM_COVERAGE=0 -DVM_SC=0 -DVM_TRACE=1 -DVM_TRACE_FST=1 -DVM_TRACE_VCD=0 -faligned-new -fcf-protection=none -Wno-bool-operation -Wno-overloaded-virtual -Wno-shadow -Wno-sign-compare -Wno-uninitialized -Wno-unused-but-set-parameter -Wno-unused-but-set-variable -Wno-unused-parameter -Wno-unused-variable       -Os -c -o verilator.o /usr/local/lib/python3.11/dist-packages/cocotb/share/lib/verilator/verilator.cpp\n",
      "ccache g++ -Os  -I.  -MMD -I/usr/local/share/verilator/include -I/usr/local/share/verilator/include/vltstd -DVM_COVERAGE=0 -DVM_SC=0 -DVM_TRACE=1 -DVM_TRACE_FST=1 -DVM_TRACE_VCD=0 -faligned-new -fcf-protection=none -Wno-bool-operation -Wno-overloaded-virtual -Wno-shadow -Wno-sign-compare -Wno-uninitialized -Wno-unused-but-set-parameter -Wno-unused-but-set-variable -Wno-unused-parameter -Wno-unused-variable       -c -o verilated.o /usr/local/share/verilator/include/verilated.cpp\n",
      "ccache g++ -Os  -I.  -MMD -I/usr/local/share/verilator/include -I/usr/local/share/verilator/include/vltstd -DVM_COVERAGE=0 -DVM_SC=0 -DVM_TRACE=1 -DVM_TRACE_FST=1 -DVM_TRACE_VCD=0 -faligned-new -fcf-protection=none -Wno-bool-operation -Wno-overloaded-virtual -Wno-shadow -Wno-sign-compare -Wno-uninitialized -Wno-unused-but-set-parameter -Wno-unused-but-set-variable -Wno-unused-parameter -Wno-unused-variable       -c -o verilated_dpi.o /usr/local/share/verilator/include/verilated_dpi.cpp\n",
      "ccache g++ -Os  -I.  -MMD -I/usr/local/share/verilator/include -I/usr/local/share/verilator/include/vltstd -DVM_COVERAGE=0 -DVM_SC=0 -DVM_TRACE=1 -DVM_TRACE_FST=1 -DVM_TRACE_VCD=0 -faligned-new -fcf-protection=none -Wno-bool-operation -Wno-overloaded-virtual -Wno-shadow -Wno-sign-compare -Wno-uninitialized -Wno-unused-but-set-parameter -Wno-unused-but-set-variable -Wno-unused-parameter -Wno-unused-variable       -c -o verilated_vpi.o /usr/local/share/verilator/include/verilated_vpi.cpp\n",
      "ccache g++ -Os  -I.  -MMD -I/usr/local/share/verilator/include -I/usr/local/share/verilator/include/vltstd -DVM_COVERAGE=0 -DVM_SC=0 -DVM_TRACE=1 -DVM_TRACE_FST=1 -DVM_TRACE_VCD=0 -faligned-new -fcf-protection=none -Wno-bool-operation -Wno-overloaded-virtual -Wno-shadow -Wno-sign-compare -Wno-uninitialized -Wno-unused-but-set-parameter -Wno-unused-but-set-variable -Wno-unused-parameter -Wno-unused-variable       -c -o verilated_fst_c.o /usr/local/share/verilator/include/verilated_fst_c.cpp\n",
      "ccache g++ -Os  -I.  -MMD -I/usr/local/share/verilator/include -I/usr/local/share/verilator/include/vltstd -DVM_COVERAGE=0 -DVM_SC=0 -DVM_TRACE=1 -DVM_TRACE_FST=1 -DVM_TRACE_VCD=0 -faligned-new -fcf-protection=none -Wno-bool-operation -Wno-overloaded-virtual -Wno-shadow -Wno-sign-compare -Wno-uninitialized -Wno-unused-but-set-parameter -Wno-unused-but-set-variable -Wno-unused-parameter -Wno-unused-variable       -c -o verilated_threads.o /usr/local/share/verilator/include/verilated_threads.cpp\n",
      "/usr/bin/python3 /usr/local/share/verilator/bin/verilator_includer -DVL_INCLUDE_OPT=include Vtop.cpp Vtop___024root__DepSet_h84412442__0.cpp Vtop___024root__DepSet_heccd7ead__0.cpp Vtop__Dpi.cpp Vtop__Trace__0.cpp Vtop__ConstPool_0.cpp Vtop___024root__Slow.cpp Vtop___024root__DepSet_h84412442__0__Slow.cpp Vtop___024root__DepSet_heccd7ead__0__Slow.cpp Vtop__Syms.cpp Vtop__Trace__0__Slow.cpp Vtop__TraceDecls__0__Slow.cpp > Vtop__ALL.cpp\n",
      "ccache g++ -Os  -I.  -MMD -I/usr/local/share/verilator/include -I/usr/local/share/verilator/include/vltstd -DVM_COVERAGE=0 -DVM_SC=0 -DVM_TRACE=1 -DVM_TRACE_FST=1 -DVM_TRACE_VCD=0 -faligned-new -fcf-protection=none -Wno-bool-operation -Wno-overloaded-virtual -Wno-shadow -Wno-sign-compare -Wno-uninitialized -Wno-unused-but-set-parameter -Wno-unused-but-set-variable -Wno-unused-parameter -Wno-unused-variable       -c -o Vtop__ALL.o Vtop__ALL.cpp\n",
      "Archive ar -rcs Vtop__ALL.a Vtop__ALL.o\n",
      "g++     verilator.o verilated.o verilated_dpi.o verilated_vpi.o verilated_fst_c.o verilated_threads.o Vtop__ALL.a   -Wl,-rpath,/usr/local/lib/python3.11/dist-packages/cocotb/libs -L/usr/local/lib/python3.11/dist-packages/cocotb/libs -lcocotbvpi_verilator -lz  -pthread -lpthread -latomic   -o top\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mBuild finished. Time taken: 10.53s\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make: Leaving directory '/workspace/docs/labs/sim_build'\n",
      "cmd: [['/workspace/docs/labs/sim_build/top']]\n",
      "INFO: Running command /workspace/docs/labs/sim_build/top in directory /workspace/docs/labs/sim_build\n",
      "     -.--ns INFO     gpi                                ..mbed/gpi_embed.cpp:76   in set_program_name_in_venv        Did not detect Python virtual environment. Using system-wide Python interpreter\n",
      "     -.--ns INFO     gpi                                ../gpi/GpiCommon.cpp:101  in gpi_print_registered_impl       VPI registered\n",
      "     0.00ns INFO     cocotb                             Running on Verilator version 5.020 2024-01-01\n",
      "     0.00ns INFO     cocotb                             Running tests with cocotb v1.8.0 from /usr/local/lib/python3.11/dist-packages/cocotb\n",
      "     0.00ns INFO     cocotb                             Seeding Python random module with 1741207555\n",
      "     0.00ns INFO     cocotb.regression                  Found test mase_top_tb.test.test\n",
      "     0.00ns INFO     cocotb.regression                  running test (1/1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/src/mase_cocotb/driver.py:25: DeprecationWarning: This method is now private.\n",
      "  self._thread = cocotb.scheduler.add(self._send_thread())\n",
      "/workspace/src/mase_cocotb/monitor.py:27: DeprecationWarning: This method is now private.\n",
      "  self._thread = cocotb.scheduler.add(self._recv_thread())\n",
      "[W305 20:46:05.285489035 NNPACK.cpp:62] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nihap in generate_inputs\n",
      "inputs in generate_inputs: {'data_in_0': tensor([[[[0.4963, 0.7682, 0.0885],\n",
      "          [0.1320, 0.3074, 0.6341],\n",
      "          [0.4901, 0.8964, 0.4556]]]])}\n",
      "          0\n",
      "          2\n",
      "         14\n",
      "         16\n",
      "in_tensors:  {'data_in_0': tensor([[[[0.4963, 0.7682, 0.0885],\n",
      "          [0.1320, 0.3074, 0.6341],\n",
      "          [0.4901, 0.8964, 0.4556]]]])}\n",
      "GraphModule(\n",
      "  (conv1): Conv2dInteger(1, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "def forward(self, x):\n",
      "    conv1 = self.conv1(x);  x = None\n",
      "    return conv1\n",
      "    \n",
      "# To see more debug info, please use `graph_module.print_readable()`\n",
      "exp_out:  tensor([[[[-0.5674, -0.5020, -0.3945],\n",
      "          [-0.5088, -0.6406, -0.4854],\n",
      "          [-0.3857, -0.1484, -0.0703]],\n",
      "\n",
      "         [[-0.0225, -0.1748, -0.1553],\n",
      "          [ 0.1963,  0.3086,  0.0010],\n",
      "          [ 0.0654, -0.0283, -0.2725]]]], grad_fn=<ConvolutionBackward0>)\n",
      "load_drivers in emit_tb.py\n",
      "arg in load_drivers in emit_tb:  data_in_0\n",
      "arg_batch in load_drivers in emit_tb:  tensor([[[[0.4963, 0.7682, 0.0885],\n",
      "          [0.1320, 0.3074, 0.6341],\n",
      "          [0.4901, 0.8964, 0.4556]]]])\n",
      "in_data_blocks: [[15, 24, 2, 4, 9, 20, 15, 28, 14]]\n",
      "self.input_drivers in load_drivers: {'data_in_0': <mase_cocotb.interfaces.streaming.StreamDriver object at 0x7ffff8308a50>}\n",
      "    60.00ns DEBUG    cocotb.driver.StreamDriver         Sent from streamping.py StreamDriver [15, 24, 2, 4, 9, 20, 15, 28, 14]\n",
      "2000020.00ns INFO     cocotb.regression                  test failed\n",
      "                                                         Traceback (most recent call last):\n",
      "                                                           File \"/root/.mase/top/hardware/test/mase_top_tb/test.py\", line 28, in test\n",
      "                                                             await tb.wait_end(timeout=2, timeout_unit=\"ms\")\n",
      "                                                           File \"/workspace/src/mase_cocotb/testbench.py\", line 76, in wait_end\n",
      "                                                             raise TimeoutError(\"Timed out waiting for test to end.\")\n",
      "                                                         TimeoutError: Timed out waiting for test to end.\n",
      "2000020.00ns INFO     cocotb.regression                  **************************************************************************************\n",
      "                                                         ** TEST                          STATUS  SIM TIME (ns)  REAL TIME (s)  RATIO (ns/s) **\n",
      "                                                         **************************************************************************************\n",
      "                                                         ** mase_top_tb.test.test          FAIL     2000020.00          16.90     118327.24  **\n",
      "                                                         **************************************************************************************\n",
      "                                                         ** TESTS=1 PASS=0 FAIL=1 SKIP=0            2000020.00          17.18     116445.91  **\n",
      "                                                         **************************************************************************************\n",
      "                                                         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.11/tempfile.py:1073: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmp7ex_z0qw'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTest finished. Time taken: 18.57s\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- :0: Verilog $finish\n",
      "INFO: Results file: /workspace/docs/labs/sim_build/results.xml\n"
     ]
    }
   ],
   "source": [
    "from chop.actions import simulate\n",
    "\n",
    "simulate(skip_build=False, skip_test=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
