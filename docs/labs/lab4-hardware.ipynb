{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />\n",
    "<div align=\"center\">\n",
    "  <a href=\"https://deepwok.github.io/\">\n",
    "    <img src=\"../imgs/deepwok.png\" alt=\"Logo\" width=\"160\" height=\"160\">\n",
    "  </a>\n",
    "\n",
    "  <h1 align=\"center\">Lab 4 for Advanced Deep Learning Systems (ADLS) - Hardware Stream</h1>\n",
    "\n",
    "  <p align=\"center\">\n",
    "    ELEC70109/EE9-AML3-10/EE9-AO25\n",
    "    <br />\n",
    "\t\tWritten by\n",
    "    <a href=\"https://aaron-zhao123.github.io/\">Aaron Zhao, Pedro Gimenes </a>\n",
    "  </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General introduction\n",
    "\n",
    "In this lab, you will learn how to emit SystemVerilog code for a neural network that's been transformed and optimized by MASE. Then, you'll design some hardware for a new Pytorch layer, and simulate the hardware using your new module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Hardware Emit pass\n",
    "\n",
    "The `emit_verilog` transform pass generates a top-level RTL file and testbench file according to the `MaseGraph`, which includes a hardware implementation of each layer in the network. This top-level file instantiates modules from the `components` library in MASE and/or modules generated using [HLS](https://en.wikipedia.org/wiki/High-level_synthesis), when internal components are not available. The hardware can then be simulated using [Verilator](https://www.veripool.org/verilator/), or deployed on an FPGA.\n",
    "\n",
    "First, add Machop to your system PATH (if you haven't already done so) and import the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mSet logging level to debug\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage:\n",
      "        verilator --help\n",
      "        verilator --version\n",
      "        verilator --binary -j 0 [options] [source_files.v]... [opt_c_files.cpp/c/cc/a/o/so]\n",
      "        verilator --cc [options] [source_files.v]... [opt_c_files.cpp/c/cc/a/o/so]\n",
      "        verilator --sc [options] [source_files.v]... [opt_c_files.cpp/c/cc/a/o/so]\n",
      "        verilator --lint-only -Wall [source_files.v]...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "\n",
    "from chop.ir.graph.mase_graph import MaseGraph\n",
    "\n",
    "from chop.passes.graph.analysis import (\n",
    "    init_metadata_analysis_pass,\n",
    "    add_common_metadata_analysis_pass,\n",
    "    add_hardware_metadata_analysis_pass,\n",
    "    add_software_metadata_analysis_pass,\n",
    "    report_node_type_analysis_pass,\n",
    ")\n",
    "\n",
    "from chop.passes.graph.transforms import (\n",
    "    emit_verilog_top_transform_pass,\n",
    "    emit_internal_rtl_transform_pass,\n",
    "    emit_bram_transform_pass,\n",
    "    emit_cocotb_transform_pass,\n",
    "    quantize_transform_pass,\n",
    ")\n",
    "\n",
    "from chop.tools.logger import set_logging_verbosity\n",
    "\n",
    "set_logging_verbosity(\"debug\")\n",
    "\n",
    "import toml\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# TO DO: remove\n",
    "import os\n",
    "os.environ[\"PATH\"] = \"/opt/homebrew/bin:\" + os.environ[\"PATH\"]\n",
    "!verilator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, define the neural network. We're using a model which can be used to perform digit classification on the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Toy FC model for digit recognition on MNIST\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(16, 16)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, start_dim=1, end_dim=-1)\n",
    "        x = torch.nn.functional.relu(self.fc1(x),inplace=False)\n",
    "        # x = torch.nn.functional.leaky_relu(self.fc1(x),negative_slope=0.5,inplace=False)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def float_to_fixed(x, scaling_factor, total_bits=8):\n",
    "    \"\"\"\n",
    "    Convert a floating-point numpy array to fixed-point representation.\n",
    "\n",
    "    Parameters:\n",
    "      x            : numpy array of floats.\n",
    "      scaling_factor: Factor to scale the float values (2^frac_bits).\n",
    "      total_bits   : Total number of bits (default is 8).\n",
    "\n",
    "    Returns:\n",
    "      A numpy array of type np.int8 representing the fixed-point values.\n",
    "    \"\"\"\n",
    "    # Scale the floating-point values.\n",
    "    x_scaled = x * scaling_factor\n",
    "\n",
    "    # Round to the nearest integer.\n",
    "    x_fixed = np.trunc(x_scaled)\n",
    "\n",
    "    # Define the representable range for signed 8-bit integers.\n",
    "    min_val = -2**(total_bits - 1)       # -128 for 8 bits\n",
    "    max_val = 2**(total_bits - 1) - 1      #  127 for 8 bits\n",
    "\n",
    "    # Clip values that exceed the representable range.\n",
    "    x_fixed = np.clip(x_fixed, min_val, max_val)\n",
    "\n",
    "    # Return as np.int8.\n",
    "    return x_fixed.astype(np.int8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "frac_bits = 8  # for example\n",
    "scale = 2 ** frac_bits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# weight_np = np.array([\n",
    "#     [-0.0037,  0.2682, -0.4115, -0.3680],\n",
    "#     [-0.1926,  0.1341, -0.0099,  0.3964],\n",
    "#     [-0.0444,  0.1323, -0.1511, -0.0983],\n",
    "#     [-0.4777, -0.3311, -0.2061,  0.0185],\n",
    "#     [ 0.1977,  0.3000, -0.3390, -0.2177],\n",
    "#     [ 0.1816,  0.4152, -0.1029,  0.3742],\n",
    "#     [-0.0806,  0.0529,  0.4527, -0.4638],\n",
    "#     [-0.3148, -0.1266, -0.1949,  0.4320]\n",
    "# ])  # shape (8,4)\n",
    "\n",
    "# bias_np = np.array([-0.3241, -0.2302, -0.3493, -0.4683,\n",
    "#                     -0.2919,  0.4298,  0.2231,  0.2423])  # shape (8,)\n",
    "\n",
    "# # Convert them to PyTorch tensors of the correct shape and dtype\n",
    "# weight_torch = torch.tensor(weight_np, dtype=torch.float32)\n",
    "# bias_torch   = torch.tensor(bias_np,   dtype=torch.float32)\n",
    "\n",
    "\n",
    "# model = MLP()\n",
    "\n",
    "# # Overwrite the linear layerâ€™s weight/bias data\n",
    "# # Note: PyTorch layers store weight/bias in .weight and .bias\n",
    "# with torch.no_grad():\n",
    "#     model.fc1.weight.copy_(weight_torch)\n",
    "#     model.fc1.bias.copy_(bias_torch)\n",
    "\n",
    "# # Input as a NumPy array, shape = (1, 4)\n",
    "# input_np = np.array([[0.4963, 0.7682, 0.0885, 0.1320]])\n",
    "\n",
    "# # Convert to PyTorch tensor\n",
    "# input_torch = torch.tensor(input_np, dtype=torch.float32)\n",
    "\n",
    "# # Forward pass\n",
    "# output = model(input_torch)\n",
    "# print(\"Output:\\n\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supported quantized engines: ['qnnpack', 'none', 'onednn']\n",
      "Current quantized engine:    onednn\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"Supported quantized engines:\", torch.backends.quantized.supported_engines)\n",
    "print(\"Current quantized engine:   \", torch.backends.quantized.engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll generate a MaseGraph and add metadata. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36mDEBUG   \u001b[0m \u001b[34mgraph():\n",
      "    %x : [num_users=1] = placeholder[target=x]\n",
      "    %flatten : [num_users=1] = call_function[target=torch.flatten](args = (%x,), kwargs = {start_dim: 1, end_dim: -1})\n",
      "    %fc1 : [num_users=1] = call_module[target=fc1](args = (%flatten,), kwargs = {})\n",
      "    %relu : [num_users=1] = call_function[target=torch.nn.functional.relu](args = (%fc1,), kwargs = {inplace: False})\n",
      "    return relu\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.2340,  0.7073,  0.5800,  0.2683],\n",
      "         [-2.0589,  0.5340, -0.5354, -0.8637],\n",
      "         [-0.0235,  1.1717,  0.3987, -0.1987],\n",
      "         [-1.1559, -0.3167,  0.9403, -1.1470]]])\n",
      "Hellos in add_common_metadata\n",
      "sigoyi in add_common_metadata\n",
      "nihhhhhhhhh in graph_iterator_for_mase_ops in add_common_metadata\n",
      "nihhhhhhhhh in graph_iterator_for_mase_ops in add_common_metadata\n",
      "graph_model:  GraphModule(\n",
      "  (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "def forward(self, x):\n",
      "    flatten = torch.flatten(x, start_dim = 1, end_dim = -1);  x = None\n",
      "    fc1 = self.fc1(flatten);  flatten = None\n",
      "    relu = torch.nn.functional.relu(fc1, inplace = False);  fc1 = None\n",
      "    return relu\n",
      "    \n",
      "# To see more debug info, please use `graph_module.print_readable()`\n",
      "wocao in add_common_metadata\n",
      "graph_iterator_for_metadata:  GraphModule(\n",
      "  (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "def forward(self, x):\n",
      "    flatten = torch.flatten(x, start_dim = 1, end_dim = -1);  x = None\n",
      "    fc1 = self.fc1(flatten);  flatten = None\n",
      "    relu = torch.nn.functional.relu(fc1, inplace = False);  fc1 = None\n",
      "    return relu\n",
      "    \n",
      "# To see more debug info, please use `graph_module.print_readable()`\n",
      "kwargs:  {'start_dim': 1, 'end_dim': -1}\n",
      "args in call_module:  (tensor([[-0.2340,  0.7073,  0.5800,  0.2683, -2.0589,  0.5340, -0.5354, -0.8637,\n",
      "         -0.0235,  1.1717,  0.3987, -0.1987, -1.1559, -0.3167,  0.9403, -1.1470]]),)\n",
      "kwargs in call_module:  {}\n",
      "HIIII from analyse_common_parameters_module\n",
      "args from analyse_common_parameters_module (tensor([[-0.2340,  0.7073,  0.5800,  0.2683, -2.0589,  0.5340, -0.5354, -0.8637,\n",
      "         -0.0235,  1.1717,  0.3987, -0.1987, -1.1559, -0.3167,  0.9403, -1.1470]]),)\n",
      "kwargs from analyse_common_parameters_module {}\n",
      "meta before _annotate_arg_metadata: {'mase_type': 'module_related_func', 'mase_op': 'linear'}\n",
      "kwargs:  {}\n",
      "meta after _annotate_arg_metadata: {'mase_type': 'module_related_func', 'mase_op': 'linear', 'args': OrderedDict([('data_in_0', {'shape': [1, 16], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]})])}\n",
      "meta after get_type_and_precision: {'mase_type': 'module_related_func', 'mase_op': 'linear', 'args': OrderedDict([('data_in_0', {'shape': [1, 16], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]})])}\n",
      "weight\n",
      "bias\n",
      "meta after for: {'mase_type': 'module_related_func', 'mase_op': 'linear', 'args': OrderedDict([('data_in_0', {'shape': [1, 16], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]}), ('weight', {'type': 'float', 'precision': [32], 'shape': [16, 16], 'from': None}), ('bias', {'type': 'float', 'precision': [32], 'shape': [1, 16], 'from': None})])}\n",
      "kwargs:  {'inplace': False}\n",
      "wobucao in add_common_metadata\n",
      "nihappp in add_common_metadata\n"
     ]
    }
   ],
   "source": [
    "mlp = MLP()\n",
    "mg = MaseGraph(model=mlp)\n",
    "\n",
    "# Provide a dummy input for the graph so it can use for tracing\n",
    "batch_size = 1\n",
    "x = torch.randn((batch_size, 4, 4))\n",
    "print(x)\n",
    "dummy_in = {\"x\": x}\n",
    "\n",
    "mg, _ = init_metadata_analysis_pass(mg, None)\n",
    "mg, _ = add_common_metadata_analysis_pass(\n",
    "    mg, {\"dummy_in\": dummy_in, \"add_value\": False}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running `emit_verilog`, we'll quantize the model to fixed precision. Refer back to [lab 3](https://deepwok.github.io/mase/modules/labs_2023/lab3.html) if you've forgotten how this works. Check that the data type for each node is correct after quantization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mInspecting graph [add_common_node_type_analysis_pass]\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Node name    Fx Node op     Mase type            Mase op      Value type\n",
      "-----------  -------------  -------------------  -----------  ------------\n",
      "x            placeholder    placeholder          placeholder  NA\n",
      "flatten      call_function  implicit_func        flatten      float\n",
      "fc1          call_module    module_related_func  linear       fixed\n",
      "relu         call_function  module_related_func  relu         fixed\n",
      "output       output         output               output       NA\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "placeholder\n",
      "flatten\n",
      "node_config:  {'name': 'fixed', 'data_in_width': 8, 'data_in_frac_width': 5, 'weight_width': 8, 'weight_frac_width': 5, 'bias_width': 8, 'bias_frac_width': 5, 'data_out_width': 8, 'data_out_frac_width': 5, 'floor': True}\n",
      "node_config:  {'name': 'fixed', 'data_in_width': 8, 'data_in_frac_width': 5, 'weight_width': 8, 'weight_frac_width': 5, 'bias_width': 8, 'bias_frac_width': 5, 'data_out_width': 8, 'data_out_frac_width': 5, 'floor': True}\n",
      "output\n"
     ]
    }
   ],
   "source": [
    "config_file = os.path.join(\n",
    "    os.path.abspath(\"\"),\n",
    "    \"..\",\n",
    "    \"..\",\n",
    "    \"configs\",\n",
    "    \"tests\",\n",
    "    \"quantize\",\n",
    "    \"fixed.toml\",\n",
    ")\n",
    "with open(config_file, \"r\") as f:\n",
    "    quan_args = toml.load(f)[\"passes\"][\"quantize\"]\n",
    "mg, _ = quantize_transform_pass(mg, quan_args)\n",
    "\n",
    "_ = report_node_type_analysis_pass(mg)\n",
    "\n",
    "# Update the metadata\n",
    "for node in mg.fx_graph.nodes:\n",
    "    for arg, arg_info in node.meta[\"mase\"][\"common\"][\"args\"].items():\n",
    "        if isinstance(arg_info, dict):\n",
    "            arg_info[\"type\"] = \"fixed\"\n",
    "            arg_info[\"precision\"] = [8, 5]\n",
    "    for result, result_info in node.meta[\"mase\"][\"common\"][\"results\"].items():\n",
    "        if isinstance(result_info, dict):\n",
    "            result_info[\"type\"] = \"fixed\"\n",
    "            result_info[\"precision\"] = [8, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, it's important to run the `add_hardware_metadata` analysis pass. This adds all the required metadata which is later used by the `emit_verilog` pass, including:\n",
    "\n",
    "1. The node's toolchain, which defines whether we use internal Verilog modules from the `components` library or the HLS flow.\n",
    "2. The Verilog parameters associated with each node.\n",
    "\n",
    "> **_TASK:_** Read [this page](https://deepwok.github.io/mase/modules/chop/analysis/add_metadata.html#add-hardware-metadata-analysis-pass) for more information on the hardware metadata pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mase_op: linear\n",
      "2222\n",
      "mase_op: relu\n",
      "2222\n",
      "vp:  {}\n",
      "arg in add_verilog_param: data_in_0\n",
      "vp after for:  {'DATA_IN_0_PRECISION_0': 8, 'DATA_IN_0_PRECISION_1': 5, 'DATA_IN_0_TENSOR_SIZE_DIM_0': 16, 'DATA_IN_0_PARALLELISM_DIM_0': 4, 'DATA_IN_0_TENSOR_SIZE_DIM_1': 1, 'DATA_IN_0_PARALLELISM_DIM_1': 1}\n",
      "arg in add_verilog_param: weight\n",
      "vp after for:  {'DATA_IN_0_PRECISION_0': 8, 'DATA_IN_0_PRECISION_1': 5, 'DATA_IN_0_TENSOR_SIZE_DIM_0': 16, 'DATA_IN_0_PARALLELISM_DIM_0': 4, 'DATA_IN_0_TENSOR_SIZE_DIM_1': 1, 'DATA_IN_0_PARALLELISM_DIM_1': 1, 'WEIGHT_PRECISION_0': 8, 'WEIGHT_PRECISION_1': 5, 'WEIGHT_TENSOR_SIZE_DIM_0': 16, 'WEIGHT_PARALLELISM_DIM_0': 4, 'WEIGHT_TENSOR_SIZE_DIM_1': 16, 'WEIGHT_PARALLELISM_DIM_1': 4}\n",
      "arg in add_verilog_param: bias\n",
      "vp after for:  {'DATA_IN_0_PRECISION_0': 8, 'DATA_IN_0_PRECISION_1': 5, 'DATA_IN_0_TENSOR_SIZE_DIM_0': 16, 'DATA_IN_0_PARALLELISM_DIM_0': 4, 'DATA_IN_0_TENSOR_SIZE_DIM_1': 1, 'DATA_IN_0_PARALLELISM_DIM_1': 1, 'WEIGHT_PRECISION_0': 8, 'WEIGHT_PRECISION_1': 5, 'WEIGHT_TENSOR_SIZE_DIM_0': 16, 'WEIGHT_PARALLELISM_DIM_0': 4, 'WEIGHT_TENSOR_SIZE_DIM_1': 16, 'WEIGHT_PARALLELISM_DIM_1': 4, 'BIAS_PRECISION_0': 8, 'BIAS_PRECISION_1': 5, 'BIAS_TENSOR_SIZE_DIM_0': 16, 'BIAS_PARALLELISM_DIM_0': 4, 'BIAS_TENSOR_SIZE_DIM_1': 1, 'BIAS_PARALLELISM_DIM_1': 1}\n",
      "result in add_verilog_param: data_out_0\n",
      "result_info in add_verilog_param: {'type': 'fixed', 'precision': [8, 5], 'shape': [1, 16], 'torch_dtype': torch.float32}\n",
      "vp:  {}\n",
      "arg in add_verilog_param: data_in_0\n",
      "vp after for:  {'DATA_IN_0_PRECISION_0': 8, 'DATA_IN_0_PRECISION_1': 5, 'DATA_IN_0_TENSOR_SIZE_DIM_0': 16, 'DATA_IN_0_PARALLELISM_DIM_0': 4, 'DATA_IN_0_TENSOR_SIZE_DIM_1': 1, 'DATA_IN_0_PARALLELISM_DIM_1': 1}\n",
      "vp after for:  {'DATA_IN_0_PRECISION_0': 8, 'DATA_IN_0_PRECISION_1': 5, 'DATA_IN_0_TENSOR_SIZE_DIM_0': 16, 'DATA_IN_0_PARALLELISM_DIM_0': 4, 'DATA_IN_0_TENSOR_SIZE_DIM_1': 1, 'DATA_IN_0_PARALLELISM_DIM_1': 1, 'INPLACE': 0}\n",
      "result in add_verilog_param: data_out_0\n",
      "result_info in add_verilog_param: {'type': 'fixed', 'precision': [8, 5], 'shape': [1, 16], 'torch_dtype': torch.float32}\n",
      "mase_op: placeholder\n",
      "common: {'mase_type': 'placeholder', 'mase_op': 'placeholder', 'args': {}, 'results': OrderedDict([('data_out_0', {'type': 'fixed', 'precision': [8, 5], 'shape': [1, 4, 4], 'torch_dtype': torch.float32})])}\n",
      "hardware: {'is_implicit': True, 'device_id': 0, 'max_parallelism': [4, 4, 4, 4]}\n",
      "mase_op: flatten\n",
      "common: {'mase_type': 'implicit_func', 'mase_op': 'flatten', 'results': OrderedDict([('data_out_0', {'type': 'fixed', 'precision': [8, 5], 'shape': [1, 16], 'torch_dtype': torch.float32})]), 'args': OrderedDict([('data_in_0', {'shape': [1, 4, 4], 'torch_dtype': torch.float32, 'type': 'fixed', 'precision': [8, 5]}), ('start_dim', {'type': 'fixed', 'precision': [8, 5], 'shape': [1]}), ('end_dim', {'type': 'fixed', 'precision': [8, 5], 'shape': [1]})])}\n",
      "hardware: {'is_implicit': True, 'device_id': 0, 'max_parallelism': [4, 4, 4, 4]}\n",
      "mase_op: linear\n",
      "common: {'mase_type': 'module_related_func', 'mase_op': 'linear', 'args': OrderedDict([('data_in_0', {'shape': [1, 16], 'torch_dtype': torch.float32, 'type': 'fixed', 'precision': [8, 5]}), ('weight', {'type': 'fixed', 'precision': [8, 5], 'shape': [16, 16], 'from': None}), ('bias', {'type': 'fixed', 'precision': [8, 5], 'shape': [1, 16], 'from': None})]), 'results': OrderedDict([('data_out_0', {'type': 'fixed', 'precision': [8, 5], 'shape': [1, 16], 'torch_dtype': torch.float32})])}\n",
      "hardware: {'is_implicit': False, 'device_id': -1, 'interface': {'weight': {'storage': 'BRAM', 'transpose': False}, 'bias': {'storage': 'BRAM', 'transpose': False}}, 'toolchain': 'INTERNAL_RTL', 'module': 'fixed_linear', 'dependence_files': ['cast/rtl/fixed_cast.sv', 'linear_layers/fixed_operators/rtl/fixed_dot_product.sv', 'linear_layers/fixed_operators/rtl/fixed_vector_mult.sv', 'linear_layers/fixed_operators/rtl/fixed_accumulator.sv', 'linear_layers/fixed_operators/rtl/fixed_adder_tree.sv', 'linear_layers/fixed_operators/rtl/fixed_adder_tree_layer.sv', 'linear_layers/fixed_operators/rtl/fixed_mult.sv', 'common/rtl/register_slice.sv', 'common/rtl/join2.sv', 'memory/rtl/unpacked_repeat_circular_buffer.sv', 'memory/rtl/skid_buffer.sv', 'linear_layers/fixed_linear_layer/rtl/fixed_linear.sv', 'linear_layers/matmul/rtl/matrix_flatten.sv', 'linear_layers/matmul/rtl/matrix_unflatten.sv', 'linear_layers/matmul/rtl/matrix_fifo.sv', 'linear_layers/matmul/rtl/matrix_accumulator.sv', 'linear_layers/matmul/rtl/simple_matmul.sv', 'linear_layers/matmul/rtl/matmul.sv', 'linear_layers/matmul/rtl/transpose.sv', 'linear_layers/matmul/rtl/matrix_stream_transpose.sv'], 'max_parallelism': [4, 4, 4, 4], 'verilog_param': {'DATA_IN_0_PRECISION_0': 8, 'DATA_IN_0_PRECISION_1': 5, 'DATA_IN_0_TENSOR_SIZE_DIM_0': 16, 'DATA_IN_0_PARALLELISM_DIM_0': 4, 'DATA_IN_0_TENSOR_SIZE_DIM_1': 1, 'DATA_IN_0_PARALLELISM_DIM_1': 1, 'WEIGHT_PRECISION_0': 8, 'WEIGHT_PRECISION_1': 5, 'WEIGHT_TENSOR_SIZE_DIM_0': 16, 'WEIGHT_PARALLELISM_DIM_0': 4, 'WEIGHT_TENSOR_SIZE_DIM_1': 16, 'WEIGHT_PARALLELISM_DIM_1': 4, 'BIAS_PRECISION_0': 8, 'BIAS_PRECISION_1': 5, 'BIAS_TENSOR_SIZE_DIM_0': 16, 'BIAS_PARALLELISM_DIM_0': 4, 'BIAS_TENSOR_SIZE_DIM_1': 1, 'BIAS_PARALLELISM_DIM_1': 1, 'DATA_OUT_0_PRECISION_0': 8, 'DATA_OUT_0_PRECISION_1': 5, 'DATA_OUT_0_TENSOR_SIZE_DIM_0': 16, 'DATA_OUT_0_PARALLELISM_DIM_0': 4, 'DATA_OUT_0_TENSOR_SIZE_DIM_1': 1, 'DATA_OUT_0_PARALLELISM_DIM_1': 1}}\n",
      "mase_op: relu\n",
      "common: {'mase_type': 'module_related_func', 'mase_op': 'relu', 'results': OrderedDict([('data_out_0', {'type': 'fixed', 'precision': [8, 5], 'shape': [1, 16], 'torch_dtype': torch.float32})]), 'args': OrderedDict([('data_in_0', {'shape': [1, 16], 'torch_dtype': torch.float32, 'type': 'fixed', 'precision': [8, 5]}), ('inplace', False)])}\n",
      "hardware: {'is_implicit': False, 'device_id': -1, 'interface': {'inplace': {}}, 'toolchain': 'INTERNAL_RTL', 'module': 'fixed_relu', 'dependence_files': ['activation_layers/rtl/fixed_relu.sv'], 'max_parallelism': [4, 4, 4, 4], 'verilog_param': {'DATA_IN_0_PRECISION_0': 8, 'DATA_IN_0_PRECISION_1': 5, 'DATA_IN_0_TENSOR_SIZE_DIM_0': 16, 'DATA_IN_0_PARALLELISM_DIM_0': 4, 'DATA_IN_0_TENSOR_SIZE_DIM_1': 1, 'DATA_IN_0_PARALLELISM_DIM_1': 1, 'INPLACE': 0, 'DATA_OUT_0_PRECISION_0': 8, 'DATA_OUT_0_PRECISION_1': 5, 'DATA_OUT_0_TENSOR_SIZE_DIM_0': 16, 'DATA_OUT_0_PARALLELISM_DIM_0': 4, 'DATA_OUT_0_TENSOR_SIZE_DIM_1': 1, 'DATA_OUT_0_PARALLELISM_DIM_1': 1}}\n",
      "mase_op: output\n",
      "common: {'mase_type': 'output', 'mase_op': 'output', 'args': {}, 'results': OrderedDict([('data_out_0', {'type': 'fixed', 'precision': [8, 5], 'shape': [1, 16], 'torch_dtype': torch.float32})])}\n",
      "hardware: {'is_implicit': True, 'device_id': 0, 'max_parallelism': [4, 4, 4, 4]}\n",
      "param_name in CNN.jynb: weight\n",
      "parameter in CNN.jynb: Parameter containing:\n",
      "tensor([[-0.0019,  0.1341, -0.2058, -0.1840, -0.0963,  0.0670, -0.0050,  0.1982,\n",
      "         -0.0222,  0.0662, -0.0756, -0.0491, -0.2388, -0.1656, -0.1031,  0.0093],\n",
      "        [ 0.0988,  0.1500, -0.1695, -0.1089,  0.0908,  0.2076, -0.0515,  0.1871,\n",
      "         -0.0403,  0.0265,  0.2264, -0.2319, -0.1574, -0.0633, -0.0974,  0.2160],\n",
      "        [-0.1620, -0.1151, -0.1747, -0.2341, -0.1459,  0.2149,  0.1116,  0.1212,\n",
      "          0.0131, -0.1282,  0.0423, -0.2334, -0.1806, -0.1289,  0.1577,  0.1466],\n",
      "        [-0.1109, -0.0090,  0.1599,  0.2485,  0.0992,  0.0338,  0.1676, -0.1472,\n",
      "          0.0466, -0.1938, -0.1733, -0.1291,  0.1131,  0.1005, -0.1481,  0.0755],\n",
      "        [ 0.1372, -0.0316,  0.0095,  0.0579,  0.1551,  0.2400, -0.1927, -0.0916,\n",
      "          0.0983,  0.2071,  0.2176,  0.2206,  0.0498, -0.2174,  0.0230, -0.1564],\n",
      "        [-0.2330,  0.2221,  0.1901, -0.2494,  0.0468, -0.0421, -0.0411, -0.1144,\n",
      "          0.0961, -0.1481,  0.0916,  0.1264,  0.1790,  0.0935, -0.2474, -0.1622],\n",
      "        [ 0.1248,  0.0523, -0.1950, -0.1440,  0.2352,  0.1685, -0.1090, -0.0629,\n",
      "         -0.2381, -0.0045, -0.1883, -0.1928, -0.0138,  0.0375, -0.1024,  0.1483],\n",
      "        [-0.1521,  0.2268,  0.1713, -0.2108, -0.0622,  0.0113,  0.0365,  0.0593,\n",
      "          0.0981,  0.0150, -0.1220,  0.1183, -0.2398, -0.1482, -0.0626, -0.1218],\n",
      "        [-0.0875, -0.2049, -0.0532,  0.0534, -0.1629, -0.0128,  0.1790, -0.0257,\n",
      "          0.0069, -0.0216,  0.0506,  0.1590,  0.2368,  0.1588,  0.2374, -0.0181],\n",
      "        [-0.2246, -0.1185,  0.1702, -0.0016, -0.1243, -0.1916, -0.2340, -0.2110,\n",
      "         -0.0507,  0.1371,  0.1352, -0.2411,  0.1559, -0.1956, -0.0529, -0.1014],\n",
      "        [-0.0482, -0.0491, -0.2243, -0.2159, -0.0391,  0.0032, -0.1136,  0.0942,\n",
      "         -0.2250, -0.0169,  0.2199, -0.1020,  0.2258,  0.0905, -0.2256,  0.1582],\n",
      "        [-0.0288, -0.1116,  0.1999, -0.2020,  0.0268, -0.0523,  0.1785,  0.0698,\n",
      "          0.1201,  0.0883, -0.0601, -0.0526, -0.2060,  0.1355,  0.1985,  0.1711],\n",
      "        [-0.1763,  0.0111, -0.1762, -0.1376, -0.1457,  0.0854, -0.1490, -0.0055,\n",
      "          0.0105,  0.1612, -0.1890, -0.1716, -0.1452,  0.1750, -0.0899,  0.2109],\n",
      "        [ 0.0904,  0.0317, -0.0019, -0.0494,  0.0314, -0.0571, -0.0018,  0.0319,\n",
      "         -0.1956, -0.1310,  0.2019, -0.2029, -0.0180,  0.2473,  0.0903,  0.0071],\n",
      "        [-0.2167,  0.1238, -0.1781, -0.0710, -0.0839, -0.0370,  0.0027,  0.2062,\n",
      "          0.0312,  0.2239,  0.1529, -0.1581,  0.1121, -0.1767, -0.1060,  0.0735],\n",
      "        [ 0.0825,  0.1876, -0.0805,  0.0004,  0.1287, -0.2418,  0.1807, -0.2067,\n",
      "          0.0034, -0.0425, -0.1317,  0.0330,  0.2067, -0.0731, -0.1484, -0.0925]],\n",
      "       requires_grad=True)\n",
      "param_name in CNN.jynb: bias\n",
      "parameter in CNN.jynb: Parameter containing:\n",
      "tensor([-0.2478,  0.1128, -0.1201, -0.1668, -0.1440,  0.1437,  0.1324,  0.1919,\n",
      "         0.0907, -0.0835, -0.0699,  0.0739,  0.2055,  0.0680, -0.1183, -0.1175],\n",
      "       requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nweights and bias in the Conv/linear in Maze\\nparam_data = node.meta[\"mase\"].module.get_parameter(param_name).data\\nprint (\"param_data: \", param_data)\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mg, _ = add_hardware_metadata_analysis_pass(mg)\n",
    "for node in mg.nodes:\n",
    "        mase_op = node.meta[\"mase\"][\"common\"][\"mase_op\"]\n",
    "        print ('mase_op:', mase_op)\n",
    "        print (\"common:\",node.meta[\"mase\"][\"common\"])\n",
    "        print (\"hardware:\",node.meta[\"mase\"][\"hardware\"])\n",
    "\n",
    "for node in mg.fx_graph.nodes:\n",
    "        if node.meta[\"mase\"].parameters[\"hardware\"][\"is_implicit\"]:\n",
    "            continue\n",
    "        # Only modules have internal parameters\n",
    "        if node.meta[\"mase\"].module is None:\n",
    "            continue\n",
    "        # print (node.meta[\"mase\"].parameters[\"hardware\"])\n",
    "        # Only checks the hardware data that contains the key toolchain\n",
    "        if \"INTERNAL\" in node.meta[\"mase\"].parameters[\"hardware\"][\"toolchain\"]:\n",
    "                for param_name, parameter in node.meta[\"mase\"].module.named_parameters():\n",
    "                        print (\"param_name in CNN.jynb:\",param_name)\n",
    "                        print (\"parameter in CNN.jynb:\", parameter)\n",
    "\n",
    "\"\"\"\n",
    "weights and bias in the Conv/linear in Maze\n",
    "param_data = node.meta[\"mase\"].module.get_parameter(param_name).data\n",
    "print (\"param_data: \", param_data)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<chop.ir.graph.mase_graph.MaseGraph object at 0x7ffff81e96d0>\n"
     ]
    }
   ],
   "source": [
    "mg_soft, _ = add_software_metadata_analysis_pass(mg)\n",
    "print (mg_soft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, run the emit verilog pass to generate the SystemVerilog files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mEmitting Verilog...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEmitting internal components...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter_map in VerilogEmitter: {'fc1_DATA_IN_0_PRECISION_0': 8, 'fc1_DATA_IN_0_PRECISION_1': 5, 'fc1_DATA_IN_0_TENSOR_SIZE_DIM_0': 16, 'fc1_DATA_IN_0_PARALLELISM_DIM_0': 4, 'fc1_DATA_IN_0_TENSOR_SIZE_DIM_1': 1, 'fc1_DATA_IN_0_PARALLELISM_DIM_1': 1, 'fc1_WEIGHT_PRECISION_0': 8, 'fc1_WEIGHT_PRECISION_1': 5, 'fc1_WEIGHT_TENSOR_SIZE_DIM_0': 16, 'fc1_WEIGHT_PARALLELISM_DIM_0': 4, 'fc1_WEIGHT_TENSOR_SIZE_DIM_1': 16, 'fc1_WEIGHT_PARALLELISM_DIM_1': 4, 'fc1_BIAS_PRECISION_0': 8, 'fc1_BIAS_PRECISION_1': 5, 'fc1_BIAS_TENSOR_SIZE_DIM_0': 16, 'fc1_BIAS_PARALLELISM_DIM_0': 4, 'fc1_BIAS_TENSOR_SIZE_DIM_1': 1, 'fc1_BIAS_PARALLELISM_DIM_1': 1, 'fc1_DATA_OUT_0_PRECISION_0': 8, 'fc1_DATA_OUT_0_PRECISION_1': 5, 'fc1_DATA_OUT_0_TENSOR_SIZE_DIM_0': 16, 'fc1_DATA_OUT_0_PARALLELISM_DIM_0': 4, 'fc1_DATA_OUT_0_TENSOR_SIZE_DIM_1': 1, 'fc1_DATA_OUT_0_PARALLELISM_DIM_1': 1, 'relu_DATA_IN_0_PRECISION_0': 8, 'relu_DATA_IN_0_PRECISION_1': 5, 'relu_DATA_IN_0_TENSOR_SIZE_DIM_0': 16, 'relu_DATA_IN_0_PARALLELISM_DIM_0': 4, 'relu_DATA_IN_0_TENSOR_SIZE_DIM_1': 1, 'relu_DATA_IN_0_PARALLELISM_DIM_1': 1, 'relu_INPLACE': 0, 'relu_DATA_OUT_0_PRECISION_0': 8, 'relu_DATA_OUT_0_PRECISION_1': 5, 'relu_DATA_OUT_0_TENSOR_SIZE_DIM_0': 16, 'relu_DATA_OUT_0_PARALLELISM_DIM_0': 4, 'relu_DATA_OUT_0_TENSOR_SIZE_DIM_1': 1, 'relu_DATA_OUT_0_PARALLELISM_DIM_1': 1, 'DATA_IN_0_PRECISION_0': 8, 'DATA_IN_0_PRECISION_1': 5, 'DATA_IN_0_TENSOR_SIZE_DIM_0': 16, 'DATA_IN_0_PARALLELISM_DIM_0': 4, 'DATA_IN_0_TENSOR_SIZE_DIM_1': 1, 'DATA_IN_0_PARALLELISM_DIM_1': 1, 'DATA_OUT_0_PRECISION_0': 8, 'DATA_OUT_0_PRECISION_1': 5, 'DATA_OUT_0_TENSOR_SIZE_DIM_0': 16, 'DATA_OUT_0_PARALLELISM_DIM_0': 4, 'DATA_OUT_0_TENSOR_SIZE_DIM_1': 1, 'DATA_OUT_0_PARALLELISM_DIM_1': 1}\n",
      "nodes_in: [fc1]\n",
      "nodes_out: [relu]\n",
      "parameter in VerilogParameterEmitter:     parameter fc1_DATA_IN_0_PRECISION_0 = 8,\n",
      "    parameter fc1_DATA_IN_0_PRECISION_1 = 5,\n",
      "    parameter fc1_DATA_IN_0_TENSOR_SIZE_DIM_0 = 16,\n",
      "    parameter fc1_DATA_IN_0_PARALLELISM_DIM_0 = 4,\n",
      "    parameter fc1_DATA_IN_0_TENSOR_SIZE_DIM_1 = 1,\n",
      "    parameter fc1_DATA_IN_0_PARALLELISM_DIM_1 = 1,\n",
      "    parameter fc1_WEIGHT_PRECISION_0 = 8,\n",
      "    parameter fc1_WEIGHT_PRECISION_1 = 5,\n",
      "    parameter fc1_WEIGHT_TENSOR_SIZE_DIM_0 = 16,\n",
      "    parameter fc1_WEIGHT_PARALLELISM_DIM_0 = 4,\n",
      "    parameter fc1_WEIGHT_TENSOR_SIZE_DIM_1 = 16,\n",
      "    parameter fc1_WEIGHT_PARALLELISM_DIM_1 = 4,\n",
      "    parameter fc1_BIAS_PRECISION_0 = 8,\n",
      "    parameter fc1_BIAS_PRECISION_1 = 5,\n",
      "    parameter fc1_BIAS_TENSOR_SIZE_DIM_0 = 16,\n",
      "    parameter fc1_BIAS_PARALLELISM_DIM_0 = 4,\n",
      "    parameter fc1_BIAS_TENSOR_SIZE_DIM_1 = 1,\n",
      "    parameter fc1_BIAS_PARALLELISM_DIM_1 = 1,\n",
      "    parameter fc1_DATA_OUT_0_PRECISION_0 = 8,\n",
      "    parameter fc1_DATA_OUT_0_PRECISION_1 = 5,\n",
      "    parameter fc1_DATA_OUT_0_TENSOR_SIZE_DIM_0 = 16,\n",
      "    parameter fc1_DATA_OUT_0_PARALLELISM_DIM_0 = 4,\n",
      "    parameter fc1_DATA_OUT_0_TENSOR_SIZE_DIM_1 = 1,\n",
      "    parameter fc1_DATA_OUT_0_PARALLELISM_DIM_1 = 1,\n",
      "    parameter relu_DATA_IN_0_PRECISION_0 = 8,\n",
      "    parameter relu_DATA_IN_0_PRECISION_1 = 5,\n",
      "    parameter relu_DATA_IN_0_TENSOR_SIZE_DIM_0 = 16,\n",
      "    parameter relu_DATA_IN_0_PARALLELISM_DIM_0 = 4,\n",
      "    parameter relu_DATA_IN_0_TENSOR_SIZE_DIM_1 = 1,\n",
      "    parameter relu_DATA_IN_0_PARALLELISM_DIM_1 = 1,\n",
      "    parameter relu_INPLACE = 0,\n",
      "    parameter relu_DATA_OUT_0_PRECISION_0 = 8,\n",
      "    parameter relu_DATA_OUT_0_PRECISION_1 = 5,\n",
      "    parameter relu_DATA_OUT_0_TENSOR_SIZE_DIM_0 = 16,\n",
      "    parameter relu_DATA_OUT_0_PARALLELISM_DIM_0 = 4,\n",
      "    parameter relu_DATA_OUT_0_TENSOR_SIZE_DIM_1 = 1,\n",
      "    parameter relu_DATA_OUT_0_PARALLELISM_DIM_1 = 1,\n",
      "    parameter DATA_IN_0_PRECISION_0 = 8,\n",
      "    parameter DATA_IN_0_PRECISION_1 = 5,\n",
      "    parameter DATA_IN_0_TENSOR_SIZE_DIM_0 = 16,\n",
      "    parameter DATA_IN_0_PARALLELISM_DIM_0 = 4,\n",
      "    parameter DATA_IN_0_TENSOR_SIZE_DIM_1 = 1,\n",
      "    parameter DATA_IN_0_PARALLELISM_DIM_1 = 1,\n",
      "    parameter DATA_OUT_0_PRECISION_0 = 8,\n",
      "    parameter DATA_OUT_0_PRECISION_1 = 5,\n",
      "    parameter DATA_OUT_0_TENSOR_SIZE_DIM_0 = 16,\n",
      "    parameter DATA_OUT_0_PARALLELISM_DIM_0 = 4,\n",
      "    parameter DATA_OUT_0_TENSOR_SIZE_DIM_1 = 1,\n",
      "    parameter DATA_OUT_0_PARALLELISM_DIM_1 = 1,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mg, _ = emit_verilog_top_transform_pass(mg)\n",
    "mg, _ = emit_internal_rtl_transform_pass(mg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generated files should now be found under `top/hardware`. \n",
    "\n",
    "> **_TASK:_** Read through `top/hardware/rtl/top.sv` and make sure you understand how our MLP model maps to this hardware design. \n",
    "\n",
    "You will notice the following instantiated modules:\n",
    "\n",
    "* `fixed_linear`: this is found under `components/linear/fixed_linear.sv` and implements each Linear layer in the model.\n",
    "* `fc<layer number>_weight/bias_source`: these are [BRAM](https://nandland.com/lesson-15-what-is-a-block-ram-bram/) memories which drive the weights and biases into the linear layers for computation.\n",
    "* `fixed_relu`: found under `components/activations/fixed_relu.sv`, implements the ReLU activation.\n",
    "\n",
    "As of now, we can't yet run a simulation on the model, as we haven't yet generated the memory components. To do this, run the `emit_bram` transform pass as follows, which will generate the memory initialization files and SystemVerilog modules to drive weights and biases into the linear layers. Finally, the `emit_verilog_tb` transform pass will generate the testbench files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mEmitting BRAM...\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[34mEmitting DAT file for node: fc1, parameter: weight\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 in emit_bram_transform_pass\n",
      "/root/.mase/top/hardware/rtl\n",
      "param_name in emit_bram_handshake: weight\n",
      "parameter in emit_bram_handshake: Parameter containing:\n",
      "tensor([[-0.0019,  0.1341, -0.2058, -0.1840, -0.0963,  0.0670, -0.0050,  0.1982,\n",
      "         -0.0222,  0.0662, -0.0756, -0.0491, -0.2388, -0.1656, -0.1031,  0.0093],\n",
      "        [ 0.0988,  0.1500, -0.1695, -0.1089,  0.0908,  0.2076, -0.0515,  0.1871,\n",
      "         -0.0403,  0.0265,  0.2264, -0.2319, -0.1574, -0.0633, -0.0974,  0.2160],\n",
      "        [-0.1620, -0.1151, -0.1747, -0.2341, -0.1459,  0.2149,  0.1116,  0.1212,\n",
      "          0.0131, -0.1282,  0.0423, -0.2334, -0.1806, -0.1289,  0.1577,  0.1466],\n",
      "        [-0.1109, -0.0090,  0.1599,  0.2485,  0.0992,  0.0338,  0.1676, -0.1472,\n",
      "          0.0466, -0.1938, -0.1733, -0.1291,  0.1131,  0.1005, -0.1481,  0.0755],\n",
      "        [ 0.1372, -0.0316,  0.0095,  0.0579,  0.1551,  0.2400, -0.1927, -0.0916,\n",
      "          0.0983,  0.2071,  0.2176,  0.2206,  0.0498, -0.2174,  0.0230, -0.1564],\n",
      "        [-0.2330,  0.2221,  0.1901, -0.2494,  0.0468, -0.0421, -0.0411, -0.1144,\n",
      "          0.0961, -0.1481,  0.0916,  0.1264,  0.1790,  0.0935, -0.2474, -0.1622],\n",
      "        [ 0.1248,  0.0523, -0.1950, -0.1440,  0.2352,  0.1685, -0.1090, -0.0629,\n",
      "         -0.2381, -0.0045, -0.1883, -0.1928, -0.0138,  0.0375, -0.1024,  0.1483],\n",
      "        [-0.1521,  0.2268,  0.1713, -0.2108, -0.0622,  0.0113,  0.0365,  0.0593,\n",
      "          0.0981,  0.0150, -0.1220,  0.1183, -0.2398, -0.1482, -0.0626, -0.1218],\n",
      "        [-0.0875, -0.2049, -0.0532,  0.0534, -0.1629, -0.0128,  0.1790, -0.0257,\n",
      "          0.0069, -0.0216,  0.0506,  0.1590,  0.2368,  0.1588,  0.2374, -0.0181],\n",
      "        [-0.2246, -0.1185,  0.1702, -0.0016, -0.1243, -0.1916, -0.2340, -0.2110,\n",
      "         -0.0507,  0.1371,  0.1352, -0.2411,  0.1559, -0.1956, -0.0529, -0.1014],\n",
      "        [-0.0482, -0.0491, -0.2243, -0.2159, -0.0391,  0.0032, -0.1136,  0.0942,\n",
      "         -0.2250, -0.0169,  0.2199, -0.1020,  0.2258,  0.0905, -0.2256,  0.1582],\n",
      "        [-0.0288, -0.1116,  0.1999, -0.2020,  0.0268, -0.0523,  0.1785,  0.0698,\n",
      "          0.1201,  0.0883, -0.0601, -0.0526, -0.2060,  0.1355,  0.1985,  0.1711],\n",
      "        [-0.1763,  0.0111, -0.1762, -0.1376, -0.1457,  0.0854, -0.1490, -0.0055,\n",
      "          0.0105,  0.1612, -0.1890, -0.1716, -0.1452,  0.1750, -0.0899,  0.2109],\n",
      "        [ 0.0904,  0.0317, -0.0019, -0.0494,  0.0314, -0.0571, -0.0018,  0.0319,\n",
      "         -0.1956, -0.1310,  0.2019, -0.2029, -0.0180,  0.2473,  0.0903,  0.0071],\n",
      "        [-0.2167,  0.1238, -0.1781, -0.0710, -0.0839, -0.0370,  0.0027,  0.2062,\n",
      "          0.0312,  0.2239,  0.1529, -0.1581,  0.1121, -0.1767, -0.1060,  0.0735],\n",
      "        [ 0.0825,  0.1876, -0.0805,  0.0004,  0.1287, -0.2418,  0.1807, -0.2067,\n",
      "          0.0034, -0.0425, -0.1317,  0.0330,  0.2067, -0.0731, -0.1484, -0.0925]],\n",
      "       requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36mDEBUG   \u001b[0m \u001b[34mROM module weight successfully written into /root/.mase/top/hardware/rtl/fc1_weight_source.sv\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out_size in emit_parameters_in_mem_internal: 16\n",
      "fc1\n",
      "param_data in emit_parameters_in_dat_internal:  tensor([[-0.0019,  0.1341, -0.2058, -0.1840, -0.0963,  0.0670, -0.0050,  0.1982,\n",
      "         -0.0222,  0.0662, -0.0756, -0.0491, -0.2388, -0.1656, -0.1031,  0.0093],\n",
      "        [ 0.0988,  0.1500, -0.1695, -0.1089,  0.0908,  0.2076, -0.0515,  0.1871,\n",
      "         -0.0403,  0.0265,  0.2264, -0.2319, -0.1574, -0.0633, -0.0974,  0.2160],\n",
      "        [-0.1620, -0.1151, -0.1747, -0.2341, -0.1459,  0.2149,  0.1116,  0.1212,\n",
      "          0.0131, -0.1282,  0.0423, -0.2334, -0.1806, -0.1289,  0.1577,  0.1466],\n",
      "        [-0.1109, -0.0090,  0.1599,  0.2485,  0.0992,  0.0338,  0.1676, -0.1472,\n",
      "          0.0466, -0.1938, -0.1733, -0.1291,  0.1131,  0.1005, -0.1481,  0.0755],\n",
      "        [ 0.1372, -0.0316,  0.0095,  0.0579,  0.1551,  0.2400, -0.1927, -0.0916,\n",
      "          0.0983,  0.2071,  0.2176,  0.2206,  0.0498, -0.2174,  0.0230, -0.1564],\n",
      "        [-0.2330,  0.2221,  0.1901, -0.2494,  0.0468, -0.0421, -0.0411, -0.1144,\n",
      "          0.0961, -0.1481,  0.0916,  0.1264,  0.1790,  0.0935, -0.2474, -0.1622],\n",
      "        [ 0.1248,  0.0523, -0.1950, -0.1440,  0.2352,  0.1685, -0.1090, -0.0629,\n",
      "         -0.2381, -0.0045, -0.1883, -0.1928, -0.0138,  0.0375, -0.1024,  0.1483],\n",
      "        [-0.1521,  0.2268,  0.1713, -0.2108, -0.0622,  0.0113,  0.0365,  0.0593,\n",
      "          0.0981,  0.0150, -0.1220,  0.1183, -0.2398, -0.1482, -0.0626, -0.1218],\n",
      "        [-0.0875, -0.2049, -0.0532,  0.0534, -0.1629, -0.0128,  0.1790, -0.0257,\n",
      "          0.0069, -0.0216,  0.0506,  0.1590,  0.2368,  0.1588,  0.2374, -0.0181],\n",
      "        [-0.2246, -0.1185,  0.1702, -0.0016, -0.1243, -0.1916, -0.2340, -0.2110,\n",
      "         -0.0507,  0.1371,  0.1352, -0.2411,  0.1559, -0.1956, -0.0529, -0.1014],\n",
      "        [-0.0482, -0.0491, -0.2243, -0.2159, -0.0391,  0.0032, -0.1136,  0.0942,\n",
      "         -0.2250, -0.0169,  0.2199, -0.1020,  0.2258,  0.0905, -0.2256,  0.1582],\n",
      "        [-0.0288, -0.1116,  0.1999, -0.2020,  0.0268, -0.0523,  0.1785,  0.0698,\n",
      "          0.1201,  0.0883, -0.0601, -0.0526, -0.2060,  0.1355,  0.1985,  0.1711],\n",
      "        [-0.1763,  0.0111, -0.1762, -0.1376, -0.1457,  0.0854, -0.1490, -0.0055,\n",
      "          0.0105,  0.1612, -0.1890, -0.1716, -0.1452,  0.1750, -0.0899,  0.2109],\n",
      "        [ 0.0904,  0.0317, -0.0019, -0.0494,  0.0314, -0.0571, -0.0018,  0.0319,\n",
      "         -0.1956, -0.1310,  0.2019, -0.2029, -0.0180,  0.2473,  0.0903,  0.0071],\n",
      "        [-0.2167,  0.1238, -0.1781, -0.0710, -0.0839, -0.0370,  0.0027,  0.2062,\n",
      "          0.0312,  0.2239,  0.1529, -0.1581,  0.1121, -0.1767, -0.1060,  0.0735],\n",
      "        [ 0.0825,  0.1876, -0.0805,  0.0004,  0.1287, -0.2418,  0.1807, -0.2067,\n",
      "          0.0034, -0.0425, -0.1317,  0.0330,  0.2067, -0.0731, -0.1484, -0.0925]])\n",
      "out_depth:  16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36mDEBUG   \u001b[0m \u001b[34mInit data weight successfully written into /root/.mase/top/hardware/rtl/fc1_weight_rom.dat\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[34mEmitting DAT file for node: fc1, parameter: bias\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[34mROM module bias successfully written into /root/.mase/top/hardware/rtl/fc1_bias_source.sv\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[34mInit data bias successfully written into /root/.mase/top/hardware/rtl/fc1_bias_rom.dat\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_buff:  0004f9fafd020006ff02fefef8fbfd00\n",
      "0305fbfd0307fe06ff0107f9fbfefd07\n",
      "fbfcfaf9fb07040400fc01f9fafc0505\n",
      "fc000508030105fb01fafafc0403fb02\n",
      "04ff00020508fafd0307070702f901fb\n",
      "f90706f801fffffc03fb03040603f8fb\n",
      "0402fafb0805fdfef800fafa0001fd05\n",
      "fb0705f9fe0001020300fc04f8fbfefc\n",
      "fdf9fe02fb0006ff00ff0205080508ff\n",
      "f9fc0500fcfaf9f9fe0404f805fafefd\n",
      "fefef9f9ff00fc03f9ff07fd0703f905\n",
      "fffc06fa01fe06020403fefef9040605\n",
      "fa00fafcfb03fb000005fafbfb06fd07\n",
      "030100fe01fe0001fafc06faff080300\n",
      "f904fafefdff0007010705fb04fafd02\n",
      "0306fd0004f806f900fffc0107fefbfd\n",
      "\n",
      "param_name in emit_bram_handshake: bias\n",
      "parameter in emit_bram_handshake: Parameter containing:\n",
      "tensor([-0.2478,  0.1128, -0.1201, -0.1668, -0.1440,  0.1437,  0.1324,  0.1919,\n",
      "         0.0907, -0.0835, -0.0699,  0.0739,  0.2055,  0.0680, -0.1183, -0.1175],\n",
      "       requires_grad=True)\n",
      "out_size in emit_parameters_in_mem_internal: 4\n",
      "fc1\n",
      "param_data in emit_parameters_in_dat_internal:  tensor([-0.2478,  0.1128, -0.1201, -0.1668, -0.1440,  0.1437,  0.1324,  0.1919,\n",
      "         0.0907, -0.0835, -0.0699,  0.0739,  0.2055,  0.0680, -0.1183, -0.1175])\n",
      "out_depth:  4\n",
      "data_buff:  f804fcfb\n",
      "fb050406\n",
      "03fdfe02\n",
      "0702fcfc\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mg, _ = emit_bram_transform_pass(mg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mEmitting testbench...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "mg, _ = emit_cocotb_transform_pass(mg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **_TASK:_** Now, you're ready to launch a simulation by calling the simulate action as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Running command perl /usr/local/bin/verilator -cc --exe -Mdir /workspace/docs/labs/sim_build -DCOCOTB_SIM=1 --top-module top --vpi --public-flat-rw --prefix Vtop -o top -LDFLAGS '-Wl,-rpath,/usr/local/lib/python3.11/dist-packages/cocotb/libs -L/usr/local/lib/python3.11/dist-packages/cocotb/libs -lcocotbvpi_verilator' -Wno-fatal -Wno-lint -Wno-style --trace-fst --trace-structs --trace-depth 3 -I/root/.mase/top/hardware/rtl -I/workspace/src/mase_components/interface/rtl -I/workspace/src/mase_components/language_models/rtl -I/workspace/src/mase_components/memory/rtl -I/workspace/src/mase_components/vivado/rtl -I/workspace/src/mase_components/convolution_layers/rtl -I/workspace/src/mase_components/cast/rtl -I/workspace/src/mase_components/systolic_arrays/rtl -I/workspace/src/mase_components/scalar_operators/rtl -I/workspace/src/mase_components/transformer_layers/rtl -I/workspace/src/mase_components/common/rtl -I/workspace/src/mase_components/hls/rtl -I/workspace/src/mase_components/vision_models/rtl -I/workspace/src/mase_components/linear_layers/rtl -I/workspace/src/mase_components/activation_layers/rtl -I/workspace/src/mase_components/normalization_layers/rtl -I/workspace/src/mase_components/helper/rtl /usr/local/lib/python3.11/dist-packages/cocotb/share/lib/verilator/verilator.cpp /root/.mase/top/hardware/rtl/register_slice.sv /root/.mase/top/hardware/rtl/fixed_adder_tree_layer.sv /root/.mase/top/hardware/rtl/unpacked_repeat_circular_buffer.sv /root/.mase/top/hardware/rtl/matmul.sv /root/.mase/top/hardware/rtl/join2.sv /root/.mase/top/hardware/rtl/sliding_window.sv /root/.mase/top/hardware/rtl/convolution.sv /root/.mase/top/hardware/rtl/matrix_unflatten.sv /root/.mase/top/hardware/rtl/fixed_signed_cast.sv /root/.mase/top/hardware/rtl/blk_mem_gen_0.sv /root/.mase/top/hardware/rtl/fixed_relu.sv /root/.mase/top/hardware/rtl/fixed_adder_tree.sv /root/.mase/top/hardware/rtl/matrix_fifo.sv /root/.mase/top/hardware/rtl/conv1_bias_source.sv /root/.mase/top/hardware/rtl/fc1_bias_source.sv /root/.mase/top/hardware/rtl/fixed_linear.sv /root/.mase/top/hardware/rtl/top.sv /root/.mase/top/hardware/rtl/fc1_weight_source.sv /root/.mase/top/hardware/rtl/fc1_1_bias_source.sv /root/.mase/top/hardware/rtl/conv1_weight_source.sv /root/.mase/top/hardware/rtl/transpose.sv /root/.mase/top/hardware/rtl/fixed_rounding.sv /root/.mase/top/hardware/rtl/input_buffer.sv /root/.mase/top/hardware/rtl/floor_round.sv /root/.mase/top/hardware/rtl/convolution_mase.sv /root/.mase/top/hardware/rtl/fc1_1_weight_source.sv /root/.mase/top/hardware/rtl/convolution_arith.sv /root/.mase/top/hardware/rtl/matrix_accumulator.sv /root/.mase/top/hardware/rtl/simple_matmul.sv /root/.mase/top/hardware/rtl/skid_buffer.sv /root/.mase/top/hardware/rtl/matrix_stream_transpose.sv /root/.mase/top/hardware/rtl/unpacked_skid_buffer.sv /root/.mase/top/hardware/rtl/fixed_leakyrelu.sv /root/.mase/top/hardware/rtl/fixed_accumulator.sv /root/.mase/top/hardware/rtl/fixed_vector_mult.sv /root/.mase/top/hardware/rtl/matrix_flatten.sv /root/.mase/top/hardware/rtl/fixed_dot_product.sv /root/.mase/top/hardware/rtl/padding.sv /root/.mase/top/hardware/rtl/fixed_cast.sv /root/.mase/top/hardware/rtl/roller.sv /root/.mase/top/hardware/rtl/fixed_mult.sv /root/.mase/top/hardware/rtl/signed_clamp.sv in directory /workspace/docs/labs/sim_build\n",
      "INFO: Running command make -C /workspace/docs/labs/sim_build -f Vtop.mk in directory /workspace/docs/labs/sim_build\n",
      "make: Entering directory '/workspace/docs/labs/sim_build'\n",
      "ccache g++  -I.  -MMD -I/usr/local/share/verilator/include -I/usr/local/share/verilator/include/vltstd -DVM_COVERAGE=0 -DVM_SC=0 -DVM_TRACE=1 -DVM_TRACE_FST=1 -DVM_TRACE_VCD=0 -faligned-new -fcf-protection=none -Wno-bool-operation -Wno-overloaded-virtual -Wno-shadow -Wno-sign-compare -Wno-uninitialized -Wno-unused-but-set-parameter -Wno-unused-but-set-variable -Wno-unused-parameter -Wno-unused-variable       -Os -c -o verilator.o /usr/local/lib/python3.11/dist-packages/cocotb/share/lib/verilator/verilator.cpp\n",
      "ccache g++ -Os  -I.  -MMD -I/usr/local/share/verilator/include -I/usr/local/share/verilator/include/vltstd -DVM_COVERAGE=0 -DVM_SC=0 -DVM_TRACE=1 -DVM_TRACE_FST=1 -DVM_TRACE_VCD=0 -faligned-new -fcf-protection=none -Wno-bool-operation -Wno-overloaded-virtual -Wno-shadow -Wno-sign-compare -Wno-uninitialized -Wno-unused-but-set-parameter -Wno-unused-but-set-variable -Wno-unused-parameter -Wno-unused-variable       -c -o verilated.o /usr/local/share/verilator/include/verilated.cpp\n",
      "ccache g++ -Os  -I.  -MMD -I/usr/local/share/verilator/include -I/usr/local/share/verilator/include/vltstd -DVM_COVERAGE=0 -DVM_SC=0 -DVM_TRACE=1 -DVM_TRACE_FST=1 -DVM_TRACE_VCD=0 -faligned-new -fcf-protection=none -Wno-bool-operation -Wno-overloaded-virtual -Wno-shadow -Wno-sign-compare -Wno-uninitialized -Wno-unused-but-set-parameter -Wno-unused-but-set-variable -Wno-unused-parameter -Wno-unused-variable       -c -o verilated_dpi.o /usr/local/share/verilator/include/verilated_dpi.cpp\n",
      "ccache g++ -Os  -I.  -MMD -I/usr/local/share/verilator/include -I/usr/local/share/verilator/include/vltstd -DVM_COVERAGE=0 -DVM_SC=0 -DVM_TRACE=1 -DVM_TRACE_FST=1 -DVM_TRACE_VCD=0 -faligned-new -fcf-protection=none -Wno-bool-operation -Wno-overloaded-virtual -Wno-shadow -Wno-sign-compare -Wno-uninitialized -Wno-unused-but-set-parameter -Wno-unused-but-set-variable -Wno-unused-parameter -Wno-unused-variable       -c -o verilated_vpi.o /usr/local/share/verilator/include/verilated_vpi.cpp\n",
      "ccache g++ -Os  -I.  -MMD -I/usr/local/share/verilator/include -I/usr/local/share/verilator/include/vltstd -DVM_COVERAGE=0 -DVM_SC=0 -DVM_TRACE=1 -DVM_TRACE_FST=1 -DVM_TRACE_VCD=0 -faligned-new -fcf-protection=none -Wno-bool-operation -Wno-overloaded-virtual -Wno-shadow -Wno-sign-compare -Wno-uninitialized -Wno-unused-but-set-parameter -Wno-unused-but-set-variable -Wno-unused-parameter -Wno-unused-variable       -c -o verilated_fst_c.o /usr/local/share/verilator/include/verilated_fst_c.cpp\n",
      "ccache g++ -Os  -I.  -MMD -I/usr/local/share/verilator/include -I/usr/local/share/verilator/include/vltstd -DVM_COVERAGE=0 -DVM_SC=0 -DVM_TRACE=1 -DVM_TRACE_FST=1 -DVM_TRACE_VCD=0 -faligned-new -fcf-protection=none -Wno-bool-operation -Wno-overloaded-virtual -Wno-shadow -Wno-sign-compare -Wno-uninitialized -Wno-unused-but-set-parameter -Wno-unused-but-set-variable -Wno-unused-parameter -Wno-unused-variable       -c -o verilated_threads.o /usr/local/share/verilator/include/verilated_threads.cpp\n",
      "ccache g++ -Os  -I.  -MMD -I/usr/local/share/verilator/include -I/usr/local/share/verilator/include/vltstd -DVM_COVERAGE=0 -DVM_SC=0 -DVM_TRACE=1 -DVM_TRACE_FST=1 -DVM_TRACE_VCD=0 -faligned-new -fcf-protection=none -Wno-bool-operation -Wno-overloaded-virtual -Wno-shadow -Wno-sign-compare -Wno-uninitialized -Wno-unused-but-set-parameter -Wno-unused-but-set-variable -Wno-unused-parameter -Wno-unused-variable       -x c++-header Vtop__pch.h -o Vtop__pch.h.fast.gch\n",
      "ccache g++ -Os  -I.  -MMD -I/usr/local/share/verilator/include -I/usr/local/share/verilator/include/vltstd -DVM_COVERAGE=0 -DVM_SC=0 -DVM_TRACE=1 -DVM_TRACE_FST=1 -DVM_TRACE_VCD=0 -faligned-new -fcf-protection=none -Wno-bool-operation -Wno-overloaded-virtual -Wno-shadow -Wno-sign-compare -Wno-uninitialized -Wno-unused-but-set-parameter -Wno-unused-but-set-variable -Wno-unused-parameter -Wno-unused-variable       -include Vtop__pch.h.fast -c -o Vtop.o Vtop.cpp\n",
      "ccache g++ -Os  -I.  -MMD -I/usr/local/share/verilator/include -I/usr/local/share/verilator/include/vltstd -DVM_COVERAGE=0 -DVM_SC=0 -DVM_TRACE=1 -DVM_TRACE_FST=1 -DVM_TRACE_VCD=0 -faligned-new -fcf-protection=none -Wno-bool-operation -Wno-overloaded-virtual -Wno-shadow -Wno-sign-compare -Wno-uninitialized -Wno-unused-but-set-parameter -Wno-unused-but-set-variable -Wno-unused-parameter -Wno-unused-variable       -include Vtop__pch.h.fast -c -o Vtop___024root__DepSet_h84412442__0.o Vtop___024root__DepSet_h84412442__0.cpp\n",
      "ccache g++ -Os  -I.  -MMD -I/usr/local/share/verilator/include -I/usr/local/share/verilator/include/vltstd -DVM_COVERAGE=0 -DVM_SC=0 -DVM_TRACE=1 -DVM_TRACE_FST=1 -DVM_TRACE_VCD=0 -faligned-new -fcf-protection=none -Wno-bool-operation -Wno-overloaded-virtual -Wno-shadow -Wno-sign-compare -Wno-uninitialized -Wno-unused-but-set-parameter -Wno-unused-but-set-variable -Wno-unused-parameter -Wno-unused-variable       -include Vtop__pch.h.fast -c -o Vtop___024root__DepSet_h84412442__1.o Vtop___024root__DepSet_h84412442__1.cpp\n",
      "ccache g++ -Os  -I.  -MMD -I/usr/local/share/verilator/include -I/usr/local/share/verilator/include/vltstd -DVM_COVERAGE=0 -DVM_SC=0 -DVM_TRACE=1 -DVM_TRACE_FST=1 -DVM_TRACE_VCD=0 -faligned-new -fcf-protection=none -Wno-bool-operation -Wno-overloaded-virtual -Wno-shadow -Wno-sign-compare -Wno-uninitialized -Wno-unused-but-set-parameter -Wno-unused-but-set-variable -Wno-unused-parameter -Wno-unused-variable       -include Vtop__pch.h.fast -c -o Vtop___024root__DepSet_heccd7ead__0.o Vtop___024root__DepSet_heccd7ead__0.cpp\n",
      "ccache g++ -Os  -I.  -MMD -I/usr/local/share/verilator/include -I/usr/local/share/verilator/include/vltstd -DVM_COVERAGE=0 -DVM_SC=0 -DVM_TRACE=1 -DVM_TRACE_FST=1 -DVM_TRACE_VCD=0 -faligned-new -fcf-protection=none -Wno-bool-operation -Wno-overloaded-virtual -Wno-shadow -Wno-sign-compare -Wno-uninitialized -Wno-unused-but-set-parameter -Wno-unused-but-set-variable -Wno-unused-parameter -Wno-unused-variable       -include Vtop__pch.h.fast -c -o Vtop_matrix_accumulator__pi9__DepSet_hcabfba31__0.o Vtop_matrix_accumulator__pi9__DepSet_hcabfba31__0.cpp\n",
      "ccache g++ -Os  -I.  -MMD -I/usr/local/share/verilator/include -I/usr/local/share/verilator/include/vltstd -DVM_COVERAGE=0 -DVM_SC=0 -DVM_TRACE=1 -DVM_TRACE_FST=1 -DVM_TRACE_VCD=0 -faligned-new -fcf-protection=none -Wno-bool-operation -Wno-overloaded-virtual -Wno-shadow -Wno-sign-compare -Wno-uninitialized -Wno-unused-but-set-parameter -Wno-unused-but-set-variable -Wno-unused-parameter -Wno-unused-variable       -include Vtop__pch.h.fast -c -o Vtop_fixed_dot_product__I8_W8__DepSet_h6108f7e9__0.o Vtop_fixed_dot_product__I8_W8__DepSet_h6108f7e9__0.cpp\n",
      "ccache g++ -Os  -I.  -MMD -I/usr/local/share/verilator/include -I/usr/local/share/verilator/include/vltstd -DVM_COVERAGE=0 -DVM_SC=0 -DVM_TRACE=1 -DVM_TRACE_FST=1 -DVM_TRACE_VCD=0 -faligned-new -fcf-protection=none -Wno-bool-operation -Wno-overloaded-virtual -Wno-shadow -Wno-sign-compare -Wno-uninitialized -Wno-unused-but-set-parameter -Wno-unused-but-set-variable -Wno-unused-parameter -Wno-unused-variable       -include Vtop__pch.h.fast -c -o Vtop__Dpi.o Vtop__Dpi.cpp\n",
      "ccache g++ -Os  -I.  -MMD -I/usr/local/share/verilator/include -I/usr/local/share/verilator/include/vltstd -DVM_COVERAGE=0 -DVM_SC=0 -DVM_TRACE=1 -DVM_TRACE_FST=1 -DVM_TRACE_VCD=0 -faligned-new -fcf-protection=none -Wno-bool-operation -Wno-overloaded-virtual -Wno-shadow -Wno-sign-compare -Wno-uninitialized -Wno-unused-but-set-parameter -Wno-unused-but-set-variable -Wno-unused-parameter -Wno-unused-variable       -include Vtop__pch.h.fast -c -o Vtop__Trace__0.o Vtop__Trace__0.cpp\n",
      "ccache g++   -I.  -MMD -I/usr/local/share/verilator/include -I/usr/local/share/verilator/include/vltstd -DVM_COVERAGE=0 -DVM_SC=0 -DVM_TRACE=1 -DVM_TRACE_FST=1 -DVM_TRACE_VCD=0 -faligned-new -fcf-protection=none -Wno-bool-operation -Wno-overloaded-virtual -Wno-shadow -Wno-sign-compare -Wno-uninitialized -Wno-unused-but-set-parameter -Wno-unused-but-set-variable -Wno-unused-parameter -Wno-unused-variable       -x c++-header Vtop__pch.h -o Vtop__pch.h.slow.gch\n",
      "ccache g++   -I.  -MMD -I/usr/local/share/verilator/include -I/usr/local/share/verilator/include/vltstd -DVM_COVERAGE=0 -DVM_SC=0 -DVM_TRACE=1 -DVM_TRACE_FST=1 -DVM_TRACE_VCD=0 -faligned-new -fcf-protection=none -Wno-bool-operation -Wno-overloaded-virtual -Wno-shadow -Wno-sign-compare -Wno-uninitialized -Wno-unused-but-set-parameter -Wno-unused-but-set-variable -Wno-unused-parameter -Wno-unused-variable       -include Vtop__pch.h.slow -c -o Vtop__ConstPool_0.o Vtop__ConstPool_0.cpp\n",
      "ccache g++   -I.  -MMD -I/usr/local/share/verilator/include -I/usr/local/share/verilator/include/vltstd -DVM_COVERAGE=0 -DVM_SC=0 -DVM_TRACE=1 -DVM_TRACE_FST=1 -DVM_TRACE_VCD=0 -faligned-new -fcf-protection=none -Wno-bool-operation -Wno-overloaded-virtual -Wno-shadow -Wno-sign-compare -Wno-uninitialized -Wno-unused-but-set-parameter -Wno-unused-but-set-variable -Wno-unused-parameter -Wno-unused-variable       -include Vtop__pch.h.slow -c -o Vtop___024root__Slow.o Vtop___024root__Slow.cpp\n",
      "ccache g++   -I.  -MMD -I/usr/local/share/verilator/include -I/usr/local/share/verilator/include/vltstd -DVM_COVERAGE=0 -DVM_SC=0 -DVM_TRACE=1 -DVM_TRACE_FST=1 -DVM_TRACE_VCD=0 -faligned-new -fcf-protection=none -Wno-bool-operation -Wno-overloaded-virtual -Wno-shadow -Wno-sign-compare -Wno-uninitialized -Wno-unused-but-set-parameter -Wno-unused-but-set-variable -Wno-unused-parameter -Wno-unused-variable       -include Vtop__pch.h.slow -c -o Vtop___024root__DepSet_h84412442__0__Slow.o Vtop___024root__DepSet_h84412442__0__Slow.cpp\n",
      "ccache g++   -I.  -MMD -I/usr/local/share/verilator/include -I/usr/local/share/verilator/include/vltstd -DVM_COVERAGE=0 -DVM_SC=0 -DVM_TRACE=1 -DVM_TRACE_FST=1 -DVM_TRACE_VCD=0 -faligned-new -fcf-protection=none -Wno-bool-operation -Wno-overloaded-virtual -Wno-shadow -Wno-sign-compare -Wno-uninitialized -Wno-unused-but-set-parameter -Wno-unused-but-set-variable -Wno-unused-parameter -Wno-unused-variable       -include Vtop__pch.h.slow -c -o Vtop___024root__DepSet_heccd7ead__0__Slow.o Vtop___024root__DepSet_heccd7ead__0__Slow.cpp\n",
      "ccache g++   -I.  -MMD -I/usr/local/share/verilator/include -I/usr/local/share/verilator/include/vltstd -DVM_COVERAGE=0 -DVM_SC=0 -DVM_TRACE=1 -DVM_TRACE_FST=1 -DVM_TRACE_VCD=0 -faligned-new -fcf-protection=none -Wno-bool-operation -Wno-overloaded-virtual -Wno-shadow -Wno-sign-compare -Wno-uninitialized -Wno-unused-but-set-parameter -Wno-unused-but-set-variable -Wno-unused-parameter -Wno-unused-variable       -include Vtop__pch.h.slow -c -o Vtop_matrix_accumulator__pi9__Slow.o Vtop_matrix_accumulator__pi9__Slow.cpp\n",
      "ccache g++   -I.  -MMD -I/usr/local/share/verilator/include -I/usr/local/share/verilator/include/vltstd -DVM_COVERAGE=0 -DVM_SC=0 -DVM_TRACE=1 -DVM_TRACE_FST=1 -DVM_TRACE_VCD=0 -faligned-new -fcf-protection=none -Wno-bool-operation -Wno-overloaded-virtual -Wno-shadow -Wno-sign-compare -Wno-uninitialized -Wno-unused-but-set-parameter -Wno-unused-but-set-variable -Wno-unused-parameter -Wno-unused-variable       -include Vtop__pch.h.slow -c -o Vtop_matrix_accumulator__pi9__DepSet_hcabfba31__0__Slow.o Vtop_matrix_accumulator__pi9__DepSet_hcabfba31__0__Slow.cpp\n",
      "ccache g++   -I.  -MMD -I/usr/local/share/verilator/include -I/usr/local/share/verilator/include/vltstd -DVM_COVERAGE=0 -DVM_SC=0 -DVM_TRACE=1 -DVM_TRACE_FST=1 -DVM_TRACE_VCD=0 -faligned-new -fcf-protection=none -Wno-bool-operation -Wno-overloaded-virtual -Wno-shadow -Wno-sign-compare -Wno-uninitialized -Wno-unused-but-set-parameter -Wno-unused-but-set-variable -Wno-unused-parameter -Wno-unused-variable       -include Vtop__pch.h.slow -c -o Vtop_fixed_dot_product__I8_W8__Slow.o Vtop_fixed_dot_product__I8_W8__Slow.cpp\n",
      "ccache g++   -I.  -MMD -I/usr/local/share/verilator/include -I/usr/local/share/verilator/include/vltstd -DVM_COVERAGE=0 -DVM_SC=0 -DVM_TRACE=1 -DVM_TRACE_FST=1 -DVM_TRACE_VCD=0 -faligned-new -fcf-protection=none -Wno-bool-operation -Wno-overloaded-virtual -Wno-shadow -Wno-sign-compare -Wno-uninitialized -Wno-unused-but-set-parameter -Wno-unused-but-set-variable -Wno-unused-parameter -Wno-unused-variable       -include Vtop__pch.h.slow -c -o Vtop_fixed_dot_product__I8_W8__DepSet_h6108f7e9__0__Slow.o Vtop_fixed_dot_product__I8_W8__DepSet_h6108f7e9__0__Slow.cpp\n",
      "ccache g++   -I.  -MMD -I/usr/local/share/verilator/include -I/usr/local/share/verilator/include/vltstd -DVM_COVERAGE=0 -DVM_SC=0 -DVM_TRACE=1 -DVM_TRACE_FST=1 -DVM_TRACE_VCD=0 -faligned-new -fcf-protection=none -Wno-bool-operation -Wno-overloaded-virtual -Wno-shadow -Wno-sign-compare -Wno-uninitialized -Wno-unused-but-set-parameter -Wno-unused-but-set-variable -Wno-unused-parameter -Wno-unused-variable       -include Vtop__pch.h.slow -c -o Vtop__Syms.o Vtop__Syms.cpp\n",
      "ccache g++   -I.  -MMD -I/usr/local/share/verilator/include -I/usr/local/share/verilator/include/vltstd -DVM_COVERAGE=0 -DVM_SC=0 -DVM_TRACE=1 -DVM_TRACE_FST=1 -DVM_TRACE_VCD=0 -faligned-new -fcf-protection=none -Wno-bool-operation -Wno-overloaded-virtual -Wno-shadow -Wno-sign-compare -Wno-uninitialized -Wno-unused-but-set-parameter -Wno-unused-but-set-variable -Wno-unused-parameter -Wno-unused-variable       -include Vtop__pch.h.slow -c -o Vtop__Trace__0__Slow.o Vtop__Trace__0__Slow.cpp\n",
      "ccache g++   -I.  -MMD -I/usr/local/share/verilator/include -I/usr/local/share/verilator/include/vltstd -DVM_COVERAGE=0 -DVM_SC=0 -DVM_TRACE=1 -DVM_TRACE_FST=1 -DVM_TRACE_VCD=0 -faligned-new -fcf-protection=none -Wno-bool-operation -Wno-overloaded-virtual -Wno-shadow -Wno-sign-compare -Wno-uninitialized -Wno-unused-but-set-parameter -Wno-unused-but-set-variable -Wno-unused-parameter -Wno-unused-variable       -include Vtop__pch.h.slow -c -o Vtop__TraceDecls__0__Slow.o Vtop__TraceDecls__0__Slow.cpp\n",
      "Archive ar -rcs Vtop__ALL.a Vtop.o Vtop___024root__DepSet_h84412442__0.o Vtop___024root__DepSet_h84412442__1.o Vtop___024root__DepSet_heccd7ead__0.o Vtop_matrix_accumulator__pi9__DepSet_hcabfba31__0.o Vtop_fixed_dot_product__I8_W8__DepSet_h6108f7e9__0.o Vtop__Dpi.o Vtop__Trace__0.o Vtop__ConstPool_0.o Vtop___024root__Slow.o Vtop___024root__DepSet_h84412442__0__Slow.o Vtop___024root__DepSet_heccd7ead__0__Slow.o Vtop_matrix_accumulator__pi9__Slow.o Vtop_matrix_accumulator__pi9__DepSet_hcabfba31__0__Slow.o Vtop_fixed_dot_product__I8_W8__Slow.o Vtop_fixed_dot_product__I8_W8__DepSet_h6108f7e9__0__Slow.o Vtop__Syms.o Vtop__Trace__0__Slow.o Vtop__TraceDecls__0__Slow.o\n",
      "g++     verilator.o verilated.o verilated_dpi.o verilated_vpi.o verilated_fst_c.o verilated_threads.o Vtop__ALL.a   -Wl,-rpath,/usr/local/lib/python3.11/dist-packages/cocotb/libs -L/usr/local/lib/python3.11/dist-packages/cocotb/libs -lcocotbvpi_verilator -lz  -pthread -lpthread -latomic   -o top\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mBuild finished. Time taken: 7.35s\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make: Leaving directory '/workspace/docs/labs/sim_build'\n",
      "cmd: [['/workspace/docs/labs/sim_build/top']]\n",
      "INFO: Running command /workspace/docs/labs/sim_build/top in directory /workspace/docs/labs/sim_build\n",
      "     -.--ns INFO     gpi                                ..mbed/gpi_embed.cpp:76   in set_program_name_in_venv        Did not detect Python virtual environment. Using system-wide Python interpreter\n",
      "     -.--ns INFO     gpi                                ../gpi/GpiCommon.cpp:101  in gpi_print_registered_impl       VPI registered\n",
      "     0.00ns INFO     cocotb                             Running on Verilator version 5.020 2024-01-01\n",
      "     0.00ns INFO     cocotb                             Running tests with cocotb v1.8.0 from /usr/local/lib/python3.11/dist-packages/cocotb\n",
      "     0.00ns INFO     cocotb                             Seeding Python random module with 1741204017\n",
      "     0.00ns INFO     cocotb.regression                  Found test mase_top_tb.test.test\n",
      "     0.00ns INFO     cocotb.regression                  running test (1/1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/src/mase_cocotb/driver.py:25: DeprecationWarning: This method is now private.\n",
      "  self._thread = cocotb.scheduler.add(self._send_thread())\n",
      "/workspace/src/mase_cocotb/monitor.py:27: DeprecationWarning: This method is now private.\n",
      "  self._thread = cocotb.scheduler.add(self._recv_thread())\n",
      "/usr/lib/python3.11/tempfile.py:1073: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpasoiojgw'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_tensors:  (1, 2, 3, 3)\n",
      "GraphModule(\n",
      "  (fc1): LinearInteger(in_features=16, out_features=16, bias=True)\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "def forward(self, x):\n",
      "    flatten = torch.flatten(x, start_dim = 1, end_dim = -1);  x = None\n",
      "    fc1 = self.fc1(flatten);  flatten = None\n",
      "    mul = fc1 * 32;  fc1 = None\n",
      "    round_1 = mul.round();  mul = None\n",
      "    clamp = round_1.clamp(min = 0, max = 255);  round_1 = None\n",
      "    truediv = clamp / 32;  clamp = None\n",
      "    relu = torch.nn.functional.relu(truediv, inplace = False);  truediv = None\n",
      "    return relu\n",
      "    \n",
      "# To see more debug info, please use `graph_module.print_readable()`\n",
      "load_drivers in emit_tb.py\n",
      "    40.00ns INFO     cocotb.regression                  test failed\n",
      "                                                        Traceback (most recent call last):\n",
      "                                                          File \"/root/.mase/top/hardware/test/mase_top_tb/test.py\", line 26, in test\n",
      "                                                            tb.load_drivers(in_tensors)\n",
      "                                                          File \"/workspace/src/chop/passes/graph/transforms/verilog/emit_tb.py\", line 163, in load_drivers\n",
      "                                                            for arg, arg_batches in in_tensors.items():\n",
      "                                                                                    ^^^^^^^^^^^^^^^^\n",
      "                                                        AttributeError: 'tuple' object has no attribute 'items'\n",
      "    40.00ns INFO     cocotb.regression                  **************************************************************************************\n",
      "                                                        ** TEST                          STATUS  SIM TIME (ns)  REAL TIME (s)  RATIO (ns/s) **\n",
      "                                                        **************************************************************************************\n",
      "                                                        ** mase_top_tb.test.test          FAIL          40.00           9.56          4.18  **\n",
      "                                                        **************************************************************************************\n",
      "                                                        ** TESTS=1 PASS=0 FAIL=1 SKIP=0                 40.00           9.78          4.09  **\n",
      "                                                        **************************************************************************************\n",
      "                                                        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mTest finished. Time taken: 11.21s\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- :0: Verilog $finish\n",
      "INFO: Results file: /workspace/docs/labs/sim_build/results.xml\n"
     ]
    }
   ],
   "source": [
    "from chop.actions import simulate\n",
    "\n",
    "simulate(skip_build=False, skip_test=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `simulate` action creates a `dump.vcd` file within the `sim_build` directory, which contains the waveform trace of the simulation. The waveforms can be opened with a viewer like GTKWave.\n",
    "\n",
    "> **TASK**: Follow the instructions [here](https://gtkwave.sourceforge.net/) to install GTKWave on your platform, then open the generated trace file to inspect the signals in the simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Task\n",
    "\n",
    "Pytorch has a number of layers which are available to users to define neural network models. At the moment, `emit_verilog` supports generating Verilog for models including Linear layers and the ReLU activation.\n",
    "\n",
    "> **_MAIN TASK:_** choose another layer type from the [Pytorch list](https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity) and write a SystemVerilog file to implement that layer in hardware. Then, change the generated `top.sv` file to inject that layer within the design. For example, you may replace the ReLU activations with [Leaky ReLU](https://pytorch.org/docs/stable/generated/torch.nn.RReLU.html#torch.nn.RReLU). Re-run the simulation and observe the effect on latency and accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
