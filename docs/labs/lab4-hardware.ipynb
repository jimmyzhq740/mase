{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />\n",
    "<div align=\"center\">\n",
    "  <a href=\"https://deepwok.github.io/\">\n",
    "    <img src=\"../imgs/deepwok.png\" alt=\"Logo\" width=\"160\" height=\"160\">\n",
    "  </a>\n",
    "\n",
    "  <h1 align=\"center\">Lab 4 for Advanced Deep Learning Systems (ADLS) - Hardware Stream</h1>\n",
    "\n",
    "  <p align=\"center\">\n",
    "    ELEC70109/EE9-AML3-10/EE9-AO25\n",
    "    <br />\n",
    "\t\tWritten by\n",
    "    <a href=\"https://aaron-zhao123.github.io/\">Aaron Zhao, Pedro Gimenes </a>\n",
    "  </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General introduction\n",
    "\n",
    "In this lab, you will learn how to emit SystemVerilog code for a neural network that's been transformed and optimized by MASE. Then, you'll design some hardware for a new Pytorch layer, and simulate the hardware using your new module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Hardware Emit pass\n",
    "\n",
    "The `emit_verilog` transform pass generates a top-level RTL file and testbench file according to the `MaseGraph`, which includes a hardware implementation of each layer in the network. This top-level file instantiates modules from the `components` library in MASE and/or modules generated using [HLS](https://en.wikipedia.org/wiki/High-level_synthesis), when internal components are not available. The hardware can then be simulated using [Verilator](https://www.veripool.org/verilator/), or deployed on an FPGA.\n",
    "\n",
    "First, add Machop to your system PATH (if you haven't already done so) and import the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mSet logging level to debug\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage:\n",
      "        verilator --help\n",
      "        verilator --version\n",
      "        verilator --binary -j 0 [options] [source_files.v]... [opt_c_files.cpp/c/cc/a/o/so]\n",
      "        verilator --cc [options] [source_files.v]... [opt_c_files.cpp/c/cc/a/o/so]\n",
      "        verilator --sc [options] [source_files.v]... [opt_c_files.cpp/c/cc/a/o/so]\n",
      "        verilator --lint-only -Wall [source_files.v]...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "\n",
    "from chop.ir.graph.mase_graph import MaseGraph\n",
    "\n",
    "from chop.passes.graph.analysis import (\n",
    "    init_metadata_analysis_pass,\n",
    "    add_common_metadata_analysis_pass,\n",
    "    add_hardware_metadata_analysis_pass,\n",
    "    add_software_metadata_analysis_pass,\n",
    "    report_node_type_analysis_pass,\n",
    ")\n",
    "\n",
    "from chop.passes.graph.transforms import (\n",
    "    emit_verilog_top_transform_pass,\n",
    "    emit_internal_rtl_transform_pass,\n",
    "    emit_bram_transform_pass,\n",
    "    emit_cocotb_transform_pass,\n",
    "    quantize_transform_pass,\n",
    ")\n",
    "\n",
    "from chop.tools.logger import set_logging_verbosity\n",
    "\n",
    "set_logging_verbosity(\"debug\")\n",
    "\n",
    "import toml\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# TO DO: remove\n",
    "import os\n",
    "os.environ[\"PATH\"] = \"/opt/homebrew/bin:\" + os.environ[\"PATH\"]\n",
    "!verilator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, define the neural network. We're using a model which can be used to perform digit classification on the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Toy FC model for digit recognition on MNIST\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(4, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, start_dim=1, end_dim=-1)\n",
    "        x=self.fc1(x)\n",
    "        # x = torch.nn.functional.relu(self.fc1(x),inplace=False)\n",
    "        # x = torch.nn.functional.leaky_relu(self.fc1(x),negative_slope=0.5,inplace=False)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def float_to_fixed(x, scaling_factor, total_bits=8):\n",
    "    \"\"\"\n",
    "    Convert a floating-point numpy array to fixed-point representation.\n",
    "\n",
    "    Parameters:\n",
    "      x            : numpy array of floats.\n",
    "      scaling_factor: Factor to scale the float values (2^frac_bits).\n",
    "      total_bits   : Total number of bits (default is 8).\n",
    "\n",
    "    Returns:\n",
    "      A numpy array of type np.int8 representing the fixed-point values.\n",
    "    \"\"\"\n",
    "    # Scale the floating-point values.\n",
    "    x_scaled = x * scaling_factor\n",
    "\n",
    "    # Round to the nearest integer.\n",
    "    x_fixed = np.trunc(x_scaled)\n",
    "\n",
    "    # Define the representable range for signed 8-bit integers.\n",
    "    min_val = -2**(total_bits - 1)       # -128 for 8 bits\n",
    "    max_val = 2**(total_bits - 1) - 1      #  127 for 8 bits\n",
    "\n",
    "    # Clip values that exceed the representable range.\n",
    "    x_fixed = np.clip(x_fixed, min_val, max_val)\n",
    "\n",
    "    # Return as np.int8.\n",
    "    return x_fixed.astype(np.int8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "frac_bits = 8  # for example\n",
    "scale = 2 ** frac_bits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# weight_np = np.array([\n",
    "#     [-0.0037,  0.2682, -0.4115, -0.3680],\n",
    "#     [-0.1926,  0.1341, -0.0099,  0.3964],\n",
    "#     [-0.0444,  0.1323, -0.1511, -0.0983],\n",
    "#     [-0.4777, -0.3311, -0.2061,  0.0185],\n",
    "#     [ 0.1977,  0.3000, -0.3390, -0.2177],\n",
    "#     [ 0.1816,  0.4152, -0.1029,  0.3742],\n",
    "#     [-0.0806,  0.0529,  0.4527, -0.4638],\n",
    "#     [-0.3148, -0.1266, -0.1949,  0.4320]\n",
    "# ])  # shape (8,4)\n",
    "\n",
    "# bias_np = np.array([-0.3241, -0.2302, -0.3493, -0.4683,\n",
    "#                     -0.2919,  0.4298,  0.2231,  0.2423])  # shape (8,)\n",
    "\n",
    "# # Convert them to PyTorch tensors of the correct shape and dtype\n",
    "# weight_torch = torch.tensor(weight_np, dtype=torch.float32)\n",
    "# bias_torch   = torch.tensor(bias_np,   dtype=torch.float32)\n",
    "\n",
    "\n",
    "# model = MLP()\n",
    "\n",
    "# # Overwrite the linear layerâ€™s weight/bias data\n",
    "# # Note: PyTorch layers store weight/bias in .weight and .bias\n",
    "# with torch.no_grad():\n",
    "#     model.fc1.weight.copy_(weight_torch)\n",
    "#     model.fc1.bias.copy_(bias_torch)\n",
    "\n",
    "# # Input as a NumPy array, shape = (1, 4)\n",
    "# input_np = np.array([[0.4963, 0.7682, 0.0885, 0.1320]])\n",
    "\n",
    "# # Convert to PyTorch tensor\n",
    "# input_torch = torch.tensor(input_np, dtype=torch.float32)\n",
    "\n",
    "# # Forward pass\n",
    "# output = model(input_torch)\n",
    "# print(\"Output:\\n\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supported quantized engines: ['qnnpack', 'none', 'onednn']\n",
      "Current quantized engine:    onednn\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"Supported quantized engines:\", torch.backends.quantized.supported_engines)\n",
    "print(\"Current quantized engine:   \", torch.backends.quantized.engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll generate a MaseGraph and add metadata. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36mDEBUG   \u001b[0m \u001b[34mgraph():\n",
      "    %x : [num_users=1] = placeholder[target=x]\n",
      "    %flatten : [num_users=1] = call_function[target=torch.flatten](args = (%x,), kwargs = {start_dim: 1, end_dim: -1})\n",
      "    %fc1 : [num_users=1] = call_module[target=fc1](args = (%flatten,), kwargs = {})\n",
      "    return fc1\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.5966,  0.1820],\n",
      "         [-0.8567,  1.1006]]])\n",
      "Hellos in add_common_metadata\n",
      "sigoyi in add_common_metadata\n",
      "nihhhhhhhhh in graph_iterator_for_mase_ops in add_common_metadata\n",
      "graph_model:  GraphModule(\n",
      "  (fc1): Linear(in_features=4, out_features=4, bias=True)\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "def forward(self, x):\n",
      "    flatten = torch.flatten(x, start_dim = 1, end_dim = -1);  x = None\n",
      "    fc1 = self.fc1(flatten);  flatten = None\n",
      "    return fc1\n",
      "    \n",
      "# To see more debug info, please use `graph_module.print_readable()`\n",
      "wocao in add_common_metadata\n",
      "graph_iterator_for_metadata:  GraphModule(\n",
      "  (fc1): Linear(in_features=4, out_features=4, bias=True)\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "def forward(self, x):\n",
      "    flatten = torch.flatten(x, start_dim = 1, end_dim = -1);  x = None\n",
      "    fc1 = self.fc1(flatten);  flatten = None\n",
      "    return fc1\n",
      "    \n",
      "# To see more debug info, please use `graph_module.print_readable()`\n",
      "args[i]: tensor([[[-0.5966,  0.1820],\n",
      "         [-0.8567,  1.1006]]])\n",
      "get_shape(args[i]) [1, 2, 2]\n",
      "kwargs:  {'start_dim': 1, 'end_dim': -1}\n",
      "k,v in _annotate_arg_metadata: start_dim 1\n",
      "k,v in _annotate_arg_metadata: end_dim -1\n",
      "args in call_module:  (tensor([[-0.5966,  0.1820, -0.8567,  1.1006]]),)\n",
      "kwargs in call_module:  {}\n",
      "HIIII from analyse_common_parameters_module\n",
      "args from analyse_common_parameters_module (tensor([[-0.5966,  0.1820, -0.8567,  1.1006]]),)\n",
      "kwargs from analyse_common_parameters_module {}\n",
      "meta before _annotate_arg_metadata: {'mase_type': 'module_related_func', 'mase_op': 'linear'}\n",
      "args[i]: tensor([[-0.5966,  0.1820, -0.8567,  1.1006]])\n",
      "get_shape(args[i]) [1, 4]\n",
      "kwargs:  {}\n",
      "meta after _annotate_arg_metadata: {'mase_type': 'module_related_func', 'mase_op': 'linear', 'args': OrderedDict([('data_in_0', {'shape': [1, 4], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]})])}\n",
      "meta after get_type_and_precision: {'mase_type': 'module_related_func', 'mase_op': 'linear', 'args': OrderedDict([('data_in_0', {'shape': [1, 4], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]})])}\n",
      "weight\n",
      "bias\n",
      "meta after for: {'mase_type': 'module_related_func', 'mase_op': 'linear', 'args': OrderedDict([('data_in_0', {'shape': [1, 4], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]}), ('weight', {'type': 'float', 'precision': [32], 'shape': [4, 4], 'from': None}), ('bias', {'type': 'float', 'precision': [32], 'shape': [1, 4], 'from': None})])}\n",
      "wobucao in add_common_metadata\n",
      "nihappp in add_common_metadata\n"
     ]
    }
   ],
   "source": [
    "mlp = MLP()\n",
    "mg = MaseGraph(model=mlp)\n",
    "\n",
    "# Provide a dummy input for the graph so it can use for tracing\n",
    "batch_size = 1\n",
    "x = torch.randn((batch_size, 2, 2))\n",
    "print(x)\n",
    "dummy_in = {\"x\": x}\n",
    "\n",
    "mg, _ = init_metadata_analysis_pass(mg, None)\n",
    "mg, _ = add_common_metadata_analysis_pass(\n",
    "    mg, {\"dummy_in\": dummy_in, \"add_value\": False}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running `emit_verilog`, we'll quantize the model to fixed precision. Refer back to [lab 3](https://deepwok.github.io/mase/modules/labs_2023/lab3.html) if you've forgotten how this works. Check that the data type for each node is correct after quantization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mInspecting graph [add_common_node_type_analysis_pass]\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Node name    Fx Node op     Mase type            Mase op      Value type\n",
      "-----------  -------------  -------------------  -----------  ------------\n",
      "x            placeholder    placeholder          placeholder  NA\n",
      "flatten      call_function  implicit_func        flatten      float\n",
      "fc1          call_module    module_related_func  linear       fixed\n",
      "output       output         output               output       NA\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "placeholder\n",
      "flatten\n",
      "node_config:  {'name': 'fixed', 'data_in_width': 8, 'data_in_frac_width': 5, 'weight_width': 8, 'weight_frac_width': 5, 'bias_width': 8, 'bias_frac_width': 5, 'data_out_width': 8, 'data_out_frac_width': 5, 'floor': True}\n",
      "output\n"
     ]
    }
   ],
   "source": [
    "config_file = os.path.join(\n",
    "    os.path.abspath(\"\"),\n",
    "    \"..\",\n",
    "    \"..\",\n",
    "    \"configs\",\n",
    "    \"tests\",\n",
    "    \"quantize\",\n",
    "    \"fixed.toml\",\n",
    ")\n",
    "with open(config_file, \"r\") as f:\n",
    "    quan_args = toml.load(f)[\"passes\"][\"quantize\"]\n",
    "mg, _ = quantize_transform_pass(mg, quan_args)\n",
    "\n",
    "_ = report_node_type_analysis_pass(mg)\n",
    "\n",
    "# Update the metadata\n",
    "for node in mg.fx_graph.nodes:\n",
    "    for arg, arg_info in node.meta[\"mase\"][\"common\"][\"args\"].items():\n",
    "        if isinstance(arg_info, dict):\n",
    "            arg_info[\"type\"] = \"fixed\"\n",
    "            arg_info[\"precision\"] = [8, 5]\n",
    "    for result, result_info in node.meta[\"mase\"][\"common\"][\"results\"].items():\n",
    "        if isinstance(result_info, dict):\n",
    "            result_info[\"type\"] = \"fixed\"\n",
    "            result_info[\"precision\"] = [8, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, it's important to run the `add_hardware_metadata` analysis pass. This adds all the required metadata which is later used by the `emit_verilog` pass, including:\n",
    "\n",
    "1. The node's toolchain, which defines whether we use internal Verilog modules from the `components` library or the HLS flow.\n",
    "2. The Verilog parameters associated with each node.\n",
    "\n",
    "> **_TASK:_** Read [this page](https://deepwok.github.io/mase/modules/chop/analysis/add_metadata.html#add-hardware-metadata-analysis-pass) for more information on the hardware metadata pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mase_op: linear\n",
      "2222\n",
      " I changed max_parallelism add_hardware_metadata_analysis_pass\n",
      "vp:  {}\n",
      "arg in add_verilog_param: data_in_0\n",
      "vp after for:  {'DATA_IN_0_PRECISION_0': 8, 'DATA_IN_0_PRECISION_1': 5, 'DATA_IN_0_TENSOR_SIZE_DIM_0': 4, 'DATA_IN_0_PARALLELISM_DIM_0': 2, 'DATA_IN_0_TENSOR_SIZE_DIM_1': 1, 'DATA_IN_0_PARALLELISM_DIM_1': 1}\n",
      "arg in add_verilog_param: weight\n",
      "vp after for:  {'DATA_IN_0_PRECISION_0': 8, 'DATA_IN_0_PRECISION_1': 5, 'DATA_IN_0_TENSOR_SIZE_DIM_0': 4, 'DATA_IN_0_PARALLELISM_DIM_0': 2, 'DATA_IN_0_TENSOR_SIZE_DIM_1': 1, 'DATA_IN_0_PARALLELISM_DIM_1': 1, 'WEIGHT_PRECISION_0': 8, 'WEIGHT_PRECISION_1': 5, 'WEIGHT_TENSOR_SIZE_DIM_0': 4, 'WEIGHT_PARALLELISM_DIM_0': 2, 'WEIGHT_TENSOR_SIZE_DIM_1': 4, 'WEIGHT_PARALLELISM_DIM_1': 2}\n",
      "arg in add_verilog_param: bias\n",
      "vp after for:  {'DATA_IN_0_PRECISION_0': 8, 'DATA_IN_0_PRECISION_1': 5, 'DATA_IN_0_TENSOR_SIZE_DIM_0': 4, 'DATA_IN_0_PARALLELISM_DIM_0': 2, 'DATA_IN_0_TENSOR_SIZE_DIM_1': 1, 'DATA_IN_0_PARALLELISM_DIM_1': 1, 'WEIGHT_PRECISION_0': 8, 'WEIGHT_PRECISION_1': 5, 'WEIGHT_TENSOR_SIZE_DIM_0': 4, 'WEIGHT_PARALLELISM_DIM_0': 2, 'WEIGHT_TENSOR_SIZE_DIM_1': 4, 'WEIGHT_PARALLELISM_DIM_1': 2, 'BIAS_PRECISION_0': 8, 'BIAS_PRECISION_1': 5, 'BIAS_TENSOR_SIZE_DIM_0': 4, 'BIAS_PARALLELISM_DIM_0': 2, 'BIAS_TENSOR_SIZE_DIM_1': 1, 'BIAS_PARALLELISM_DIM_1': 1}\n",
      "result in add_verilog_param: data_out_0\n",
      "result_info in add_verilog_param: {'type': 'fixed', 'precision': [8, 5], 'shape': [1, 4], 'torch_dtype': torch.float32}\n",
      "mase_op: placeholder\n",
      "common: {'mase_type': 'placeholder', 'mase_op': 'placeholder', 'args': {}, 'results': OrderedDict([('data_out_0', {'type': 'fixed', 'precision': [8, 5], 'shape': [1, 2, 2], 'torch_dtype': torch.float32})])}\n",
      "hardware: {'is_implicit': True, 'device_id': 0, 'max_parallelism': [2, 2, 2, 2]}\n",
      "mase_op: flatten\n",
      "common: {'mase_type': 'implicit_func', 'mase_op': 'flatten', 'results': OrderedDict([('data_out_0', {'type': 'fixed', 'precision': [8, 5], 'shape': [1, 4], 'torch_dtype': torch.float32})]), 'args': OrderedDict([('data_in_0', {'shape': [1, 2, 2], 'torch_dtype': torch.float32, 'type': 'fixed', 'precision': [8, 5]}), ('start_dim', {'type': 'fixed', 'precision': [8, 5], 'shape': [1]}), ('end_dim', {'type': 'fixed', 'precision': [8, 5], 'shape': [1]})])}\n",
      "hardware: {'is_implicit': True, 'device_id': 0, 'max_parallelism': [2, 2, 2, 2]}\n",
      "mase_op: linear\n",
      "common: {'mase_type': 'module_related_func', 'mase_op': 'linear', 'args': OrderedDict([('data_in_0', {'shape': [1, 4], 'torch_dtype': torch.float32, 'type': 'fixed', 'precision': [8, 5]}), ('weight', {'type': 'fixed', 'precision': [8, 5], 'shape': [4, 4], 'from': None}), ('bias', {'type': 'fixed', 'precision': [8, 5], 'shape': [1, 4], 'from': None})]), 'results': OrderedDict([('data_out_0', {'type': 'fixed', 'precision': [8, 5], 'shape': [1, 4], 'torch_dtype': torch.float32})])}\n",
      "hardware: {'is_implicit': False, 'device_id': -1, 'interface': {'weight': {'storage': 'BRAM', 'transpose': False}, 'bias': {'storage': 'BRAM', 'transpose': False}}, 'toolchain': 'INTERNAL_RTL', 'module': 'fixed_linear', 'dependence_files': ['cast/rtl/fixed_cast.sv', 'linear_layers/fixed_operators/rtl/fixed_dot_product.sv', 'linear_layers/fixed_operators/rtl/fixed_vector_mult.sv', 'linear_layers/fixed_operators/rtl/fixed_accumulator.sv', 'linear_layers/fixed_operators/rtl/fixed_adder_tree.sv', 'linear_layers/fixed_operators/rtl/fixed_adder_tree_layer.sv', 'linear_layers/fixed_operators/rtl/fixed_mult.sv', 'common/rtl/register_slice.sv', 'common/rtl/join2.sv', 'memory/rtl/unpacked_repeat_circular_buffer.sv', 'memory/rtl/skid_buffer.sv', 'linear_layers/fixed_linear_layer/rtl/fixed_linear.sv', 'linear_layers/matmul/rtl/matrix_flatten.sv', 'linear_layers/matmul/rtl/matrix_unflatten.sv', 'linear_layers/matmul/rtl/matrix_fifo.sv', 'linear_layers/matmul/rtl/matrix_accumulator.sv', 'linear_layers/matmul/rtl/simple_matmul.sv', 'linear_layers/matmul/rtl/matmul.sv', 'linear_layers/matmul/rtl/transpose.sv', 'linear_layers/matmul/rtl/matrix_stream_transpose.sv'], 'max_parallelism': [2, 2, 2, 2], 'verilog_param': {'DATA_IN_0_PRECISION_0': 8, 'DATA_IN_0_PRECISION_1': 5, 'DATA_IN_0_TENSOR_SIZE_DIM_0': 4, 'DATA_IN_0_PARALLELISM_DIM_0': 2, 'DATA_IN_0_TENSOR_SIZE_DIM_1': 1, 'DATA_IN_0_PARALLELISM_DIM_1': 1, 'WEIGHT_PRECISION_0': 8, 'WEIGHT_PRECISION_1': 5, 'WEIGHT_TENSOR_SIZE_DIM_0': 4, 'WEIGHT_PARALLELISM_DIM_0': 2, 'WEIGHT_TENSOR_SIZE_DIM_1': 4, 'WEIGHT_PARALLELISM_DIM_1': 2, 'BIAS_PRECISION_0': 8, 'BIAS_PRECISION_1': 5, 'BIAS_TENSOR_SIZE_DIM_0': 4, 'BIAS_PARALLELISM_DIM_0': 2, 'BIAS_TENSOR_SIZE_DIM_1': 1, 'BIAS_PARALLELISM_DIM_1': 1, 'DATA_OUT_0_PRECISION_0': 8, 'DATA_OUT_0_PRECISION_1': 5, 'DATA_OUT_0_TENSOR_SIZE_DIM_0': 4, 'DATA_OUT_0_PARALLELISM_DIM_0': 2, 'DATA_OUT_0_TENSOR_SIZE_DIM_1': 1, 'DATA_OUT_0_PARALLELISM_DIM_1': 1}}\n",
      "mase_op: output\n",
      "common: {'mase_type': 'output', 'mase_op': 'output', 'args': {}, 'results': OrderedDict([('data_out_0', {'type': 'fixed', 'precision': [8, 5], 'shape': [1, 4], 'torch_dtype': torch.float32})])}\n",
      "hardware: {'is_implicit': True, 'device_id': 0, 'max_parallelism': [2, 2, 2, 2]}\n",
      "param_name in CNN.jynb: weight\n",
      "parameter in CNN.jynb: Parameter containing:\n",
      "tensor([[-0.0037,  0.2682, -0.4115, -0.3680],\n",
      "        [-0.1926,  0.1341, -0.0099,  0.3964],\n",
      "        [-0.0444,  0.1323, -0.1511, -0.0983],\n",
      "        [-0.4777, -0.3311, -0.2061,  0.0185]], requires_grad=True)\n",
      "param_name in CNN.jynb: bias\n",
      "parameter in CNN.jynb: Parameter containing:\n",
      "tensor([ 0.1977,  0.3000, -0.3390, -0.2177], requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nweights and bias in the Conv/linear in Maze\\nparam_data = node.meta[\"mase\"].module.get_parameter(param_name).data\\nprint (\"param_data: \", param_data)\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mg, _ = add_hardware_metadata_analysis_pass(mg)\n",
    "for node in mg.nodes:\n",
    "        mase_op = node.meta[\"mase\"][\"common\"][\"mase_op\"]\n",
    "        print ('mase_op:', mase_op)\n",
    "        print (\"common:\",node.meta[\"mase\"][\"common\"])\n",
    "        print (\"hardware:\",node.meta[\"mase\"][\"hardware\"])\n",
    "\n",
    "for node in mg.fx_graph.nodes:\n",
    "        if node.meta[\"mase\"].parameters[\"hardware\"][\"is_implicit\"]:\n",
    "            continue\n",
    "        # Only modules have internal parameters\n",
    "        if node.meta[\"mase\"].module is None:\n",
    "            continue\n",
    "        # print (node.meta[\"mase\"].parameters[\"hardware\"])\n",
    "        # Only checks the hardware data that contains the key toolchain\n",
    "        if \"INTERNAL\" in node.meta[\"mase\"].parameters[\"hardware\"][\"toolchain\"]:\n",
    "                for param_name, parameter in node.meta[\"mase\"].module.named_parameters():\n",
    "                        print (\"param_name in CNN.jynb:\",param_name)\n",
    "                        print (\"parameter in CNN.jynb:\", parameter)\n",
    "\n",
    "\"\"\"\n",
    "weights and bias in the Conv/linear in Maze\n",
    "param_data = node.meta[\"mase\"].module.get_parameter(param_name).data\n",
    "print (\"param_data: \", param_data)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<chop.ir.graph.mase_graph.MaseGraph object at 0x7fff6ff35b50>\n"
     ]
    }
   ],
   "source": [
    "mg_soft, _ = add_software_metadata_analysis_pass(mg)\n",
    "print (mg_soft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, run the emit verilog pass to generate the SystemVerilog files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mEmitting Verilog...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEmitting internal components...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter_map in VerilogEmitter: {'fc1_DATA_IN_0_PRECISION_0': 8, 'fc1_DATA_IN_0_PRECISION_1': 5, 'fc1_DATA_IN_0_TENSOR_SIZE_DIM_0': 4, 'fc1_DATA_IN_0_PARALLELISM_DIM_0': 2, 'fc1_DATA_IN_0_TENSOR_SIZE_DIM_1': 1, 'fc1_DATA_IN_0_PARALLELISM_DIM_1': 1, 'fc1_WEIGHT_PRECISION_0': 8, 'fc1_WEIGHT_PRECISION_1': 5, 'fc1_WEIGHT_TENSOR_SIZE_DIM_0': 4, 'fc1_WEIGHT_PARALLELISM_DIM_0': 2, 'fc1_WEIGHT_TENSOR_SIZE_DIM_1': 4, 'fc1_WEIGHT_PARALLELISM_DIM_1': 2, 'fc1_BIAS_PRECISION_0': 8, 'fc1_BIAS_PRECISION_1': 5, 'fc1_BIAS_TENSOR_SIZE_DIM_0': 4, 'fc1_BIAS_PARALLELISM_DIM_0': 2, 'fc1_BIAS_TENSOR_SIZE_DIM_1': 1, 'fc1_BIAS_PARALLELISM_DIM_1': 1, 'fc1_DATA_OUT_0_PRECISION_0': 8, 'fc1_DATA_OUT_0_PRECISION_1': 5, 'fc1_DATA_OUT_0_TENSOR_SIZE_DIM_0': 4, 'fc1_DATA_OUT_0_PARALLELISM_DIM_0': 2, 'fc1_DATA_OUT_0_TENSOR_SIZE_DIM_1': 1, 'fc1_DATA_OUT_0_PARALLELISM_DIM_1': 1, 'DATA_IN_0_PRECISION_0': 8, 'DATA_IN_0_PRECISION_1': 5, 'DATA_IN_0_TENSOR_SIZE_DIM_0': 4, 'DATA_IN_0_PARALLELISM_DIM_0': 2, 'DATA_IN_0_TENSOR_SIZE_DIM_1': 1, 'DATA_IN_0_PARALLELISM_DIM_1': 1, 'DATA_OUT_0_PRECISION_0': 8, 'DATA_OUT_0_PRECISION_1': 5, 'DATA_OUT_0_TENSOR_SIZE_DIM_0': 4, 'DATA_OUT_0_PARALLELISM_DIM_0': 2, 'DATA_OUT_0_TENSOR_SIZE_DIM_1': 1, 'DATA_OUT_0_PARALLELISM_DIM_1': 1}\n",
      "nodes_in: [fc1]\n",
      "nodes_out: [fc1]\n",
      "parameter in VerilogParameterEmitter:     parameter fc1_DATA_IN_0_PRECISION_0 = 8,\n",
      "    parameter fc1_DATA_IN_0_PRECISION_1 = 5,\n",
      "    parameter fc1_DATA_IN_0_TENSOR_SIZE_DIM_0 = 4,\n",
      "    parameter fc1_DATA_IN_0_PARALLELISM_DIM_0 = 2,\n",
      "    parameter fc1_DATA_IN_0_TENSOR_SIZE_DIM_1 = 1,\n",
      "    parameter fc1_DATA_IN_0_PARALLELISM_DIM_1 = 1,\n",
      "    parameter fc1_WEIGHT_PRECISION_0 = 8,\n",
      "    parameter fc1_WEIGHT_PRECISION_1 = 5,\n",
      "    parameter fc1_WEIGHT_TENSOR_SIZE_DIM_0 = 4,\n",
      "    parameter fc1_WEIGHT_PARALLELISM_DIM_0 = 2,\n",
      "    parameter fc1_WEIGHT_TENSOR_SIZE_DIM_1 = 4,\n",
      "    parameter fc1_WEIGHT_PARALLELISM_DIM_1 = 2,\n",
      "    parameter fc1_BIAS_PRECISION_0 = 8,\n",
      "    parameter fc1_BIAS_PRECISION_1 = 5,\n",
      "    parameter fc1_BIAS_TENSOR_SIZE_DIM_0 = 4,\n",
      "    parameter fc1_BIAS_PARALLELISM_DIM_0 = 2,\n",
      "    parameter fc1_BIAS_TENSOR_SIZE_DIM_1 = 1,\n",
      "    parameter fc1_BIAS_PARALLELISM_DIM_1 = 1,\n",
      "    parameter fc1_DATA_OUT_0_PRECISION_0 = 8,\n",
      "    parameter fc1_DATA_OUT_0_PRECISION_1 = 5,\n",
      "    parameter fc1_DATA_OUT_0_TENSOR_SIZE_DIM_0 = 4,\n",
      "    parameter fc1_DATA_OUT_0_PARALLELISM_DIM_0 = 2,\n",
      "    parameter fc1_DATA_OUT_0_TENSOR_SIZE_DIM_1 = 1,\n",
      "    parameter fc1_DATA_OUT_0_PARALLELISM_DIM_1 = 1,\n",
      "    parameter DATA_IN_0_PRECISION_0 = 8,\n",
      "    parameter DATA_IN_0_PRECISION_1 = 5,\n",
      "    parameter DATA_IN_0_TENSOR_SIZE_DIM_0 = 4,\n",
      "    parameter DATA_IN_0_PARALLELISM_DIM_0 = 2,\n",
      "    parameter DATA_IN_0_TENSOR_SIZE_DIM_1 = 1,\n",
      "    parameter DATA_IN_0_PARALLELISM_DIM_1 = 1,\n",
      "    parameter DATA_OUT_0_PRECISION_0 = 8,\n",
      "    parameter DATA_OUT_0_PRECISION_1 = 5,\n",
      "    parameter DATA_OUT_0_TENSOR_SIZE_DIM_0 = 4,\n",
      "    parameter DATA_OUT_0_PARALLELISM_DIM_0 = 2,\n",
      "    parameter DATA_OUT_0_TENSOR_SIZE_DIM_1 = 1,\n",
      "    parameter DATA_OUT_0_PARALLELISM_DIM_1 = 1,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mg, _ = emit_verilog_top_transform_pass(mg)\n",
    "mg, _ = emit_internal_rtl_transform_pass(mg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generated files should now be found under `top/hardware`. \n",
    "\n",
    "> **_TASK:_** Read through `top/hardware/rtl/top.sv` and make sure you understand how our MLP model maps to this hardware design. \n",
    "\n",
    "You will notice the following instantiated modules:\n",
    "\n",
    "* `fixed_linear`: this is found under `components/linear/fixed_linear.sv` and implements each Linear layer in the model.\n",
    "* `fc<layer number>_weight/bias_source`: these are [BRAM](https://nandland.com/lesson-15-what-is-a-block-ram-bram/) memories which drive the weights and biases into the linear layers for computation.\n",
    "* `fixed_relu`: found under `components/activations/fixed_relu.sv`, implements the ReLU activation.\n",
    "\n",
    "As of now, we can't yet run a simulation on the model, as we haven't yet generated the memory components. To do this, run the `emit_bram` transform pass as follows, which will generate the memory initialization files and SystemVerilog modules to drive weights and biases into the linear layers. Finally, the `emit_verilog_tb` transform pass will generate the testbench files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mEmitting BRAM...\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[34mEmitting DAT file for node: fc1, parameter: weight\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[34mROM module weight successfully written into /root/.mase/top/hardware/rtl/fc1_weight_source.sv\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[34mInit data weight successfully written into /root/.mase/top/hardware/rtl/fc1_weight_rom.dat\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[34mEmitting DAT file for node: fc1, parameter: bias\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[34mROM module bias successfully written into /root/.mase/top/hardware/rtl/fc1_bias_source.sv\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[34mInit data bias successfully written into /root/.mase/top/hardware/rtl/fc1_bias_rom.dat\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 in emit_bram_transform_pass\n",
      "/root/.mase/top/hardware/rtl\n",
      "param_name in emit_bram_handshake: weight\n",
      "out_size: 4\n",
      "out_size in emit_parameters_in_mem_internal: 4\n",
      "fc1\n",
      "verilog_param_name weight\n",
      "total_size: 16\n",
      "shape: [4, 4]\n",
      " node.meta[mase].parameters[hardware][verilog_param] {'DATA_IN_0_PRECISION_0': 8, 'DATA_IN_0_PRECISION_1': 5, 'DATA_IN_0_TENSOR_SIZE_DIM_0': 4, 'DATA_IN_0_PARALLELISM_DIM_0': 2, 'DATA_IN_0_TENSOR_SIZE_DIM_1': 1, 'DATA_IN_0_PARALLELISM_DIM_1': 1, 'WEIGHT_PRECISION_0': 8, 'WEIGHT_PRECISION_1': 5, 'WEIGHT_TENSOR_SIZE_DIM_0': 4, 'WEIGHT_PARALLELISM_DIM_0': 2, 'WEIGHT_TENSOR_SIZE_DIM_1': 4, 'WEIGHT_PARALLELISM_DIM_1': 2, 'BIAS_PRECISION_0': 8, 'BIAS_PRECISION_1': 5, 'BIAS_TENSOR_SIZE_DIM_0': 4, 'BIAS_PARALLELISM_DIM_0': 2, 'BIAS_TENSOR_SIZE_DIM_1': 1, 'BIAS_PARALLELISM_DIM_1': 1, 'DATA_OUT_0_PRECISION_0': 8, 'DATA_OUT_0_PRECISION_1': 5, 'DATA_OUT_0_TENSOR_SIZE_DIM_0': 4, 'DATA_OUT_0_PARALLELISM_DIM_0': 2, 'DATA_OUT_0_TENSOR_SIZE_DIM_1': 1, 'DATA_OUT_0_PARALLELISM_DIM_1': 1}\n",
      "out_size: 4\n",
      "param_data in emit_parameters_in_dat_internal:  tensor([[-0.0037,  0.2682, -0.4115, -0.3680],\n",
      "        [-0.1926,  0.1341, -0.0099,  0.3964],\n",
      "        [-0.0444,  0.1323, -0.1511, -0.0983],\n",
      "        [-0.4777, -0.3311, -0.2061,  0.0185]])\n",
      "param_data in emit_parameters_in_dat_internal after flatten:  [-0.003743410110473633, 0.26822179555892944, -0.4115225672721863, -0.3679695129394531, -0.19257718324661255, 0.13407868146896362, -0.009906589984893799, 0.39644473791122437, -0.04437202215194702, 0.1323062777519226, -0.15110653638839722, -0.09828269481658936, -0.4776742458343506, -0.33114105463027954, -0.20611155033111572, 0.018521785736083984]\n",
      "out_depth:  4\n",
      "value in dec: -0.368\n",
      "value in signed fixed: 244\n",
      "value in binary: 0b11110100\n",
      "value_bits: f4\n",
      "value in dec: -0.4115\n",
      "value in signed fixed: 243\n",
      "value in binary: 0b11110011\n",
      "value_bits: f3\n",
      "value in dec: 0.2682\n",
      "value in signed fixed: 9\n",
      "value in binary: 0b1001\n",
      "value_bits: 09\n",
      "value in dec: -0.0037\n",
      "value in signed fixed: 0\n",
      "value in binary: 0b0\n",
      "value_bits: 00\n",
      "value in dec: 0.3964\n",
      "value in signed fixed: 13\n",
      "value in binary: 0b1101\n",
      "value_bits: 0d\n",
      "value in dec: -0.0099\n",
      "value in signed fixed: 0\n",
      "value in binary: 0b0\n",
      "value_bits: 00\n",
      "value in dec: 0.1341\n",
      "value in signed fixed: 4\n",
      "value in binary: 0b100\n",
      "value_bits: 04\n",
      "value in dec: -0.1926\n",
      "value in signed fixed: 250\n",
      "value in binary: 0b11111010\n",
      "value_bits: fa\n",
      "value in dec: -0.0983\n",
      "value in signed fixed: 253\n",
      "value in binary: 0b11111101\n",
      "value_bits: fd\n",
      "value in dec: -0.1511\n",
      "value in signed fixed: 251\n",
      "value in binary: 0b11111011\n",
      "value_bits: fb\n",
      "value in dec: 0.1323\n",
      "value in signed fixed: 4\n",
      "value in binary: 0b100\n",
      "value_bits: 04\n",
      "value in dec: -0.0444\n",
      "value in signed fixed: 255\n",
      "value in binary: 0b11111111\n",
      "value_bits: ff\n",
      "value in dec: 0.0185\n",
      "value in signed fixed: 1\n",
      "value in binary: 0b1\n",
      "value_bits: 01\n",
      "value in dec: -0.2061\n",
      "value in signed fixed: 249\n",
      "value in binary: 0b11111001\n",
      "value_bits: f9\n",
      "value in dec: -0.3311\n",
      "value in signed fixed: 245\n",
      "value in binary: 0b11110101\n",
      "value_bits: f5\n",
      "value in dec: -0.4777\n",
      "value in signed fixed: 241\n",
      "value in binary: 0b11110001\n",
      "value_bits: f1\n",
      "data_buff:  0009f3f4\n",
      "fa04000d\n",
      "ff04fbfd\n",
      "f1f5f901\n",
      "\n",
      "param_name in emit_bram_handshake: bias\n",
      "out_size: 2\n",
      "out_size in emit_parameters_in_mem_internal: 2\n",
      "fc1\n",
      "verilog_param_name bias\n",
      "total_size: 4\n",
      "shape: [1, 4]\n",
      " node.meta[mase].parameters[hardware][verilog_param] {'DATA_IN_0_PRECISION_0': 8, 'DATA_IN_0_PRECISION_1': 5, 'DATA_IN_0_TENSOR_SIZE_DIM_0': 4, 'DATA_IN_0_PARALLELISM_DIM_0': 2, 'DATA_IN_0_TENSOR_SIZE_DIM_1': 1, 'DATA_IN_0_PARALLELISM_DIM_1': 1, 'WEIGHT_PRECISION_0': 8, 'WEIGHT_PRECISION_1': 5, 'WEIGHT_TENSOR_SIZE_DIM_0': 4, 'WEIGHT_PARALLELISM_DIM_0': 2, 'WEIGHT_TENSOR_SIZE_DIM_1': 4, 'WEIGHT_PARALLELISM_DIM_1': 2, 'BIAS_PRECISION_0': 8, 'BIAS_PRECISION_1': 5, 'BIAS_TENSOR_SIZE_DIM_0': 4, 'BIAS_PARALLELISM_DIM_0': 2, 'BIAS_TENSOR_SIZE_DIM_1': 1, 'BIAS_PARALLELISM_DIM_1': 1, 'DATA_OUT_0_PRECISION_0': 8, 'DATA_OUT_0_PRECISION_1': 5, 'DATA_OUT_0_TENSOR_SIZE_DIM_0': 4, 'DATA_OUT_0_PARALLELISM_DIM_0': 2, 'DATA_OUT_0_TENSOR_SIZE_DIM_1': 1, 'DATA_OUT_0_PARALLELISM_DIM_1': 1}\n",
      "out_size: 2\n",
      "param_data in emit_parameters_in_dat_internal:  tensor([ 0.1977,  0.3000, -0.3390, -0.2177])\n",
      "param_data in emit_parameters_in_dat_internal after flatten:  [0.19766759872436523, 0.30001139640808105, -0.3389705419540405, -0.21773141622543335]\n",
      "out_depth:  2\n",
      "value in dec: 0.3\n",
      "value in signed fixed: 10\n",
      "value in binary: 0b1010\n",
      "value_bits: 0a\n",
      "value in dec: 0.1977\n",
      "value in signed fixed: 6\n",
      "value in binary: 0b110\n",
      "value_bits: 06\n",
      "value in dec: -0.2177\n",
      "value in signed fixed: 249\n",
      "value in binary: 0b11111001\n",
      "value_bits: f9\n",
      "value in dec: -0.339\n",
      "value in signed fixed: 245\n",
      "value in binary: 0b11110101\n",
      "value_bits: f5\n",
      "data_buff:  060a\n",
      "f5f9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mg, _ = emit_bram_transform_pass(mg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mEmitting testbench...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "mg, _ = emit_cocotb_transform_pass(mg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **_TASK:_** Now, you're ready to launch a simulation by calling the simulate action as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Running command perl /usr/local/bin/verilator -cc --exe -Mdir /workspace/docs/labs/sim_build -DCOCOTB_SIM=1 --top-module top --vpi --public-flat-rw --prefix Vtop -o top -LDFLAGS '-Wl,-rpath,/usr/local/lib/python3.11/dist-packages/cocotb/libs -L/usr/local/lib/python3.11/dist-packages/cocotb/libs -lcocotbvpi_verilator' -Wno-fatal -Wno-lint -Wno-style --trace-fst --trace-structs --trace-depth 3 -I/root/.mase/top/hardware/rtl -I/workspace/src/mase_components/interface/rtl -I/workspace/src/mase_components/language_models/rtl -I/workspace/src/mase_components/memory/rtl -I/workspace/src/mase_components/vivado/rtl -I/workspace/src/mase_components/convolution_layers/rtl -I/workspace/src/mase_components/cast/rtl -I/workspace/src/mase_components/systolic_arrays/rtl -I/workspace/src/mase_components/scalar_operators/rtl -I/workspace/src/mase_components/transformer_layers/rtl -I/workspace/src/mase_components/common/rtl -I/workspace/src/mase_components/hls/rtl -I/workspace/src/mase_components/vision_models/rtl -I/workspace/src/mase_components/linear_layers/rtl -I/workspace/src/mase_components/activation_layers/rtl -I/workspace/src/mase_components/normalization_layers/rtl -I/workspace/src/mase_components/helper/rtl /usr/local/lib/python3.11/dist-packages/cocotb/share/lib/verilator/verilator.cpp /root/.mase/top/hardware/rtl/register_slice.sv /root/.mase/top/hardware/rtl/fixed_adder_tree_layer.sv /root/.mase/top/hardware/rtl/unpacked_repeat_circular_buffer.sv /root/.mase/top/hardware/rtl/matmul.sv /root/.mase/top/hardware/rtl/join2.sv /root/.mase/top/hardware/rtl/sliding_window.sv /root/.mase/top/hardware/rtl/convolution.sv /root/.mase/top/hardware/rtl/matrix_unflatten.sv /root/.mase/top/hardware/rtl/fixed_signed_cast.sv /root/.mase/top/hardware/rtl/blk_mem_gen_0.sv /root/.mase/top/hardware/rtl/fixed_relu.sv /root/.mase/top/hardware/rtl/fixed_adder_tree.sv /root/.mase/top/hardware/rtl/matrix_fifo.sv /root/.mase/top/hardware/rtl/conv1_bias_source.sv /root/.mase/top/hardware/rtl/fc1_bias_source.sv /root/.mase/top/hardware/rtl/fixed_linear.sv /root/.mase/top/hardware/rtl/top.sv /root/.mase/top/hardware/rtl/fc1_weight_source.sv /root/.mase/top/hardware/rtl/fc1_1_bias_source.sv /root/.mase/top/hardware/rtl/conv1_weight_source.sv /root/.mase/top/hardware/rtl/transpose.sv /root/.mase/top/hardware/rtl/fixed_rounding.sv /root/.mase/top/hardware/rtl/input_buffer.sv /root/.mase/top/hardware/rtl/floor_round.sv /root/.mase/top/hardware/rtl/convolution_mase.sv /root/.mase/top/hardware/rtl/fc1_1_weight_source.sv /root/.mase/top/hardware/rtl/convolution_arith.sv /root/.mase/top/hardware/rtl/matrix_accumulator.sv /root/.mase/top/hardware/rtl/simple_matmul.sv /root/.mase/top/hardware/rtl/skid_buffer.sv /root/.mase/top/hardware/rtl/matrix_stream_transpose.sv /root/.mase/top/hardware/rtl/unpacked_skid_buffer.sv /root/.mase/top/hardware/rtl/fixed_leakyrelu.sv /root/.mase/top/hardware/rtl/fixed_accumulator.sv /root/.mase/top/hardware/rtl/fixed_vector_mult.sv /root/.mase/top/hardware/rtl/matrix_flatten.sv /root/.mase/top/hardware/rtl/fixed_dot_product.sv /root/.mase/top/hardware/rtl/padding.sv /root/.mase/top/hardware/rtl/fixed_cast.sv /root/.mase/top/hardware/rtl/roller.sv /root/.mase/top/hardware/rtl/fixed_mult.sv /root/.mase/top/hardware/rtl/signed_clamp.sv in directory /workspace/docs/labs/sim_build\n",
      "INFO: Running command make -C /workspace/docs/labs/sim_build -f Vtop.mk in directory /workspace/docs/labs/sim_build\n",
      "make: Entering directory '/workspace/docs/labs/sim_build'\n",
      "ccache g++  -I.  -MMD -I/usr/local/share/verilator/include -I/usr/local/share/verilator/include/vltstd -DVM_COVERAGE=0 -DVM_SC=0 -DVM_TRACE=1 -DVM_TRACE_FST=1 -DVM_TRACE_VCD=0 -faligned-new -fcf-protection=none -Wno-bool-operation -Wno-overloaded-virtual -Wno-shadow -Wno-sign-compare -Wno-uninitialized -Wno-unused-but-set-parameter -Wno-unused-but-set-variable -Wno-unused-parameter -Wno-unused-variable       -Os -c -o verilator.o /usr/local/lib/python3.11/dist-packages/cocotb/share/lib/verilator/verilator.cpp\n",
      "ccache g++ -Os  -I.  -MMD -I/usr/local/share/verilator/include -I/usr/local/share/verilator/include/vltstd -DVM_COVERAGE=0 -DVM_SC=0 -DVM_TRACE=1 -DVM_TRACE_FST=1 -DVM_TRACE_VCD=0 -faligned-new -fcf-protection=none -Wno-bool-operation -Wno-overloaded-virtual -Wno-shadow -Wno-sign-compare -Wno-uninitialized -Wno-unused-but-set-parameter -Wno-unused-but-set-variable -Wno-unused-parameter -Wno-unused-variable       -c -o verilated.o /usr/local/share/verilator/include/verilated.cpp\n",
      "ccache g++ -Os  -I.  -MMD -I/usr/local/share/verilator/include -I/usr/local/share/verilator/include/vltstd -DVM_COVERAGE=0 -DVM_SC=0 -DVM_TRACE=1 -DVM_TRACE_FST=1 -DVM_TRACE_VCD=0 -faligned-new -fcf-protection=none -Wno-bool-operation -Wno-overloaded-virtual -Wno-shadow -Wno-sign-compare -Wno-uninitialized -Wno-unused-but-set-parameter -Wno-unused-but-set-variable -Wno-unused-parameter -Wno-unused-variable       -c -o verilated_dpi.o /usr/local/share/verilator/include/verilated_dpi.cpp\n",
      "ccache g++ -Os  -I.  -MMD -I/usr/local/share/verilator/include -I/usr/local/share/verilator/include/vltstd -DVM_COVERAGE=0 -DVM_SC=0 -DVM_TRACE=1 -DVM_TRACE_FST=1 -DVM_TRACE_VCD=0 -faligned-new -fcf-protection=none -Wno-bool-operation -Wno-overloaded-virtual -Wno-shadow -Wno-sign-compare -Wno-uninitialized -Wno-unused-but-set-parameter -Wno-unused-but-set-variable -Wno-unused-parameter -Wno-unused-variable       -c -o verilated_vpi.o /usr/local/share/verilator/include/verilated_vpi.cpp\n",
      "ccache g++ -Os  -I.  -MMD -I/usr/local/share/verilator/include -I/usr/local/share/verilator/include/vltstd -DVM_COVERAGE=0 -DVM_SC=0 -DVM_TRACE=1 -DVM_TRACE_FST=1 -DVM_TRACE_VCD=0 -faligned-new -fcf-protection=none -Wno-bool-operation -Wno-overloaded-virtual -Wno-shadow -Wno-sign-compare -Wno-uninitialized -Wno-unused-but-set-parameter -Wno-unused-but-set-variable -Wno-unused-parameter -Wno-unused-variable       -c -o verilated_fst_c.o /usr/local/share/verilator/include/verilated_fst_c.cpp\n",
      "ccache g++ -Os  -I.  -MMD -I/usr/local/share/verilator/include -I/usr/local/share/verilator/include/vltstd -DVM_COVERAGE=0 -DVM_SC=0 -DVM_TRACE=1 -DVM_TRACE_FST=1 -DVM_TRACE_VCD=0 -faligned-new -fcf-protection=none -Wno-bool-operation -Wno-overloaded-virtual -Wno-shadow -Wno-sign-compare -Wno-uninitialized -Wno-unused-but-set-parameter -Wno-unused-but-set-variable -Wno-unused-parameter -Wno-unused-variable       -c -o verilated_threads.o /usr/local/share/verilator/include/verilated_threads.cpp\n",
      "/usr/bin/python3 /usr/local/share/verilator/bin/verilator_includer -DVL_INCLUDE_OPT=include Vtop.cpp Vtop___024root__DepSet_h84412442__0.cpp Vtop___024root__DepSet_heccd7ead__0.cpp Vtop__Dpi.cpp Vtop__Trace__0.cpp Vtop__ConstPool_0.cpp Vtop___024root__Slow.cpp Vtop___024root__DepSet_h84412442__0__Slow.cpp Vtop___024root__DepSet_heccd7ead__0__Slow.cpp Vtop__Syms.cpp Vtop__Trace__0__Slow.cpp Vtop__TraceDecls__0__Slow.cpp > Vtop__ALL.cpp\n",
      "ccache g++ -Os  -I.  -MMD -I/usr/local/share/verilator/include -I/usr/local/share/verilator/include/vltstd -DVM_COVERAGE=0 -DVM_SC=0 -DVM_TRACE=1 -DVM_TRACE_FST=1 -DVM_TRACE_VCD=0 -faligned-new -fcf-protection=none -Wno-bool-operation -Wno-overloaded-virtual -Wno-shadow -Wno-sign-compare -Wno-uninitialized -Wno-unused-but-set-parameter -Wno-unused-but-set-variable -Wno-unused-parameter -Wno-unused-variable       -c -o Vtop__ALL.o Vtop__ALL.cpp\n",
      "Archive ar -rcs Vtop__ALL.a Vtop__ALL.o\n",
      "g++     verilator.o verilated.o verilated_dpi.o verilated_vpi.o verilated_fst_c.o verilated_threads.o Vtop__ALL.a   -Wl,-rpath,/usr/local/lib/python3.11/dist-packages/cocotb/libs -L/usr/local/lib/python3.11/dist-packages/cocotb/libs -lcocotbvpi_verilator -lz  -pthread -lpthread -latomic   -o top\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mBuild finished. Time taken: 2.58s\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make: Leaving directory '/workspace/docs/labs/sim_build'\n",
      "sys in simulate.py:  <module 'sys' (built-in)>\n",
      "cmd: [['/workspace/docs/labs/sim_build/top']]\n",
      "INFO: Running command /workspace/docs/labs/sim_build/top in directory /workspace/docs/labs/sim_build\n",
      "     -.--ns INFO     gpi                                ..mbed/gpi_embed.cpp:76   in set_program_name_in_venv        Did not detect Python virtual environment. Using system-wide Python interpreter\n",
      "     -.--ns INFO     gpi                                ../gpi/GpiCommon.cpp:101  in gpi_print_registered_impl       VPI registered\n",
      "     0.00ns INFO     cocotb                             Running on Verilator version 5.020 2024-01-01\n",
      "     0.00ns INFO     cocotb                             Running tests with cocotb v1.8.0 from /usr/local/lib/python3.11/dist-packages/cocotb\n",
      "     0.00ns INFO     cocotb                             Seeding Python random module with 1741563448\n",
      "     0.00ns INFO     cocotb.regression                  Found test mase_top_tb.test.test\n",
      "     0.00ns INFO     cocotb.regression                  running test (1/1)\n",
      "arg in _emit_cocotb: data_in_0\n",
      "getattr(dut, arg) top.data_in_0\n",
      "getattr(dut, arg).value [00000000, 00000000]\n",
      "arg in _emit_cocotb: weight\n",
      "arg in _emit_cocotb: bias\n",
      "nihap in generate_inputs\n",
      "weight:  Parameter containing:\n",
      "tensor([[-0.0037,  0.2682, -0.4115, -0.3680],\n",
      "        [-0.1926,  0.1341, -0.0099,  0.3964],\n",
      "        [-0.0444,  0.1323, -0.1511, -0.0983],\n",
      "        [-0.4777, -0.3311, -0.2061,  0.0185]], requires_grad=True)\n",
      "Bias:  Parameter containing:\n",
      "tensor([ 0.1977,  0.3000, -0.3390, -0.2177], requires_grad=True)\n",
      "load_drivers in emit_tb.py\n",
      "tensor_dim: 2\n",
      "parallelism_list: [1, 2]\n",
      "parallelism in fixed_process_tensor: [1, 2]\n",
      "tensor before tensor: tensor([[0.4963, 0.7682, 0.0885, 0.1320]])\n",
      "tensor after tensor: tensor([[0.4963, 0.7682, 0.0885, 0.1320]])\n",
      "q_tensor in fixed_preprocess_tensor: tensor([[15, 24,  2,  4]], dtype=torch.int32)\n",
      "Final splitted result: [tensor([[15, 24]], dtype=torch.int32), tensor([[2, 4]], dtype=torch.int32)]\n",
      "blocks = [[15, 24], [2, 4]]\n",
      "block_size: 2\n",
      "in_data_blocks: [[15, 24], [2, 4]]\n",
      "block sending in: [15, 24]\n",
      "block sending in: [2, 4]\n",
      "expectations: tensor([[ 0.3125,  0.3750, -0.2812, -0.7500]],\n",
      "       grad_fn=<IntegerQuantizeBackward>)\n",
      "shape of expectations: 2\n",
      "parallelism in fixed_process_tensor: [1, 2]\n",
      "tensor before tensor: tensor([[ 0.3125,  0.3750, -0.2812, -0.7500]],\n",
      "       grad_fn=<IntegerQuantizeBackward>)\n",
      "tensor after tensor: tensor([[ 0.3125,  0.3750, -0.2812, -0.7500]], grad_fn=<ViewBackward0>)\n",
      "q_tensor in fixed_preprocess_tensor: tensor([[ 10,  12,  -9, -24]], dtype=torch.int32)\n",
      "Final splitted result: [tensor([[10, 12]], dtype=torch.int32), tensor([[ -9, -24]], dtype=torch.int32)]\n",
      "blocks = [[10, 12], [-9, -24]]\n",
      "output_blocks in load_monitors: [[10, 12], [-9, -24]]\n",
      "block in load_monitors in emit_tb.py: [10, 12]\n",
      "block in load_monitors in emit_tb.py: [-9, -24]\n",
      "    60.00ns DEBUG    cocotb.driver.StreamDriver         Sent from streamping.py StreamDriver [15, 24]\n",
      "   100.00ns DEBUG    cocotb.driver.StreamDriver         Sent from streamping.py StreamDriver [2, 4]\n",
      "   300.00ns DEBUG    cocotb.monitor.StreamMonitor       Observed output beat hiiiiiii [12, -4]\n",
      "   300.00ns DEBUG    cocotb.monitor.StreamMonitor       Got [12, -4], Expected [10, 12]\n",
      "   340.00ns DEBUG    cocotb.monitor.StreamMonitor       Observed output beat hiiiiiii [-11, -12]\n",
      "   340.00ns DEBUG    cocotb.monitor.StreamMonitor       Got [-11, -12], Expected [-9, -24]\n",
      "   340.00ns INFO     cocotb.monitor.StreamMonitor       Monitor has been drained.\n",
      "   340.00ns INFO     cocotb.regression                  test passed\n",
      "   340.00ns INFO     cocotb.regression                  **************************************************************************************\n",
      "                                                        ** TEST                          STATUS  SIM TIME (ns)  REAL TIME (s)  RATIO (ns/s) **\n",
      "                                                        **************************************************************************************\n",
      "                                                        ** mase_top_tb.test.test          PASS         340.00          37.03          9.18  **\n",
      "                                                        **************************************************************************************\n",
      "                                                        ** TESTS=1 PASS=1 FAIL=0 SKIP=0                340.00          37.36          9.10  **\n",
      "                                                        **************************************************************************************\n",
      "                                                        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/src/mase_cocotb/driver.py:25: DeprecationWarning: This method is now private.\n",
      "  self._thread = cocotb.scheduler.add(self._send_thread())\n",
      "/workspace/src/mase_cocotb/monitor.py:27: DeprecationWarning: This method is now private.\n",
      "  self._thread = cocotb.scheduler.add(self._recv_thread())\n",
      "/usr/lib/python3.11/tempfile.py:1073: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmp6ysg0gff'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- :0: Verilog $finish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mTest finished. Time taken: 39.03s\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Results file: /workspace/docs/labs/sim_build/results.xml\n"
     ]
    }
   ],
   "source": [
    "from chop.actions import simulate\n",
    "\n",
    "simulate(skip_build=False, skip_test=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `simulate` action creates a `dump.vcd` file within the `sim_build` directory, which contains the waveform trace of the simulation. The waveforms can be opened with a viewer like GTKWave.\n",
    "\n",
    "> **TASK**: Follow the instructions [here](https://gtkwave.sourceforge.net/) to install GTKWave on your platform, then open the generated trace file to inspect the signals in the simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Task\n",
    "\n",
    "Pytorch has a number of layers which are available to users to define neural network models. At the moment, `emit_verilog` supports generating Verilog for models including Linear layers and the ReLU activation.\n",
    "\n",
    "> **_MAIN TASK:_** choose another layer type from the [Pytorch list](https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity) and write a SystemVerilog file to implement that layer in hardware. Then, change the generated `top.sv` file to inject that layer within the design. For example, you may replace the ReLU activations with [Leaky ReLU](https://pytorch.org/docs/stable/generated/torch.nn.RReLU.html#torch.nn.RReLU). Re-run the simulation and observe the effect on latency and accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
